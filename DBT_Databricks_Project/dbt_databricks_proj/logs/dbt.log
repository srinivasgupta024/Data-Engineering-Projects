[0m14:12:45.024134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002150CD9D4F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021510290B00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002151032B110>]}


============================== 14:12:45.028009 | 9e6d980f-1292-464c-82de-a8ecc1fdaec5 ==============================
[0m14:12:45.028009 [info ] [MainThread]: Running with dbt=1.10.10
[0m14:12:45.028009 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt debug', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\vrbsr\\.dbt'}
[0m14:12:45.067227 [info ] [MainThread]: dbt version: 1.10.10
[0m14:12:45.067227 [info ] [MainThread]: python version: 3.12.8
[0m14:12:45.067227 [info ] [MainThread]: python path: C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\.venv\Scripts\python.exe
[0m14:12:45.067227 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m14:12:46.331698 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:12:46.333713 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:12:46.333713 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:12:47.353724 [info ] [MainThread]: Using profiles dir at C:\Users\vrbsr\.dbt
[0m14:12:47.353724 [info ] [MainThread]: Using profiles.yml file at C:\Users\vrbsr\.dbt\profiles.yml
[0m14:12:47.353724 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\dbt_project.yml
[0m14:12:47.353724 [info ] [MainThread]: adapter type: databricks
[0m14:12:47.353724 [info ] [MainThread]: adapter version: 1.10.9
[0m14:12:47.488277 [info ] [MainThread]: Configuration:
[0m14:12:47.488277 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:12:47.488277 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:12:47.488277 [info ] [MainThread]: Required dependencies:
[0m14:12:47.488277 [debug] [MainThread]: Executing "git --help"
[0m14:12:47.552339 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:12:47.552339 [debug] [MainThread]: STDERR: "b''"
[0m14:12:47.552339 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:12:47.560366 [info ] [MainThread]: Connection:
[0m14:12:47.560366 [info ] [MainThread]:   host: dbc-4feca71d-1a9e.cloud.databricks.com
[0m14:12:47.560366 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/a0b5cb801f4427bd
[0m14:12:47.560366 [info ] [MainThread]:   catalog: dbt-databricks-proj-dev
[0m14:12:47.560366 [info ] [MainThread]:   schema: default
[0m14:12:47.565881 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:12:48.056700 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=debug) - Creating connection
[0m14:12:48.058707 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m14:12:48.058707 [debug] [MainThread]: Using databricks connection "debug"
[0m14:12:48.058707 [debug] [MainThread]: On debug: select 1 as id
[0m14:12:48.058707 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:12:48.398044 [error] [MainThread]: databricks-sql-connector adapter: ThriftBackend.attempt_request: Exception: %s
[0m14:12:48.435901 [error] [MainThread]: Databricks adapter: Connection(session-id=Unknown) - Exception while trying to create connection: Error during request to server: : Invalid access token.. 
Error properties: attempt=1/30, bounded-retry-delay=None, elapsed-seconds=0.2798178195953369/900.0, error-message=: Invalid access token., http-code=403, method=OpenSession, no-retry-reason=non-retryable error, original-exception=, query-id=None, session-id=None
[0m14:12:48.439109 [debug] [MainThread]: Databricks adapter: Exception while trying to execute query
select 1 as id
: Database Error
  Error during request to server: : Invalid access token.. 
[0m14:12:48.439109 [debug] [MainThread]: On debug: No close available on handle
[0m14:12:48.439109 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m14:12:48.439109 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:12:48.443337 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  Database Error
    Error during request to server: : Invalid access token.. 

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m14:12:48.443337 [debug] [MainThread]: Command `dbt debug` failed at 14:12:48.443337 after 3.67 seconds
[0m14:12:48.446514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215101A5070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002153FBA03E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215104DDA30>]}
[0m14:12:48.446514 [debug] [MainThread]: Flushing usage events
[0m14:12:48.894116 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:49:03.568806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D46923D4F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D46C164920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D46C165E20>]}


============================== 14:49:03.579515 | c98e173a-8e19-4d9b-bd72-8046e0e7919d ==============================
[0m14:49:03.579515 [info ] [MainThread]: Running with dbt=1.10.10
[0m14:49:03.579515 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt init', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\vrbsr\\.dbt'}
[0m14:49:03.617375 [info ] [MainThread]: Setting up your profile.
[0m14:49:16.036513 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:49:16.036513 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:49:16.036513 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:51:50.182839 [info ] [MainThread]: Profile dbt_databricks_proj written to C:\Users\vrbsr\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m14:51:50.182839 [debug] [MainThread]: Command `dbt init` succeeded at 14:51:50.182839 after 166.83 seconds
[0m14:51:50.193265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D41C011A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D41BF27E00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D41A0C5A90>]}
[0m14:51:50.193265 [debug] [MainThread]: Flushing usage events
[0m14:51:50.694231 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:52:01.904862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F99EA9340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F99D1FD40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F99D1F3E0>]}


============================== 14:52:01.923928 | c2c0f7ec-7f8b-4ac7-9716-0a1ff7d05ba5 ==============================
[0m14:52:01.923928 [info ] [MainThread]: Running with dbt=1.10.10
[0m14:52:01.923928 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt debug', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\vrbsr\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m14:52:01.957595 [info ] [MainThread]: dbt version: 1.10.10
[0m14:52:01.961428 [info ] [MainThread]: python version: 3.12.8
[0m14:52:01.961428 [info ] [MainThread]: python path: C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\.venv\Scripts\python.exe
[0m14:52:01.961428 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m14:52:03.280407 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:52:03.280407 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:52:03.280407 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:52:04.390014 [info ] [MainThread]: Using profiles dir at C:\Users\vrbsr\.dbt
[0m14:52:04.390014 [info ] [MainThread]: Using profiles.yml file at C:\Users\vrbsr\.dbt\profiles.yml
[0m14:52:04.390014 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\dbt_project.yml
[0m14:52:04.396684 [info ] [MainThread]: adapter type: databricks
[0m14:52:04.396684 [info ] [MainThread]: adapter version: 1.10.9
[0m14:52:04.538527 [info ] [MainThread]: Configuration:
[0m14:52:04.538527 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:52:04.538527 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:52:04.538527 [info ] [MainThread]: Required dependencies:
[0m14:52:04.538527 [debug] [MainThread]: Executing "git --help"
[0m14:52:04.590052 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:52:04.590052 [debug] [MainThread]: STDERR: "b''"
[0m14:52:04.590052 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:52:04.590052 [info ] [MainThread]: Connection:
[0m14:52:04.590052 [info ] [MainThread]:   host: dbc-4feca71d-1a9e.cloud.databricks.com
[0m14:52:04.590052 [info ] [MainThread]:   http_path: /sql/1.0/warehouses/a0b5cb801f4427bd
[0m14:52:04.590052 [info ] [MainThread]:   catalog: dbt-databricks-proj-dev
[0m14:52:04.590052 [info ] [MainThread]:   schema: default
[0m14:52:04.590052 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:52:05.086666 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=debug) - Creating connection
[0m14:52:05.086666 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m14:52:05.086666 [debug] [MainThread]: Using databricks connection "debug"
[0m14:52:05.086666 [debug] [MainThread]: On debug: select 1 as id
[0m14:52:05.086666 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:52:05.576376 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0869b-956e-1965-8715-ac29dc06ee92) - Created
[0m14:52:17.986743 [debug] [MainThread]: SQL status: OK in 12.900 seconds
[0m14:52:17.989067 [debug] [MainThread]: Databricks adapter: Cursor(session-id=01f0869b-956e-1965-8715-ac29dc06ee92, command-id=01f0869b-958e-1141-a069-b639e668ead3) - Closing
[0m14:52:18.335563 [debug] [MainThread]: On debug: Close
[0m14:52:18.335563 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0869b-956e-1965-8715-ac29dc06ee92) - Closing
[0m14:52:18.421194 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:52:18.427339 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:52:18.428012 [debug] [MainThread]: Command `dbt debug` succeeded at 14:52:18.428012 after 16.78 seconds
[0m14:52:18.429770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F9D2883E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F99CF3CE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022F99CF3080>]}
[0m14:52:18.429770 [debug] [MainThread]: Flushing usage events
[0m14:52:18.843852 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:02:27.077831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002383A168770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002383C0ED1F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002383BD15B80>]}


============================== 15:02:27.085099 | aeac687c-ae97-4b4e-9d34-4cc3faff1b8d ==============================
[0m15:02:27.085099 [info ] [MainThread]: Running with dbt=1.10.10
[0m15:02:27.088120 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\vrbsr\\.dbt', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt ', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'c:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m15:02:27.269075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aeac687c-ae97-4b4e-9d34-4cc3faff1b8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002383CE01C40>]}
[0m15:02:27.332529 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:02:27.335969 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:02:27.335969 [debug] [MainThread]: Command `cli deps` succeeded at 15:02:27.335969 after 0.52 seconds
[0m15:02:27.337862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002383CB32480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002383CEE26F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002383DF88EF0>]}
[0m15:02:27.338372 [debug] [MainThread]: Flushing usage events
[0m15:02:27.810769 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:20:27.671253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232E11FDDF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232E185F140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232E1398C80>]}


============================== 16:20:27.671253 | 64676e9e-5917-4283-8fd1-1a7db5baa1b6 ==============================
[0m16:20:27.671253 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:20:27.671253 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m16:20:28.270991 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:20:28.270991 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:20:28.270991 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:20:28.836957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232FFCB8350>]}
[0m16:20:28.896196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232E1EBDFD0>]}
[0m16:20:28.896196 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:20:29.154153 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m16:20:29.214236 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m16:20:29.214236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232E188B0E0>]}
[0m16:20:30.281030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002329177B4D0>]}
[0m16:20:30.313125 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m16:20:30.328733 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m16:20:30.328733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232928F5DC0>]}
[0m16:20:30.344588 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m16:20:30.344908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002329128B470>]}
[0m16:20:30.345240 [info ] [MainThread]: 
[0m16:20:30.345240 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:20:30.345240 [info ] [MainThread]: 
[0m16:20:30.345240 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:20:30.345240 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:20:30.345240 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m16:20:30.345240 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m16:20:30.345240 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m16:20:30.345240 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m16:20:30.353262 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:20:30.631527 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086a7-ef91-1832-a440-48681a9157b0) - Created
[0m16:20:30.953027 [debug] [ThreadPool]: SQL status: OK in 0.600 seconds
[0m16:20:30.953027 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086a7-ef91-1832-a440-48681a9157b0, command-id=01f086a7-ef9d-159f-82eb-d06b8959bac8) - Closing
[0m16:20:30.953027 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m16:20:30.953027 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086a7-ef91-1832-a440-48681a9157b0) - Closing
[0m16:20:31.049008 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_default) - Creating connection
[0m16:20:31.049008 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_default'
[0m16:20:31.063468 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_default"
[0m16:20:31.063468 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_default: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'default'

  
[0m16:20:31.063468 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:20:31.320787 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086a7-eff7-18b5-9b15-e78b71f0e981) - Created
[0m16:20:31.869631 [debug] [ThreadPool]: SQL status: OK in 0.810 seconds
[0m16:20:31.881343 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086a7-eff7-18b5-9b15-e78b71f0e981, command-id=01f086a7-f005-1e9f-abe4-da4d5f13e73e) - Closing
[0m16:20:31.881343 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_default: Close
[0m16:20:31.881343 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086a7-eff7-18b5-9b15-e78b71f0e981) - Closing
[0m16:20:31.969278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232911D1F40>]}
[0m16:20:31.985027 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_customer
[0m16:20:31.985027 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m16:20:31.985027 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_customer) - Creating connection
[0m16:20:31.985027 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_customer'
[0m16:20:31.985027 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_customer
[0m16:20:31.995629 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_customer"
[0m16:20:31.995629 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_customer
[0m16:20:32.012685 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m16:20:32.013686 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m16:20:32.013686 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023292947500>]}
[0m16:20:32.041918 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_customer"
[0m16:20:32.041918 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_customer"
[0m16:20:32.041918 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_customer"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_customer`
  
[0m16:20:32.041918 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:20:32.252570 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-f08a-171d-91a4-de2aaeeb7b93) - Created
[0m16:20:38.649670 [debug] [Thread-3 (]: SQL status: OK in 6.610 seconds
[0m16:20:38.649670 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086a7-f08a-171d-91a4-de2aaeeb7b93, command-id=01f086a7-f094-1c6a-8bfb-c925660ca26d) - Closing
[0m16:20:38.747209 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:20:38.757241 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_customer: Close
[0m16:20:38.757241 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-f08a-171d-91a4-de2aaeeb7b93) - Closing
[0m16:20:38.832260 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232E11DD280>]}
[0m16:20:38.836100 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 6.85s]
[0m16:20:38.837152 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_customer
[0m16:20:38.837152 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_date
[0m16:20:38.837152 [info ] [Thread-3 (]: 2 of 6 START sql table model default.bronze_date ............................... [RUN]
[0m16:20:38.838162 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_date) - Creating connection
[0m16:20:38.838162 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_date'
[0m16:20:38.838162 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_date
[0m16:20:38.840180 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_date"
[0m16:20:38.841178 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_date
[0m16:20:38.842468 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m16:20:38.843473 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_date"
[0m16:20:38.844473 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_date"
[0m16:20:38.844473 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_date"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`default`.`bronze_date`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_date`
  
[0m16:20:38.844473 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:20:39.082364 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-f49a-14a9-b999-9ff5dbbd2616) - Created
[0m16:20:42.057837 [debug] [Thread-3 (]: SQL status: OK in 3.210 seconds
[0m16:20:42.068072 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086a7-f49a-14a9-b999-9ff5dbbd2616, command-id=01f086a7-f4a7-18ca-b2df-2c2e17035629) - Closing
[0m16:20:42.068072 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:20:42.068072 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_date: Close
[0m16:20:42.068072 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-f49a-14a9-b999-9ff5dbbd2616) - Closing
[0m16:20:42.152243 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232928B0E90>]}
[0m16:20:42.152243 [info ] [Thread-3 (]: 2 of 6 OK created sql table model default.bronze_date .......................... [[32mOK[0m in 3.31s]
[0m16:20:42.152243 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_date
[0m16:20:42.152243 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_product
[0m16:20:42.152243 [info ] [Thread-3 (]: 3 of 6 START sql table model default.bronze_product ............................ [RUN]
[0m16:20:42.164043 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_product) - Creating connection
[0m16:20:42.164043 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_product'
[0m16:20:42.164043 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_product
[0m16:20:42.164043 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_product"
[0m16:20:42.164043 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_product
[0m16:20:42.164043 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m16:20:42.164043 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_product"
[0m16:20:42.164043 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_product"
[0m16:20:42.164043 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_product"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`default`.`bronze_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_product`
  
[0m16:20:42.164043 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:20:42.444296 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-f69b-1972-9268-d590233eda0c) - Created
[0m16:20:45.150520 [debug] [Thread-3 (]: SQL status: OK in 2.990 seconds
[0m16:20:45.150520 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086a7-f69b-1972-9268-d590233eda0c, command-id=01f086a7-f6a7-1bea-8730-8ee3c2f96800) - Closing
[0m16:20:45.150520 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:20:45.150520 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_product: Close
[0m16:20:45.150520 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-f69b-1972-9268-d590233eda0c) - Closing
[0m16:20:45.225803 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232928B3500>]}
[0m16:20:45.225803 [info ] [Thread-3 (]: 3 of 6 OK created sql table model default.bronze_product ....................... [[32mOK[0m in 3.06s]
[0m16:20:45.225803 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_product
[0m16:20:45.234936 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_returns
[0m16:20:45.234936 [info ] [Thread-3 (]: 4 of 6 START sql table model default.bronze_returns ............................ [RUN]
[0m16:20:45.234936 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_returns) - Creating connection
[0m16:20:45.234936 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_returns'
[0m16:20:45.234936 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_returns
[0m16:20:45.234936 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_returns"
[0m16:20:45.234936 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_returns
[0m16:20:45.234936 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m16:20:45.234936 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_returns"
[0m16:20:45.234936 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_returns"
[0m16:20:45.234936 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_returns"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`default`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`fact_returns`
  
[0m16:20:45.234936 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:20:45.448982 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-f869-18e5-b17e-ce86f5ed2a27) - Created
[0m16:20:47.696924 [debug] [Thread-3 (]: SQL status: OK in 2.460 seconds
[0m16:20:47.696924 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086a7-f869-18e5-b17e-ce86f5ed2a27, command-id=01f086a7-f873-1f92-8c3a-6a4d903c1f56) - Closing
[0m16:20:47.696924 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:20:47.696924 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_returns: Close
[0m16:20:47.696924 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-f869-18e5-b17e-ce86f5ed2a27) - Closing
[0m16:20:47.776800 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023292929940>]}
[0m16:20:47.776800 [info ] [Thread-3 (]: 4 of 6 OK created sql table model default.bronze_returns ....................... [[32mOK[0m in 2.53s]
[0m16:20:47.776800 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_returns
[0m16:20:47.776800 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_sales
[0m16:20:47.776800 [info ] [Thread-3 (]: 5 of 6 START sql table model default.bronze_sales .............................. [RUN]
[0m16:20:47.776800 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_sales) - Creating connection
[0m16:20:47.776800 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_sales'
[0m16:20:47.776800 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_sales
[0m16:20:47.776800 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_sales"
[0m16:20:47.776800 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_sales
[0m16:20:47.776800 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m16:20:47.776800 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_sales"
[0m16:20:47.776800 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_sales"
[0m16:20:47.776800 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_sales"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`default`.`bronze_sales`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`fact_sales`
  
[0m16:20:47.776800 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:20:48.022267 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-f9f1-1255-a0b2-d17f09fde56d) - Created
[0m16:20:50.201140 [debug] [Thread-3 (]: SQL status: OK in 2.420 seconds
[0m16:20:50.201140 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086a7-f9f1-1255-a0b2-d17f09fde56d, command-id=01f086a7-f9fa-1d10-8dc0-c7c0448fb133) - Closing
[0m16:20:50.201140 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:20:50.201140 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_sales: Close
[0m16:20:50.201140 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-f9f1-1255-a0b2-d17f09fde56d) - Closing
[0m16:20:50.285878 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232928CE150>]}
[0m16:20:50.285878 [info ] [Thread-3 (]: 5 of 6 OK created sql table model default.bronze_sales ......................... [[32mOK[0m in 2.51s]
[0m16:20:50.291338 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_sales
[0m16:20:50.291338 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_store
[0m16:20:50.291338 [info ] [Thread-3 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m16:20:50.291338 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_store) - Creating connection
[0m16:20:50.291338 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_store'
[0m16:20:50.291338 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_store
[0m16:20:50.295182 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_store"
[0m16:20:50.297186 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_store
[0m16:20:50.297186 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m16:20:50.297186 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_store"
[0m16:20:50.301620 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_store"
[0m16:20:50.301620 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_store"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_store`
  
[0m16:20:50.301620 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:20:50.526106 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-fb6c-1d30-ab48-fd4da8a64829) - Created
[0m16:20:53.058243 [debug] [Thread-3 (]: SQL status: OK in 2.760 seconds
[0m16:20:53.058243 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086a7-fb6c-1d30-ab48-fd4da8a64829, command-id=01f086a7-fb78-1410-adea-b2bc23cf599c) - Closing
[0m16:20:53.058243 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:20:53.061196 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_store: Close
[0m16:20:53.061196 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086a7-fb6c-1d30-ab48-fd4da8a64829) - Closing
[0m16:20:53.159737 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64676e9e-5917-4283-8fd1-1a7db5baa1b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232929AACF0>]}
[0m16:20:53.160258 [info ] [Thread-3 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 2.87s]
[0m16:20:53.160778 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_store
[0m16:20:53.162327 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:20:53.162855 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:20:53.163388 [info ] [MainThread]: 
[0m16:20:53.163920 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 22.82 seconds (22.82s).
[0m16:20:53.164988 [debug] [MainThread]: Command end result
[0m16:20:53.174194 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m16:20:53.174194 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m16:20:53.190415 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m16:20:53.190415 [info ] [MainThread]: 
[0m16:20:53.190415 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:20:53.190415 [info ] [MainThread]: 
[0m16:20:53.191415 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m16:20:53.191415 [debug] [MainThread]: Command `dbt run` succeeded at 16:20:53.191415 after 25.60 seconds
[0m16:20:53.192417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232E198EDE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232E1398C80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232E185F140>]}
[0m16:20:53.192417 [debug] [MainThread]: Flushing usage events
[0m16:20:53.492643 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:26:36.704194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BF26F8E570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BF2474B500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BF26EB6AB0>]}


============================== 16:26:36.704194 | 173f7ea2-c493-43e4-823f-27e169b5f7b3 ==============================
[0m16:26:36.704194 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:26:36.704194 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt clean', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'printer_width': '80', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj'}
[0m16:26:36.791759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '173f7ea2-c493-43e4-823f-27e169b5f7b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BF26FDFD40>]}
[0m16:26:36.820236 [debug] [MainThread]: Command `dbt clean` succeeded at 16:26:36.820236 after 0.21 seconds
[0m16:26:36.820673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BF2682DD30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BF2420C590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BF26FDFD40>]}
[0m16:26:36.821413 [debug] [MainThread]: Flushing usage events
[0m16:26:37.141927 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:36:48.323662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCBDF1F6E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC047DB80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC047FE90>]}


============================== 16:36:48.325624 | c3fc5087-0804-4595-bfaf-738628cfaf6f ==============================
[0m16:36:48.325624 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:36:48.325624 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'quiet': 'False', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m16:36:48.995939 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:36:48.995939 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:36:48.995939 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:36:49.615898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCEF657EF0>]}
[0m16:36:49.669914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCEFD64500>]}
[0m16:36:49.670921 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:36:49.975808 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m16:36:50.047679 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m16:36:50.047679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF08054F0>]}
[0m16:36:51.370851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF0985550>]}
[0m16:36:51.426835 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m16:36:51.432243 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m16:36:51.442168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF1B15190>]}
[0m16:36:51.442687 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m16:36:51.443482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF1AA1DC0>]}
[0m16:36:51.443482 [info ] [MainThread]: 
[0m16:36:51.443482 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:36:51.443482 [info ] [MainThread]: 
[0m16:36:51.443482 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:36:51.445991 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:36:51.445991 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m16:36:51.445991 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m16:36:51.445991 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m16:36:51.445991 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m16:36:51.445991 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:36:52.041577 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086aa-386e-1f76-896e-283b5c280706) - Created
[0m16:37:53.360762 [debug] [ThreadPool]: SQL status: OK in 61.910 seconds
[0m16:37:53.366280 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086aa-386e-1f76-896e-283b5c280706, command-id=01f086aa-5c67-145c-8738-7dd6c372716a) - Closing
[0m16:37:53.367288 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m16:37:53.368287 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086aa-386e-1f76-896e-283b5c280706) - Closing
[0m16:37:53.458744 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_default) - Creating connection
[0m16:37:53.459745 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_default'
[0m16:37:53.495885 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_default"
[0m16:37:53.496921 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_default: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'default'

  
[0m16:37:53.497910 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:37:53.974751 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086aa-5d70-1c0f-a04f-0ae642c1567f) - Created
[0m16:37:57.165908 [debug] [ThreadPool]: SQL status: OK in 3.670 seconds
[0m16:37:57.180625 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086aa-5d70-1c0f-a04f-0ae642c1567f, command-id=01f086aa-5d7e-1e67-9379-1c364d568395) - Closing
[0m16:37:57.183641 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_default: Close
[0m16:37:57.184640 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086aa-5d70-1c0f-a04f-0ae642c1567f) - Closing
[0m16:37:57.310668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF03E1AC0>]}
[0m16:37:57.322275 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_customer
[0m16:37:57.323273 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m16:37:57.327987 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_customer) - Creating connection
[0m16:37:57.330433 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_customer'
[0m16:37:57.331439 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_customer
[0m16:37:57.354349 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_customer"
[0m16:37:57.362578 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_customer
[0m16:37:57.405152 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m16:37:57.406664 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m16:37:57.408692 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF1ADC590>]}
[0m16:37:57.516062 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_customer"
[0m16:37:57.524910 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_customer"
[0m16:37:57.526440 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_customer"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_customer`
  
[0m16:37:57.527453 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:37:57.897760 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-5fc7-1efb-addf-ff4365518225) - Created
[0m16:38:08.896533 [debug] [Thread-3 (]: SQL status: OK in 11.370 seconds
[0m16:38:08.896533 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086aa-5fc7-1efb-addf-ff4365518225, command-id=01f086aa-5fd5-161d-8d29-56e9294c0b0d) - Closing
[0m16:38:09.016000 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:38:09.038930 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_customer: Close
[0m16:38:09.038930 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-5fc7-1efb-addf-ff4365518225) - Closing
[0m16:38:09.129819 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCBE01B9E0>]}
[0m16:38:09.129819 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 11.80s]
[0m16:38:09.136439 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_customer
[0m16:38:09.136977 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_date
[0m16:38:09.136977 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m16:38:09.139154 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_date) - Creating connection
[0m16:38:09.139154 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_date'
[0m16:38:09.139154 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_date
[0m16:38:09.146026 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_date"
[0m16:38:09.147447 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_date
[0m16:38:09.168459 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m16:38:09.181301 [debug] [Thread-3 (]: Dropping relation `dbt_databricks_proj_dev`.`default`.`bronze_date` because it is of type table
[0m16:38:09.189224 [debug] [Thread-3 (]: Applying DROP to: `dbt_databricks_proj_dev`.`default`.`bronze_date`
[0m16:38:09.200964 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_date"
[0m16:38:09.200964 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_date"} */
drop table if exists `dbt_databricks_proj_dev`.`default`.`bronze_date`
[0m16:38:09.203768 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:38:09.525935 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-66b5-1eb9-9422-2d300baba89d) - Created
[0m16:38:10.048683 [debug] [Thread-3 (]: SQL status: OK in 0.840 seconds
[0m16:38:10.050262 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086aa-66b5-1eb9-9422-2d300baba89d, command-id=01f086aa-66c3-1946-a4c0-f924b0ebadd4) - Closing
[0m16:38:10.065006 [debug] [Thread-3 (]: Creating view `dbt_databricks_proj_dev`.`default`.`bronze_date`
[0m16:38:10.066224 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_date"
[0m16:38:10.067229 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_date"
[0m16:38:10.067229 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_date"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`default`.`bronze_date`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`dim_date`
  )

[0m16:38:10.640575 [debug] [Thread-3 (]: SQL status: OK in 0.570 seconds
[0m16:38:10.640575 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086aa-66b5-1eb9-9422-2d300baba89d, command-id=01f086aa-6716-189c-9e3d-fe2386319f8a) - Closing
[0m16:38:10.642614 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:38:10.647957 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_date: Close
[0m16:38:10.650690 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-66b5-1eb9-9422-2d300baba89d) - Closing
[0m16:38:10.740683 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF1C274D0>]}
[0m16:38:10.740683 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 1.60s]
[0m16:38:10.740683 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_date
[0m16:38:10.740683 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_product
[0m16:38:10.745304 [info ] [Thread-3 (]: 3 of 6 START sql view model default.bronze_product ............................. [RUN]
[0m16:38:10.745815 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_product) - Creating connection
[0m16:38:10.745815 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_product'
[0m16:38:10.745815 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_product
[0m16:38:10.745815 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_product"
[0m16:38:10.753397 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_product
[0m16:38:10.756313 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m16:38:10.758877 [debug] [Thread-3 (]: Dropping relation `dbt_databricks_proj_dev`.`default`.`bronze_product` because it is of type table
[0m16:38:10.763453 [debug] [Thread-3 (]: Applying DROP to: `dbt_databricks_proj_dev`.`default`.`bronze_product`
[0m16:38:10.765428 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_product"
[0m16:38:10.765947 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_product"} */
drop table if exists `dbt_databricks_proj_dev`.`default`.`bronze_product`
[0m16:38:10.765947 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:38:11.026184 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-679e-15fe-8f09-6565f5070ffb) - Created
[0m16:38:11.641790 [debug] [Thread-3 (]: SQL status: OK in 0.880 seconds
[0m16:38:11.643321 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086aa-679e-15fe-8f09-6565f5070ffb, command-id=01f086aa-67a9-10e4-ba35-e08658ec8a8e) - Closing
[0m16:38:11.645858 [debug] [Thread-3 (]: Creating view `dbt_databricks_proj_dev`.`default`.`bronze_product`
[0m16:38:11.645858 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_product"
[0m16:38:11.651896 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_product"
[0m16:38:11.653909 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_product"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`default`.`bronze_product`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`dim_product`
  )

[0m16:38:12.015970 [debug] [Thread-3 (]: SQL status: OK in 0.360 seconds
[0m16:38:12.024472 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086aa-679e-15fe-8f09-6565f5070ffb, command-id=01f086aa-6808-1573-acc4-ef9de3e5b824) - Closing
[0m16:38:12.025979 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:38:12.025979 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_product: Close
[0m16:38:12.028047 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-679e-15fe-8f09-6565f5070ffb) - Closing
[0m16:38:12.122827 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF1BADEB0>]}
[0m16:38:12.122827 [info ] [Thread-3 (]: 3 of 6 OK created sql view model default.bronze_product ........................ [[32mOK[0m in 1.38s]
[0m16:38:12.125907 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_product
[0m16:38:12.127012 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_returns
[0m16:38:12.127012 [info ] [Thread-3 (]: 4 of 6 START sql table model default.bronze_returns ............................ [RUN]
[0m16:38:12.129028 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_returns) - Creating connection
[0m16:38:12.129028 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_returns'
[0m16:38:12.130783 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_returns
[0m16:38:12.131146 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_returns"
[0m16:38:12.139238 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_returns
[0m16:38:12.142299 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m16:38:12.145667 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_returns"
[0m16:38:12.147779 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_returns"
[0m16:38:12.147779 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_returns"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`default`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`fact_returns`
  
[0m16:38:12.147779 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:38:12.405979 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-6871-178b-9402-a693afee9d15) - Created
[0m16:38:14.759924 [debug] [Thread-3 (]: SQL status: OK in 2.610 seconds
[0m16:38:14.763924 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086aa-6871-178b-9402-a693afee9d15, command-id=01f086aa-687b-1c4a-beb8-b79db5d5a961) - Closing
[0m16:38:14.768195 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:38:14.773207 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_returns: Close
[0m16:38:14.774208 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-6871-178b-9402-a693afee9d15) - Closing
[0m16:38:14.860832 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF1C2DFD0>]}
[0m16:38:14.862833 [info ] [Thread-3 (]: 4 of 6 OK created sql table model default.bronze_returns ....................... [[32mOK[0m in 2.73s]
[0m16:38:14.864832 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_returns
[0m16:38:14.866343 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_sales
[0m16:38:14.867346 [info ] [Thread-3 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m16:38:14.869345 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_sales) - Creating connection
[0m16:38:14.870345 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_sales'
[0m16:38:14.871344 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_sales
[0m16:38:14.897323 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_sales"
[0m16:38:14.901336 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_sales
[0m16:38:14.910904 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m16:38:14.915882 [debug] [Thread-3 (]: Dropping relation `dbt_databricks_proj_dev`.`default`.`bronze_sales` because it is of type table
[0m16:38:14.925830 [debug] [Thread-3 (]: Applying DROP to: `dbt_databricks_proj_dev`.`default`.`bronze_sales`
[0m16:38:14.929244 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_sales"
[0m16:38:14.930242 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_sales"} */
drop table if exists `dbt_databricks_proj_dev`.`default`.`bronze_sales`
[0m16:38:14.932243 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:38:15.314136 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-6a2a-13c6-859c-6bba21da5d35) - Created
[0m16:38:15.734043 [debug] [Thread-3 (]: SQL status: OK in 0.800 seconds
[0m16:38:15.737572 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086aa-6a2a-13c6-859c-6bba21da5d35, command-id=01f086aa-6a37-135c-b628-e8d1ef47719c) - Closing
[0m16:38:15.741543 [debug] [Thread-3 (]: Creating view `dbt_databricks_proj_dev`.`default`.`bronze_sales`
[0m16:38:15.743544 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_sales"
[0m16:38:15.746808 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_sales"
[0m16:38:15.747807 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_sales"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`default`.`bronze_sales`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`fact_sales`
  )

[0m16:38:16.190843 [debug] [Thread-3 (]: SQL status: OK in 0.440 seconds
[0m16:38:16.196015 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086aa-6a2a-13c6-859c-6bba21da5d35, command-id=01f086aa-6a79-1124-ba4b-ce81074915a8) - Closing
[0m16:38:16.198382 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:38:16.201378 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_sales: Close
[0m16:38:16.201378 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-6a2a-13c6-859c-6bba21da5d35) - Closing
[0m16:38:16.290491 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF1C3B920>]}
[0m16:38:16.292922 [info ] [Thread-3 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 1.42s]
[0m16:38:16.295925 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_sales
[0m16:38:16.297421 [debug] [Thread-3 (]: Began running node model.dbt_databricks_proj.bronze_store
[0m16:38:16.298432 [info ] [Thread-3 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m16:38:16.300430 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_store) - Creating connection
[0m16:38:16.301793 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_store'
[0m16:38:16.302808 [debug] [Thread-3 (]: Began compiling node model.dbt_databricks_proj.bronze_store
[0m16:38:16.317009 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_store"
[0m16:38:16.320024 [debug] [Thread-3 (]: Began executing node model.dbt_databricks_proj.bronze_store
[0m16:38:16.328586 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m16:38:16.337313 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_store"
[0m16:38:16.343533 [debug] [Thread-3 (]: Using databricks connection "model.dbt_databricks_proj.bronze_store"
[0m16:38:16.344533 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_store"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_store`
  
[0m16:38:16.346040 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:38:16.707054 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-6b00-1249-a1fa-0bf216e09678) - Created
[0m16:38:19.775903 [debug] [Thread-3 (]: SQL status: OK in 3.420 seconds
[0m16:38:19.775903 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086aa-6b00-1249-a1fa-0bf216e09678, command-id=01f086aa-6b0b-1d7f-94b4-d05aaa2b7ca3) - Closing
[0m16:38:19.778508 [debug] [Thread-3 (]: Applying tags to relation None
[0m16:38:19.780763 [debug] [Thread-3 (]: On model.dbt_databricks_proj.bronze_store: Close
[0m16:38:19.780763 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086aa-6b00-1249-a1fa-0bf216e09678) - Closing
[0m16:38:19.861024 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3fc5087-0804-4595-bfaf-738628cfaf6f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF1C0C4A0>]}
[0m16:38:19.861024 [info ] [Thread-3 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 3.56s]
[0m16:38:19.865912 [debug] [Thread-3 (]: Finished running node model.dbt_databricks_proj.bronze_store
[0m16:38:19.865912 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:38:19.865912 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:38:19.865912 [info ] [MainThread]: 
[0m16:38:19.865912 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 1 minutes and 28.42 seconds (88.42s).
[0m16:38:19.872397 [debug] [MainThread]: Command end result
[0m16:38:19.911143 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m16:38:19.916012 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m16:38:19.923126 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m16:38:19.923126 [info ] [MainThread]: 
[0m16:38:19.925780 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:38:19.926824 [info ] [MainThread]: 
[0m16:38:19.926824 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m16:38:19.928588 [debug] [MainThread]: Command `dbt run` succeeded at 16:38:19.928588 after 91.70 seconds
[0m16:38:19.930554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC0B427E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCF07165A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DCC045F3B0>]}
[0m16:38:19.930554 [debug] [MainThread]: Flushing usage events
[0m16:38:20.416067 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:57:53.860811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7AAD36D50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7AAB7EAB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7AAB7F290>]}


============================== 16:57:53.868623 | c8efe68b-1ba7-40c0-b954-015a2d08f9f8 ==============================
[0m16:57:53.868623 [info ] [MainThread]: Running with dbt=1.10.10
[0m16:57:53.868623 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj'}
[0m16:57:54.999299 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:57:54.999299 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:57:54.999299 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:57:55.963585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7ADD48A10>]}
[0m16:57:56.038156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7D831F1D0>]}
[0m16:57:56.038156 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:57:56.538548 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m16:57:56.618336 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m16:57:56.624403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7D8197B30>]}
[0m16:57:58.752775 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_databricks_proj.silver
- models.dbt_databricks_proj.gold
[0m16:57:58.770912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7DA71D190>]}
[0m16:57:58.858662 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m16:57:58.863083 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m16:57:58.883462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7DBBECAD0>]}
[0m16:57:58.884897 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m16:57:58.884897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7DBC1EE40>]}
[0m16:57:58.888248 [info ] [MainThread]: 
[0m16:57:58.889998 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:57:58.891899 [info ] [MainThread]: 
[0m16:57:58.891899 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:57:58.891899 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:57:58.904296 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m16:57:58.904296 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m16:57:58.904296 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m16:57:58.904296 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m16:57:58.906309 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:57:59.638577 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ad-2bf0-1380-ad3d-520f8bfc04c1) - Created
[0m16:59:01.191112 [debug] [ThreadPool]: SQL status: OK in 62.280 seconds
[0m16:59:01.195112 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086ad-2bf0-1380-ad3d-520f8bfc04c1, command-id=01f086ad-4ff4-1e77-aa3d-51d1ce5aced2) - Closing
[0m16:59:01.195112 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m16:59:01.196782 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ad-2bf0-1380-ad3d-520f8bfc04c1) - Closing
[0m16:59:01.274392 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_databricks_proj_dev_bronze) - Creating connection
[0m16:59:01.278396 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_databricks_proj_dev_bronze'
[0m16:59:01.281218 [debug] [ThreadPool]: Creating schema "database: "dbt_databricks_proj_dev"
schema: "bronze"
"
[0m16:59:01.294985 [debug] [ThreadPool]: Using databricks connection "create_dbt_databricks_proj_dev_bronze"
[0m16:59:01.294985 [debug] [ThreadPool]: On create_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "create_dbt_databricks_proj_dev_bronze"} */
create schema if not exists `dbt_databricks_proj_dev`.`bronze`
  
[0m16:59:01.298295 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:59:01.638249 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ad-5108-117d-8383-3d0be0aa2d5c) - Created
[0m16:59:03.023943 [debug] [ThreadPool]: SQL status: OK in 1.720 seconds
[0m16:59:03.023943 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086ad-5108-117d-8383-3d0be0aa2d5c, command-id=01f086ad-5115-1ce8-9715-cbd973857463) - Closing
[0m16:59:03.025970 [debug] [ThreadPool]: On create_dbt_databricks_proj_dev_bronze: Close
[0m16:59:03.025970 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ad-5108-117d-8383-3d0be0aa2d5c) - Closing
[0m16:59:03.120823 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m16:59:03.120823 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m16:59:03.132153 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m16:59:03.134773 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m16:59:03.134773 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:59:03.418171 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ad-5217-1872-b4af-aade3aa10b35) - Created
[0m16:59:05.179515 [debug] [ThreadPool]: SQL status: OK in 2.040 seconds
[0m16:59:05.195408 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086ad-5217-1872-b4af-aade3aa10b35, command-id=01f086ad-5224-1a4c-bfa3-ddff7d7802f7) - Closing
[0m16:59:05.198389 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m16:59:05.198389 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ad-5217-1872-b4af-aade3aa10b35) - Closing
[0m16:59:05.296890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7DA7EE0F0>]}
[0m16:59:05.315975 [debug] [Thread-4 (]: Began running node model.dbt_databricks_proj.bronze_customer
[0m16:59:05.319090 [info ] [Thread-4 (]: 1 of 6 START sql table model bronze.bronze_customer ............................ [RUN]
[0m16:59:05.320174 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_customer) - Creating connection
[0m16:59:05.320174 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_customer'
[0m16:59:05.320174 [debug] [Thread-4 (]: Began compiling node model.dbt_databricks_proj.bronze_customer
[0m16:59:05.345250 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_customer"
[0m16:59:05.348467 [debug] [Thread-4 (]: Began executing node model.dbt_databricks_proj.bronze_customer
[0m16:59:05.392443 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m16:59:05.397196 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m16:59:05.399683 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7DBABFB60>]}
[0m16:59:05.518418 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_customer"
[0m16:59:05.522514 [debug] [Thread-4 (]: Using databricks connection "model.dbt_databricks_proj.bronze_customer"
[0m16:59:05.523027 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_customer"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_customer`
  
[0m16:59:05.523027 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m16:59:05.868446 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5390-1081-a53d-4a786acef608) - Created
[0m16:59:17.478429 [debug] [Thread-4 (]: SQL status: OK in 11.950 seconds
[0m16:59:17.479915 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f086ad-5390-1081-a53d-4a786acef608, command-id=01f086ad-539a-13e5-bdb4-e044909a5637) - Closing
[0m16:59:17.605927 [debug] [Thread-4 (]: Applying tags to relation None
[0m16:59:17.646785 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_customer: Close
[0m16:59:17.647419 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5390-1081-a53d-4a786acef608) - Closing
[0m16:59:17.748523 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7A80BBEC0>]}
[0m16:59:17.749091 [info ] [Thread-4 (]: 1 of 6 OK created sql table model bronze.bronze_customer ....................... [[32mOK[0m in 12.42s]
[0m16:59:17.751457 [debug] [Thread-4 (]: Finished running node model.dbt_databricks_proj.bronze_customer
[0m16:59:17.755140 [debug] [Thread-4 (]: Began running node model.dbt_databricks_proj.bronze_date
[0m16:59:17.755828 [info ] [Thread-4 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m16:59:17.758341 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_date) - Creating connection
[0m16:59:17.759888 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_date'
[0m16:59:17.759888 [debug] [Thread-4 (]: Began compiling node model.dbt_databricks_proj.bronze_date
[0m16:59:17.768127 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_date"
[0m16:59:17.770149 [debug] [Thread-4 (]: Began executing node model.dbt_databricks_proj.bronze_date
[0m16:59:17.820287 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m16:59:17.850075 [debug] [Thread-4 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_date`
[0m16:59:17.850075 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_date"
[0m16:59:17.855397 [debug] [Thread-4 (]: Using databricks connection "model.dbt_databricks_proj.bronze_date"
[0m16:59:17.856295 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_date"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_date`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`dim_date`
  )

[0m16:59:17.856958 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m16:59:18.212542 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5aeb-183c-b5ae-0ed25fbe0890) - Created
[0m16:59:18.898156 [debug] [Thread-4 (]: SQL status: OK in 1.040 seconds
[0m16:59:18.900205 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f086ad-5aeb-183c-b5ae-0ed25fbe0890, command-id=01f086ad-5af5-1b7f-aa6b-c877810b930f) - Closing
[0m16:59:18.902220 [debug] [Thread-4 (]: Applying tags to relation None
[0m16:59:18.904236 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_date: Close
[0m16:59:18.906252 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5aeb-183c-b5ae-0ed25fbe0890) - Closing
[0m16:59:19.005528 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7DA9FE960>]}
[0m16:59:19.008062 [info ] [Thread-4 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 1.25s]
[0m16:59:19.010626 [debug] [Thread-4 (]: Finished running node model.dbt_databricks_proj.bronze_date
[0m16:59:19.011402 [debug] [Thread-4 (]: Began running node model.dbt_databricks_proj.bronze_product
[0m16:59:19.012815 [info ] [Thread-4 (]: 3 of 6 START sql view model bronze.bronze_product .............................. [RUN]
[0m16:59:19.012815 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_product) - Creating connection
[0m16:59:19.016113 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_product'
[0m16:59:19.016113 [debug] [Thread-4 (]: Began compiling node model.dbt_databricks_proj.bronze_product
[0m16:59:19.030642 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_product"
[0m16:59:19.034418 [debug] [Thread-4 (]: Began executing node model.dbt_databricks_proj.bronze_product
[0m16:59:19.041170 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m16:59:19.045477 [debug] [Thread-4 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
[0m16:59:19.050076 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_product"
[0m16:59:19.054111 [debug] [Thread-4 (]: Using databricks connection "model.dbt_databricks_proj.bronze_product"
[0m16:59:19.054111 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_product"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`dim_product`
  )

[0m16:59:19.056462 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m16:59:19.408026 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5ba1-1c6d-a4c5-41e0c630ad17) - Created
[0m16:59:19.918020 [debug] [Thread-4 (]: SQL status: OK in 0.860 seconds
[0m16:59:19.926324 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f086ad-5ba1-1c6d-a4c5-41e0c630ad17, command-id=01f086ad-5bac-12d9-b75e-4620d82ee90c) - Closing
[0m16:59:19.928336 [debug] [Thread-4 (]: Applying tags to relation None
[0m16:59:19.930451 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_product: Close
[0m16:59:19.932469 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5ba1-1c6d-a4c5-41e0c630ad17) - Closing
[0m16:59:20.009007 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7DBBA8200>]}
[0m16:59:20.012013 [info ] [Thread-4 (]: 3 of 6 OK created sql view model bronze.bronze_product ......................... [[32mOK[0m in 1.00s]
[0m16:59:20.014031 [debug] [Thread-4 (]: Finished running node model.dbt_databricks_proj.bronze_product
[0m16:59:20.016045 [debug] [Thread-4 (]: Began running node model.dbt_databricks_proj.bronze_returns
[0m16:59:20.016045 [info ] [Thread-4 (]: 4 of 6 START sql table model bronze.bronze_returns ............................. [RUN]
[0m16:59:20.018062 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_returns) - Creating connection
[0m16:59:20.020118 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_returns'
[0m16:59:20.020118 [debug] [Thread-4 (]: Began compiling node model.dbt_databricks_proj.bronze_returns
[0m16:59:20.030376 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_returns"
[0m16:59:20.032240 [debug] [Thread-4 (]: Began executing node model.dbt_databricks_proj.bronze_returns
[0m16:59:20.038168 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m16:59:20.045689 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_returns"
[0m16:59:20.049159 [debug] [Thread-4 (]: Using databricks connection "model.dbt_databricks_proj.bronze_returns"
[0m16:59:20.049159 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_returns"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`fact_returns`
  
[0m16:59:20.049159 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m16:59:20.400791 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5c37-1a00-8f00-474e231b6e46) - Created
[0m16:59:23.300585 [debug] [Thread-4 (]: SQL status: OK in 3.250 seconds
[0m16:59:23.304626 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f086ad-5c37-1a00-8f00-474e231b6e46, command-id=01f086ad-5c44-10e8-b800-57d027ee2e7d) - Closing
[0m16:59:23.306642 [debug] [Thread-4 (]: Applying tags to relation None
[0m16:59:23.310970 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_returns: Close
[0m16:59:23.310970 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5c37-1a00-8f00-474e231b6e46) - Closing
[0m16:59:23.378010 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7DBCA0EF0>]}
[0m16:59:23.385995 [info ] [Thread-4 (]: 4 of 6 OK created sql table model bronze.bronze_returns ........................ [[32mOK[0m in 3.36s]
[0m16:59:23.388298 [debug] [Thread-4 (]: Finished running node model.dbt_databricks_proj.bronze_returns
[0m16:59:23.388298 [debug] [Thread-4 (]: Began running node model.dbt_databricks_proj.bronze_sales
[0m16:59:23.388298 [info ] [Thread-4 (]: 5 of 6 START sql view model bronze.bronze_sales ................................ [RUN]
[0m16:59:23.394080 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_sales) - Creating connection
[0m16:59:23.394080 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_sales'
[0m16:59:23.394080 [debug] [Thread-4 (]: Began compiling node model.dbt_databricks_proj.bronze_sales
[0m16:59:23.412891 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_sales"
[0m16:59:23.414058 [debug] [Thread-4 (]: Began executing node model.dbt_databricks_proj.bronze_sales
[0m16:59:23.423359 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m16:59:23.426440 [debug] [Thread-4 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
[0m16:59:23.428224 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_sales"
[0m16:59:23.430298 [debug] [Thread-4 (]: Using databricks connection "model.dbt_databricks_proj.bronze_sales"
[0m16:59:23.432404 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_sales"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`fact_sales`
  )

[0m16:59:23.432404 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m16:59:23.795953 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5e3d-1ef0-91af-d2691f9cb3ad) - Created
[0m16:59:24.530303 [debug] [Thread-4 (]: SQL status: OK in 1.100 seconds
[0m16:59:24.534678 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f086ad-5e3d-1ef0-91af-d2691f9cb3ad, command-id=01f086ad-5e49-18c6-8d3a-7594bcb800e1) - Closing
[0m16:59:24.536780 [debug] [Thread-4 (]: Applying tags to relation None
[0m16:59:24.538251 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_sales: Close
[0m16:59:24.538251 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5e3d-1ef0-91af-d2691f9cb3ad) - Closing
[0m16:59:24.631243 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7DBD15940>]}
[0m16:59:24.632781 [info ] [Thread-4 (]: 5 of 6 OK created sql view model bronze.bronze_sales ........................... [[32mOK[0m in 1.24s]
[0m16:59:24.632781 [debug] [Thread-4 (]: Finished running node model.dbt_databricks_proj.bronze_sales
[0m16:59:24.632781 [debug] [Thread-4 (]: Began running node model.dbt_databricks_proj.bronze_store
[0m16:59:24.637504 [info ] [Thread-4 (]: 6 of 6 START sql table model bronze.bronze_store ............................... [RUN]
[0m16:59:24.638516 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_store) - Creating connection
[0m16:59:24.638516 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_store'
[0m16:59:24.641101 [debug] [Thread-4 (]: Began compiling node model.dbt_databricks_proj.bronze_store
[0m16:59:24.649287 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_store"
[0m16:59:24.658440 [debug] [Thread-4 (]: Began executing node model.dbt_databricks_proj.bronze_store
[0m16:59:24.673613 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m16:59:24.678224 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_store"
[0m16:59:24.681746 [debug] [Thread-4 (]: Using databricks connection "model.dbt_databricks_proj.bronze_store"
[0m16:59:24.683762 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_store"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_store`
  
[0m16:59:24.683762 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m16:59:25.032668 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5efc-1506-92e4-b8d29b96a628) - Created
[0m16:59:27.915155 [debug] [Thread-4 (]: SQL status: OK in 3.230 seconds
[0m16:59:27.918379 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f086ad-5efc-1506-92e4-b8d29b96a628, command-id=01f086ad-5f06-146d-88d2-342d185780d0) - Closing
[0m16:59:27.918379 [debug] [Thread-4 (]: Applying tags to relation None
[0m16:59:27.923830 [debug] [Thread-4 (]: On model.dbt_databricks_proj.bronze_store: Close
[0m16:59:27.925852 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f086ad-5efc-1506-92e4-b8d29b96a628) - Closing
[0m16:59:28.008121 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8efe68b-1ba7-40c0-b954-015a2d08f9f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7DBD10110>]}
[0m16:59:28.008121 [info ] [Thread-4 (]: 6 of 6 OK created sql table model bronze.bronze_store .......................... [[32mOK[0m in 3.37s]
[0m16:59:28.014979 [debug] [Thread-4 (]: Finished running node model.dbt_databricks_proj.bronze_store
[0m16:59:28.018014 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:59:28.018014 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:59:28.018014 [info ] [MainThread]: 
[0m16:59:28.018014 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 1 minutes and 29.13 seconds (89.13s).
[0m16:59:28.027150 [debug] [MainThread]: Command end result
[0m16:59:28.108044 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m16:59:28.114934 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m16:59:28.130680 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m16:59:28.130680 [info ] [MainThread]: 
[0m16:59:28.130680 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:59:28.136225 [info ] [MainThread]: 
[0m16:59:28.138338 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m16:59:28.138338 [debug] [MainThread]: Command `dbt run` succeeded at 16:59:28.138338 after 94.47 seconds
[0m16:59:28.138338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7A7EDC530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7DBA9E480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7AABABEF0>]}
[0m16:59:28.138338 [debug] [MainThread]: Flushing usage events
[0m16:59:29.019702 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:34:03.569121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F1FE2FB60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F1C8FF590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F1C98C590>]}


============================== 18:34:03.579358 | 1e40b533-a83a-49c5-a160-560608681d7a ==============================
[0m18:34:03.579358 [info ] [MainThread]: Running with dbt=1.10.10
[0m18:34:03.579358 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj'}
[0m18:34:04.769045 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:34:04.769835 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:34:04.769835 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:34:05.755587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e40b533-a83a-49c5-a160-560608681d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F4EF13E60>]}
[0m18:34:05.826258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1e40b533-a83a-49c5-a160-560608681d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F4F7B3380>]}
[0m18:34:05.826258 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m18:34:06.255717 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m18:34:06.369230 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:34:06.369230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1e40b533-a83a-49c5-a160-560608681d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F1FE5B440>]}
[0m18:34:08.686091 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_databricks_proj.gold
- models.dbt_databricks_proj.silver
[0m18:34:08.699036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e40b533-a83a-49c5-a160-560608681d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F50E5EE70>]}
[0m18:34:08.802258 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m18:34:08.812700 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m18:34:09.009422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e40b533-a83a-49c5-a160-560608681d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F50E5D340>]}
[0m18:34:09.009422 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m18:34:09.015348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e40b533-a83a-49c5-a160-560608681d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F50D10CB0>]}
[0m18:34:09.020680 [info ] [MainThread]: 
[0m18:34:09.023037 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:34:09.023037 [info ] [MainThread]: 
[0m18:34:09.023037 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m18:34:09.026260 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m18:34:09.038107 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m18:34:09.040090 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m18:34:09.055826 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m18:34:09.055826 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m18:34:09.055826 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:34:09.449400 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ba-9b1e-1604-8168-606563085e74) - Created
[0m18:34:10.797698 [debug] [ThreadPool]: SQL status: OK in 1.740 seconds
[0m18:34:10.805417 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086ba-9b1e-1604-8168-606563085e74, command-id=01f086ba-9b32-154b-a258-8ff3ab0ca454) - Closing
[0m18:34:10.807429 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m18:34:10.807429 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ba-9b1e-1604-8168-606563085e74) - Closing
[0m18:34:10.889232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e40b533-a83a-49c5-a160-560608681d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F50EBBFE0>]}
[0m18:34:10.896920 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:34:10.897501 [info ] [Thread-2 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m18:34:10.899012 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m18:34:10.899012 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m18:34:10.899012 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:34:10.919789 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m18:34:10.919789 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:34:10.949146 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m18:34:10.951881 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m18:34:10.951881 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m18:34:10.951881 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:34:11.234414 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086ba-9c2c-1603-b9e0-26de30bfe75a) - Created
[0m18:34:12.561440 [debug] [Thread-2 (]: SQL status: OK in 1.610 seconds
[0m18:34:12.563512 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086ba-9c2c-1603-b9e0-26de30bfe75a, command-id=01f086ba-9c3b-1f65-8019-23db68978e11) - Closing
[0m18:34:12.568239 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m18:34:12.569253 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086ba-9c2c-1603-b9e0-26de30bfe75a) - Closing
[0m18:34:12.650649 [info ] [Thread-2 (]: 1 of 5 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 1.75s]
[0m18:34:12.653198 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:34:12.653198 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:34:12.654209 [info ] [Thread-2 (]: 2 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m18:34:12.654209 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m18:34:12.654209 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m18:34:12.656452 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:34:12.670378 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:34:12.675271 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:34:12.679658 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:34:12.681047 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:34:12.682067 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m18:34:12.682067 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:34:12.953410 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086ba-9d37-198d-9d46-ba176a834da1) - Created
[0m18:34:13.661420 [debug] [Thread-2 (]: SQL status: OK in 0.980 seconds
[0m18:34:13.664435 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086ba-9d37-198d-9d46-ba176a834da1, command-id=01f086ba-9d42-1dad-b7b3-655f8d27174c) - Closing
[0m18:34:13.664435 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m18:34:13.664435 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086ba-9d37-198d-9d46-ba176a834da1) - Closing
[0m18:34:13.750532 [info ] [Thread-2 (]: 2 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.10s]
[0m18:34:13.750532 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:34:13.759065 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:34:13.759065 [info ] [Thread-2 (]: 3 of 5 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m18:34:13.759065 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m18:34:13.759065 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m18:34:13.759065 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:34:13.769441 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:34:13.769441 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:34:13.779487 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:34:13.779487 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:34:13.779487 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m18:34:13.779487 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:34:14.041102 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086ba-9ddd-176e-aef1-37cf8ef0a414) - Created
[0m18:34:14.686727 [debug] [Thread-2 (]: SQL status: OK in 0.900 seconds
[0m18:34:14.689254 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086ba-9ddd-176e-aef1-37cf8ef0a414, command-id=01f086ba-9de8-1ba9-b140-a1c99d4f1d75) - Closing
[0m18:34:14.691358 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m18:34:14.691358 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086ba-9ddd-176e-aef1-37cf8ef0a414) - Closing
[0m18:34:14.775502 [info ] [Thread-2 (]: 3 of 5 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 1.02s]
[0m18:34:14.779034 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:34:14.780791 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:34:14.780791 [info ] [Thread-2 (]: 4 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m18:34:14.780791 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m18:34:14.782809 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m18:34:14.782809 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:34:14.792608 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:34:14.792608 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:34:14.797321 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:34:14.799332 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:34:14.799332 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m18:34:14.799332 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:34:15.081696 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086ba-9e7c-1948-82be-17290423c0e4) - Created
[0m18:34:16.325444 [debug] [Thread-2 (]: SQL status: OK in 1.530 seconds
[0m18:34:16.329253 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086ba-9e7c-1948-82be-17290423c0e4, command-id=01f086ba-9e87-1f0c-9d27-d6535da4579c) - Closing
[0m18:34:16.333474 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m18:34:16.333474 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086ba-9e7c-1948-82be-17290423c0e4) - Closing
[0m18:34:16.413222 [info ] [Thread-2 (]: 4 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.63s]
[0m18:34:16.415162 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:34:16.415162 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:34:16.415162 [info ] [Thread-2 (]: 5 of 5 START test unique_bronze_store_store_sk ................................. [RUN]
[0m18:34:16.415162 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m18:34:16.417293 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m18:34:16.417293 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:34:16.424894 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:34:16.426907 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:34:16.431387 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:34:16.432506 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:34:16.433139 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m18:34:16.433139 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:34:16.723574 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086ba-9f77-10fb-b08c-7951c000dd63) - Created
[0m18:34:17.364577 [debug] [Thread-2 (]: SQL status: OK in 0.930 seconds
[0m18:34:17.369168 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086ba-9f77-10fb-b08c-7951c000dd63, command-id=01f086ba-9f81-147e-9f03-0b0be3ca4daa) - Closing
[0m18:34:17.369168 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m18:34:17.369168 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086ba-9f77-10fb-b08c-7951c000dd63) - Closing
[0m18:34:17.455061 [info ] [Thread-2 (]: 5 of 5 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 1.04s]
[0m18:34:17.455061 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:34:17.460992 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m18:34:17.460992 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m18:34:17.460992 [info ] [MainThread]: 
[0m18:34:17.462731 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 8.44 seconds (8.44s).
[0m18:34:17.466861 [debug] [MainThread]: Command end result
[0m18:34:17.519447 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m18:34:17.524040 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m18:34:17.535373 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m18:34:17.535373 [info ] [MainThread]: 
[0m18:34:17.539055 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:34:17.539055 [info ] [MainThread]: 
[0m18:34:17.539055 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m18:34:17.542336 [debug] [MainThread]: Command `dbt test` succeeded at 18:34:17.542336 after 14.20 seconds
[0m18:34:17.542336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F1F76AC30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F1DE6F140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015F1F7CDDC0>]}
[0m18:34:17.543841 [debug] [MainThread]: Flushing usage events
[0m18:34:18.022807 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:37:40.979367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001940A2FBB30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001940D97F2C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001940D97CBF0>]}


============================== 18:37:40.981679 | e4ede1f7-8ecd-4324-951e-b3b8e272540f ==============================
[0m18:37:40.981679 [info ] [MainThread]: Running with dbt=1.10.10
[0m18:37:40.981679 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m18:37:41.974841 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:37:41.975427 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:37:41.975427 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:37:42.881734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e4ede1f7-8ecd-4324-951e-b3b8e272540f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001940BB3AA20>]}
[0m18:37:42.945102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e4ede1f7-8ecd-4324-951e-b3b8e272540f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001943BB671D0>]}
[0m18:37:42.945102 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m18:37:43.352742 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m18:37:43.452209 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:37:43.452209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e4ede1f7-8ecd-4324-951e-b3b8e272540f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001940E48B560>]}
[0m18:37:45.310033 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_databricks_proj.silver
- models.dbt_databricks_proj.gold
[0m18:37:45.318701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4ede1f7-8ecd-4324-951e-b3b8e272540f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001943F48E840>]}
[0m18:37:45.418689 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m18:37:45.418689 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m18:37:45.450242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4ede1f7-8ecd-4324-951e-b3b8e272540f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001943F499B20>]}
[0m18:37:45.450242 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m18:37:45.450242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4ede1f7-8ecd-4324-951e-b3b8e272540f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001943F48ED20>]}
[0m18:37:45.450242 [info ] [MainThread]: 
[0m18:37:45.450242 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:37:45.450242 [info ] [MainThread]: 
[0m18:37:45.450242 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m18:37:45.450242 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m18:37:45.450242 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m18:37:45.450242 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m18:37:45.482485 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m18:37:45.482485 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m18:37:45.482485 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:37:45.801642 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086bb-1c15-155c-9533-5929a5122c5d) - Created
[0m18:37:46.247891 [debug] [ThreadPool]: SQL status: OK in 0.770 seconds
[0m18:37:46.251915 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086bb-1c15-155c-9533-5929a5122c5d, command-id=01f086bb-1c23-1dc0-a348-df7c5c1b3b11) - Closing
[0m18:37:46.251915 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m18:37:46.251915 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086bb-1c15-155c-9533-5929a5122c5d) - Closing
[0m18:37:46.331636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4ede1f7-8ecd-4324-951e-b3b8e272540f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001943F36A120>]}
[0m18:37:46.337660 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:37:46.337660 [info ] [Thread-2 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m18:37:46.341986 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m18:37:46.341986 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m18:37:46.341986 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:37:46.355886 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m18:37:46.357894 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:37:46.380974 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m18:37:46.382978 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m18:37:46.382978 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m18:37:46.382978 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:37:46.645618 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-1c96-1023-973c-e24b8abf663b) - Created
[0m18:37:46.857488 [debug] [Thread-2 (]: SQL status: OK in 0.470 seconds
[0m18:37:46.861509 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-1c96-1023-973c-e24b8abf663b, command-id=01f086bb-1ca1-122a-a89d-b91c347a4a58) - Closing
[0m18:37:46.865531 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m18:37:46.867543 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-1c96-1023-973c-e24b8abf663b) - Closing
[0m18:37:46.969038 [info ] [Thread-2 (]: 1 of 5 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 0.63s]
[0m18:37:46.971049 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:37:46.971049 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:37:46.973061 [info ] [Thread-2 (]: 2 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m18:37:46.973061 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m18:37:46.973061 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m18:37:46.975073 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:37:46.987956 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:37:46.987956 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:37:46.987956 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:37:46.987956 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:37:46.996607 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m18:37:46.996607 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:37:47.248537 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-1cf4-14e3-a00f-35e8c5f9a28b) - Created
[0m18:37:47.473954 [debug] [Thread-2 (]: SQL status: OK in 0.480 seconds
[0m18:37:47.475962 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-1cf4-14e3-a00f-35e8c5f9a28b, command-id=01f086bb-1cff-127f-b486-3cb8e91ef6e3) - Closing
[0m18:37:47.477973 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m18:37:47.477973 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-1cf4-14e3-a00f-35e8c5f9a28b) - Closing
[0m18:37:47.545208 [info ] [Thread-2 (]: 2 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.57s]
[0m18:37:47.545208 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:37:47.545208 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:37:47.545208 [info ] [Thread-2 (]: 3 of 5 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m18:37:47.561118 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m18:37:47.561118 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m18:37:47.561118 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:37:47.567147 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:37:47.569156 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:37:47.575187 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:37:47.576939 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:37:47.576939 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m18:37:47.576939 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:37:47.834185 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-1d4a-1c3c-a003-78e9dfaff748) - Created
[0m18:37:48.088543 [debug] [Thread-2 (]: SQL status: OK in 0.510 seconds
[0m18:37:48.092564 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-1d4a-1c3c-a003-78e9dfaff748, command-id=01f086bb-1d56-1436-96f9-4f159f91684b) - Closing
[0m18:37:48.094319 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m18:37:48.094319 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-1d4a-1c3c-a003-78e9dfaff748) - Closing
[0m18:37:48.179082 [info ] [Thread-2 (]: 3 of 5 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.63s]
[0m18:37:48.181093 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:37:48.181093 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:37:48.183104 [info ] [Thread-2 (]: 4 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m18:37:48.183104 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m18:37:48.185120 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m18:37:48.185120 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:37:48.196214 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:37:48.197224 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:37:48.201250 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:37:48.201250 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:37:48.203264 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m18:37:48.203264 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:37:48.471283 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-1dad-1a86-8405-20f8000a2cba) - Created
[0m18:37:48.701635 [debug] [Thread-2 (]: SQL status: OK in 0.500 seconds
[0m18:37:48.705660 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-1dad-1a86-8405-20f8000a2cba, command-id=01f086bb-1db8-11fa-9ef3-793c7e40fe3d) - Closing
[0m18:37:48.706668 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m18:37:48.706668 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-1dad-1a86-8405-20f8000a2cba) - Closing
[0m18:37:48.789303 [info ] [Thread-2 (]: 4 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 0.61s]
[0m18:37:48.791317 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:37:48.791317 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:37:48.791317 [info ] [Thread-2 (]: 5 of 5 START test unique_bronze_store_store_sk ................................. [RUN]
[0m18:37:48.791317 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m18:37:48.793329 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m18:37:48.793329 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:37:48.797845 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:37:48.799851 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:37:48.801605 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:37:48.803621 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:37:48.803621 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m18:37:48.803621 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:37:49.113501 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-1e0d-102f-9bad-ee376ae1c719) - Created
[0m18:37:49.318415 [debug] [Thread-2 (]: SQL status: OK in 0.510 seconds
[0m18:37:49.322170 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-1e0d-102f-9bad-ee376ae1c719, command-id=01f086bb-1e19-1e76-b5f0-f3426eb4266e) - Closing
[0m18:37:49.322170 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m18:37:49.322170 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-1e0d-102f-9bad-ee376ae1c719) - Closing
[0m18:37:49.418727 [info ] [Thread-2 (]: 5 of 5 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 0.63s]
[0m18:37:49.420111 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:37:49.422034 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m18:37:49.422034 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m18:37:49.422957 [info ] [MainThread]: 
[0m18:37:49.423462 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 3.97 seconds (3.97s).
[0m18:37:49.424713 [debug] [MainThread]: Command end result
[0m18:37:49.451949 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m18:37:49.467476 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m18:37:49.475601 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m18:37:49.475601 [info ] [MainThread]: 
[0m18:37:49.475601 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:37:49.475601 [info ] [MainThread]: 
[0m18:37:49.475601 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m18:37:49.475601 [debug] [MainThread]: Command `dbt test` succeeded at 18:37:49.475601 after 8.68 seconds
[0m18:37:49.475601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001940E3A8E30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001940E32D580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001940E32CC80>]}
[0m18:37:49.482350 [debug] [MainThread]: Flushing usage events
[0m18:37:49.918743 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:38:06.007031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258743DD4F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258773156A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025877314890>]}


============================== 18:38:06.009125 | 007b43a3-36e2-4ba8-bb7c-3c258b31d446 ==============================
[0m18:38:06.009125 [info ] [MainThread]: Running with dbt=1.10.10
[0m18:38:06.009125 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt test', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m18:38:07.051453 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:38:07.051453 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:38:07.051453 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:38:08.024188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '007b43a3-36e2-4ba8-bb7c-3c258b31d446', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002582747BD40>]}
[0m18:38:08.081144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '007b43a3-36e2-4ba8-bb7c-3c258b31d446', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258780755B0>]}
[0m18:38:08.081144 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m18:38:08.485394 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m18:38:08.589612 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:38:08.589612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '007b43a3-36e2-4ba8-bb7c-3c258b31d446', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258278EA120>]}
[0m18:38:10.658929 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_databricks_proj.silver
- models.dbt_databricks_proj.gold
[0m18:38:10.675183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '007b43a3-36e2-4ba8-bb7c-3c258b31d446', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025828C0CC80>]}
[0m18:38:10.789180 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m18:38:10.789180 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m18:38:10.825117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '007b43a3-36e2-4ba8-bb7c-3c258b31d446', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025828D4BE00>]}
[0m18:38:10.825117 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m18:38:10.825117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '007b43a3-36e2-4ba8-bb7c-3c258b31d446', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025828D79BB0>]}
[0m18:38:10.825117 [info ] [MainThread]: 
[0m18:38:10.834016 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:38:10.834016 [info ] [MainThread]: 
[0m18:38:10.834016 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m18:38:10.836401 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m18:38:10.841469 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m18:38:10.841469 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m18:38:10.861556 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m18:38:10.861556 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m18:38:10.861556 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:38:11.185082 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086bb-2b38-1bb3-8ad2-4486f61a47ff) - Created
[0m18:38:11.534272 [debug] [ThreadPool]: SQL status: OK in 0.670 seconds
[0m18:38:11.551182 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086bb-2b38-1bb3-8ad2-4486f61a47ff, command-id=01f086bb-2b42-13f9-84fb-ede9205bb2f6) - Closing
[0m18:38:11.551182 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m18:38:11.553710 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086bb-2b38-1bb3-8ad2-4486f61a47ff) - Closing
[0m18:38:11.621446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '007b43a3-36e2-4ba8-bb7c-3c258b31d446', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025828B30350>]}
[0m18:38:11.634607 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410
[0m18:38:11.634607 [info ] [Thread-2 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m18:38:11.634607 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410) - Creating connection
[0m18:38:11.634607 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410'
[0m18:38:11.634607 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410
[0m18:38:11.654203 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410"
[0m18:38:11.657527 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410
[0m18:38:11.681365 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410"
[0m18:38:11.681365 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410"
[0m18:38:11.683115 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhatan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m18:38:11.684178 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:11.951438 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-2bab-13c2-a0ea-01e69c91004c) - Created
[0m18:38:12.665647 [debug] [Thread-2 (]: SQL status: OK in 0.980 seconds
[0m18:38:12.671599 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-2bab-13c2-a0ea-01e69c91004c, command-id=01f086bb-2bb6-1ee4-9140-a8bf82ef65a5) - Closing
[0m18:38:12.675615 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410: Close
[0m18:38:12.675615 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-2bab-13c2-a0ea-01e69c91004c) - Closing
[0m18:38:12.767277 [warn ] [Thread-2 (]: 1 of 5 WARN 1 accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 1.13s]
[0m18:38:12.771357 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410
[0m18:38:12.771357 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:12.771357 [info ] [Thread-2 (]: 2 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m18:38:12.773369 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m18:38:12.773369 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m18:38:12.773369 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:12.784081 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:38:12.784081 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:12.787914 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:38:12.787914 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:38:12.787914 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m18:38:12.787914 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:13.058161 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-2c54-188f-9ca8-32bd9762cddd) - Created
[0m18:38:13.278546 [debug] [Thread-2 (]: SQL status: OK in 0.490 seconds
[0m18:38:13.280554 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-2c54-188f-9ca8-32bd9762cddd, command-id=01f086bb-2c5f-1921-972d-eee4f22e51e5) - Closing
[0m18:38:13.282062 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m18:38:13.282062 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-2c54-188f-9ca8-32bd9762cddd) - Closing
[0m18:38:13.373709 [info ] [Thread-2 (]: 2 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.60s]
[0m18:38:13.375720 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:13.375720 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:13.375720 [info ] [Thread-2 (]: 3 of 5 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m18:38:13.377730 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m18:38:13.377730 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m18:38:13.377730 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:13.384844 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:38:13.386855 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:13.390252 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:38:13.390252 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:38:13.390252 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m18:38:13.390252 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:13.660465 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-2cb0-1d57-b7ed-ba86368a580c) - Created
[0m18:38:13.846512 [debug] [Thread-2 (]: SQL status: OK in 0.450 seconds
[0m18:38:13.848526 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-2cb0-1d57-b7ed-ba86368a580c, command-id=01f086bb-2cbb-123c-b500-796c688a3b8e) - Closing
[0m18:38:13.850539 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m18:38:13.850539 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-2cb0-1d57-b7ed-ba86368a580c) - Closing
[0m18:38:13.940733 [info ] [Thread-2 (]: 3 of 5 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.56s]
[0m18:38:13.942746 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:13.942746 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:13.944758 [info ] [Thread-2 (]: 4 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m18:38:13.944758 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m18:38:13.944758 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m18:38:13.946767 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:13.955619 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:38:13.955619 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:13.955619 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:38:13.955619 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:38:13.955619 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m18:38:13.955619 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:14.225091 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-2d08-1a4b-af14-e1621c529597) - Created
[0m18:38:14.506834 [debug] [Thread-2 (]: SQL status: OK in 0.550 seconds
[0m18:38:14.510853 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-2d08-1a4b-af14-e1621c529597, command-id=01f086bb-2d12-1460-b46b-293198704e35) - Closing
[0m18:38:14.512862 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m18:38:14.512862 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-2d08-1a4b-af14-e1621c529597) - Closing
[0m18:38:14.591656 [info ] [Thread-2 (]: 4 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 0.65s]
[0m18:38:14.593670 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:14.593670 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:14.593670 [info ] [Thread-2 (]: 5 of 5 START test unique_bronze_store_store_sk ................................. [RUN]
[0m18:38:14.593670 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m18:38:14.595682 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m18:38:14.595682 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:14.602040 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:38:14.603038 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:14.607068 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:38:14.607068 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:38:14.607068 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m18:38:14.609080 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:14.841921 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-2d67-1d46-bffe-e0eefc28452c) - Created
[0m18:38:15.122615 [debug] [Thread-2 (]: SQL status: OK in 0.510 seconds
[0m18:38:15.126149 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-2d67-1d46-bffe-e0eefc28452c, command-id=01f086bb-2d71-19c0-862a-c12c7a25cdee) - Closing
[0m18:38:15.128158 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m18:38:15.128158 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-2d67-1d46-bffe-e0eefc28452c) - Closing
[0m18:38:15.212470 [info ] [Thread-2 (]: 5 of 5 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 0.62s]
[0m18:38:15.215500 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:15.217518 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m18:38:15.220306 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m18:38:15.220819 [info ] [MainThread]: 
[0m18:38:15.222838 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 4.39 seconds (4.39s).
[0m18:38:15.225343 [debug] [MainThread]: Command end result
[0m18:38:15.268462 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m18:38:15.278892 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m18:38:15.291405 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m18:38:15.291405 [info ] [MainThread]: 
[0m18:38:15.291405 [info ] [MainThread]: [33mCompleted with 1 warning:[0m
[0m18:38:15.291405 [info ] [MainThread]: 
[0m18:38:15.291405 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models\bronze\properties.yml)[0m
[0m18:38:15.291405 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m18:38:15.291405 [info ] [MainThread]: 
[0m18:38:15.301294 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_proj\models\bronze\properties.yml\accepted_values_bronze_store_b614c33380c6ac786c2011d7ea18f0c7.sql
[0m18:38:15.302071 [info ] [MainThread]: 
[0m18:38:15.302868 [info ] [MainThread]: Done. PASS=4 WARN=1 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m18:38:15.304203 [debug] [MainThread]: Command `dbt test` succeeded at 18:38:15.304203 after 9.48 seconds
[0m18:38:15.304203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025877A26360>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025877A26870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025877D5A870>]}
[0m18:38:15.306219 [debug] [MainThread]: Flushing usage events
[0m18:38:15.758568 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:38:26.887523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001778FEDED50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001778CE8C230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001778F3EDAC0>]}


============================== 18:38:26.896478 | cc071e66-eda6-4fef-86ea-d7d680a7de74 ==============================
[0m18:38:26.896478 [info ] [MainThread]: Running with dbt=1.10.10
[0m18:38:26.896478 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt test', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m18:38:28.016495 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:38:28.016495 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:38:28.016495 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:38:29.011165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cc071e66-eda6-4fef-86ea-d7d680a7de74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001778D094920>]}
[0m18:38:29.105386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cc071e66-eda6-4fef-86ea-d7d680a7de74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000177BF27B380>]}
[0m18:38:29.105386 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m18:38:29.609562 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m18:38:29.880322 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:38:29.880322 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:38:29.896072 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_databricks_proj.gold
- models.dbt_databricks_proj.silver
[0m18:38:29.957300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cc071e66-eda6-4fef-86ea-d7d680a7de74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000177BF4407D0>]}
[0m18:38:30.068943 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m18:38:30.068943 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m18:38:30.116180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cc071e66-eda6-4fef-86ea-d7d680a7de74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000177BF9EA9F0>]}
[0m18:38:30.116180 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m18:38:30.116180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cc071e66-eda6-4fef-86ea-d7d680a7de74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000177BF9E0680>]}
[0m18:38:30.116180 [info ] [MainThread]: 
[0m18:38:30.116180 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:38:30.116180 [info ] [MainThread]: 
[0m18:38:30.116180 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m18:38:30.127131 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m18:38:30.137415 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m18:38:30.137415 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m18:38:30.166596 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m18:38:30.168912 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m18:38:30.168912 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:38:30.479645 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086bb-36b7-135a-954d-466a72d1a82a) - Created
[0m18:38:30.896345 [debug] [ThreadPool]: SQL status: OK in 0.730 seconds
[0m18:38:30.902837 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086bb-36b7-135a-954d-466a72d1a82a, command-id=01f086bb-36c1-1baa-a7a6-71bbc9026f41) - Closing
[0m18:38:30.902837 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m18:38:30.902837 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086bb-36b7-135a-954d-466a72d1a82a) - Closing
[0m18:38:30.988613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cc071e66-eda6-4fef-86ea-d7d680a7de74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001778D1362D0>]}
[0m18:38:30.996715 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410
[0m18:38:30.996715 [info ] [Thread-2 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m18:38:30.998726 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410) - Creating connection
[0m18:38:30.999474 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410'
[0m18:38:30.999474 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410
[0m18:38:31.023359 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410"
[0m18:38:31.029617 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410
[0m18:38:31.066616 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410"
[0m18:38:31.073758 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410"
[0m18:38:31.073758 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhatan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m18:38:31.073758 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:31.333575 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-373a-1826-8f45-e8ad5279f13f) - Created
[0m18:38:31.611251 [debug] [Thread-2 (]: SQL status: OK in 0.540 seconds
[0m18:38:31.615280 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-373a-1826-8f45-e8ad5279f13f, command-id=01f086bb-3744-1752-90d5-ac69952511bb) - Closing
[0m18:38:31.619303 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410: Close
[0m18:38:31.621310 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-373a-1826-8f45-e8ad5279f13f) - Closing
[0m18:38:31.707986 [warn ] [Thread-2 (]: 1 of 5 WARN 1 accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[33mWARN 1[0m in 0.71s]
[0m18:38:31.709996 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.6a520e4410
[0m18:38:31.709996 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:31.712010 [info ] [Thread-2 (]: 2 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m18:38:31.712010 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m18:38:31.714025 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m18:38:31.714025 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:31.726246 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:38:31.726246 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:31.730269 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:38:31.730269 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:38:31.732278 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m18:38:31.732278 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:31.995659 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-379f-1db3-adad-5144773f761d) - Created
[0m18:38:32.222916 [debug] [Thread-2 (]: SQL status: OK in 0.490 seconds
[0m18:38:32.226943 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-379f-1db3-adad-5144773f761d, command-id=01f086bb-37a9-1285-99ee-928e3ce6e213) - Closing
[0m18:38:32.228957 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m18:38:32.230971 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-379f-1db3-adad-5144773f761d) - Closing
[0m18:38:32.311055 [info ] [Thread-2 (]: 2 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.60s]
[0m18:38:32.313069 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:32.315084 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:32.315084 [info ] [Thread-2 (]: 3 of 5 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m18:38:32.317095 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m18:38:32.317095 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m18:38:32.319108 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:32.328913 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:38:32.328913 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:32.334209 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:38:32.334209 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:38:32.336224 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m18:38:32.336224 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:32.588474 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-37f9-11a9-9063-80d2e0faf0be) - Created
[0m18:38:32.838770 [debug] [Thread-2 (]: SQL status: OK in 0.500 seconds
[0m18:38:32.842780 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-37f9-11a9-9063-80d2e0faf0be, command-id=01f086bb-3803-1a8a-bb05-d5554edf2146) - Closing
[0m18:38:32.844784 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m18:38:32.846288 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-37f9-11a9-9063-80d2e0faf0be) - Closing
[0m18:38:32.942891 [info ] [Thread-2 (]: 3 of 5 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.62s]
[0m18:38:32.942891 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:32.945394 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:32.945394 [info ] [Thread-2 (]: 4 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m18:38:32.945394 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m18:38:32.945394 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m18:38:32.948848 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:32.962621 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:38:32.964624 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:32.968633 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:38:32.970637 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:38:32.972384 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m18:38:32.973105 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:33.226584 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-385b-15a7-a0d5-913b400a3037) - Created
[0m18:38:33.452303 [debug] [Thread-2 (]: SQL status: OK in 0.480 seconds
[0m18:38:33.456329 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-385b-15a7-a0d5-913b400a3037, command-id=01f086bb-3865-1294-8ba9-c132efdc5286) - Closing
[0m18:38:33.458344 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m18:38:33.458344 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-385b-15a7-a0d5-913b400a3037) - Closing
[0m18:38:33.542798 [info ] [Thread-2 (]: 4 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 0.60s]
[0m18:38:33.544812 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:33.544812 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:33.544812 [info ] [Thread-2 (]: 5 of 5 START test unique_bronze_store_store_sk ................................. [RUN]
[0m18:38:33.546826 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m18:38:33.546826 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m18:38:33.548842 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:33.558647 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:38:33.560659 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:33.568465 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:38:33.570940 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:38:33.570940 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m18:38:33.572952 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:33.839654 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-38b8-116e-aa84-0b8ce1d91e21) - Created
[0m18:38:34.064877 [debug] [Thread-2 (]: SQL status: OK in 0.490 seconds
[0m18:38:34.068076 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-38b8-116e-aa84-0b8ce1d91e21, command-id=01f086bb-38c2-1297-a590-62782c58d28e) - Closing
[0m18:38:34.070080 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m18:38:34.070080 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-38b8-116e-aa84-0b8ce1d91e21) - Closing
[0m18:38:34.149621 [info ] [Thread-2 (]: 5 of 5 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 0.60s]
[0m18:38:34.151538 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:34.153549 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m18:38:34.153549 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m18:38:34.156240 [info ] [MainThread]: 
[0m18:38:34.156240 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 4.04 seconds (4.04s).
[0m18:38:34.159264 [debug] [MainThread]: Command end result
[0m18:38:34.340785 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m18:38:34.340785 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m18:38:34.354055 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m18:38:34.354055 [info ] [MainThread]: 
[0m18:38:34.354055 [info ] [MainThread]: [33mCompleted with 1 warning:[0m
[0m18:38:34.354055 [info ] [MainThread]: 
[0m18:38:34.354055 [warn ] [MainThread]: [33mWarning in test accepted_values_bronze_store_store_name__MegaMart_Manhatan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto (models\bronze\properties.yml)[0m
[0m18:38:34.354055 [warn ] [MainThread]: Got 1 result, configured to warn if != 0
[0m18:38:34.354055 [info ] [MainThread]: 
[0m18:38:34.354055 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_proj\models\bronze\properties.yml\accepted_values_bronze_store_b614c33380c6ac786c2011d7ea18f0c7.sql
[0m18:38:34.354055 [info ] [MainThread]: 
[0m18:38:34.354055 [info ] [MainThread]: Done. PASS=4 WARN=1 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m18:38:34.365412 [debug] [MainThread]: Command `dbt test` succeeded at 18:38:34.363597 after 7.65 seconds
[0m18:38:34.368145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001779006C140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001778F988D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000177BFB6A540>]}
[0m18:38:34.369142 [debug] [MainThread]: Flushing usage events
[0m18:38:34.813853 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:38:44.616076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAFDE9D610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAFE2CE870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAFE2CEBA0>]}


============================== 18:38:44.616076 | 4a2024c3-3137-43fd-8b58-f2d1ceaff4f1 ==============================
[0m18:38:44.616076 [info ] [MainThread]: Running with dbt=1.10.10
[0m18:38:44.616076 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m18:38:45.722296 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:38:45.722296 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:38:45.722296 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:38:46.679361 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a2024c3-3137-43fd-8b58-f2d1ceaff4f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAAE278E00>]}
[0m18:38:46.759531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4a2024c3-3137-43fd-8b58-f2d1ceaff4f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAAE20E210>]}
[0m18:38:46.759531 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m18:38:47.165527 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m18:38:47.270578 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:38:47.286297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4a2024c3-3137-43fd-8b58-f2d1ceaff4f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAFE95B4A0>]}
[0m18:38:49.282212 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_databricks_proj.gold
- models.dbt_databricks_proj.silver
[0m18:38:49.298303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4a2024c3-3137-43fd-8b58-f2d1ceaff4f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAAE38B3E0>]}
[0m18:38:49.396965 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m18:38:49.400974 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m18:38:49.424653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4a2024c3-3137-43fd-8b58-f2d1ceaff4f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAAFA29B20>]}
[0m18:38:49.427502 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m18:38:49.427502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a2024c3-3137-43fd-8b58-f2d1ceaff4f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAAF9583E0>]}
[0m18:38:49.430284 [info ] [MainThread]: 
[0m18:38:49.430284 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:38:49.430284 [info ] [MainThread]: 
[0m18:38:49.430284 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m18:38:49.430284 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m18:38:49.441434 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m18:38:49.441434 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m18:38:49.452521 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m18:38:49.452521 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m18:38:49.452521 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:38:49.838040 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086bb-4240-1a72-8c9f-de01103fe591) - Created
[0m18:38:50.254523 [debug] [ThreadPool]: SQL status: OK in 0.800 seconds
[0m18:38:50.264103 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086bb-4240-1a72-8c9f-de01103fe591, command-id=01f086bb-424b-1827-be25-e8ec072aaf12) - Closing
[0m18:38:50.264103 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m18:38:50.266115 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086bb-4240-1a72-8c9f-de01103fe591) - Closing
[0m18:38:50.358209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a2024c3-3137-43fd-8b58-f2d1ceaff4f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAAF9EC5F0>]}
[0m18:38:50.364764 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:38:50.365340 [info ] [Thread-2 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m18:38:50.366186 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m18:38:50.368200 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m18:38:50.368200 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:38:50.380363 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m18:38:50.381899 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:38:50.414340 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m18:38:50.415970 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m18:38:50.422631 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m18:38:50.422631 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:50.684916 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-42c2-1494-8795-03cc52e68eda) - Created
[0m18:38:50.966609 [debug] [Thread-2 (]: SQL status: OK in 0.540 seconds
[0m18:38:50.970131 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-42c2-1494-8795-03cc52e68eda, command-id=01f086bb-42cc-1fe3-bdca-b1af72b76717) - Closing
[0m18:38:50.974146 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m18:38:50.974146 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-42c2-1494-8795-03cc52e68eda) - Closing
[0m18:38:51.055779 [info ] [Thread-2 (]: 1 of 5 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 0.69s]
[0m18:38:51.056788 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m18:38:51.056788 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:51.056788 [info ] [Thread-2 (]: 2 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m18:38:51.058805 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m18:38:51.059644 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m18:38:51.060183 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:51.068249 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:38:51.070260 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:51.072271 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:38:51.074287 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m18:38:51.074287 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m18:38:51.074287 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:51.325495 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-4325-1665-b0e8-362597e28e0b) - Created
[0m18:38:51.510861 [debug] [Thread-2 (]: SQL status: OK in 0.440 seconds
[0m18:38:51.514880 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-4325-1665-b0e8-362597e28e0b, command-id=01f086bb-4331-10a7-8149-7304f1873198) - Closing
[0m18:38:51.514880 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m18:38:51.516897 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-4325-1665-b0e8-362597e28e0b) - Closing
[0m18:38:51.588699 [info ] [Thread-2 (]: 2 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.53s]
[0m18:38:51.588699 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m18:38:51.590711 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:51.590711 [info ] [Thread-2 (]: 3 of 5 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m18:38:51.590711 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m18:38:51.592721 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m18:38:51.592721 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:51.598747 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:38:51.598747 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:51.606799 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:38:51.606799 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m18:38:51.608807 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m18:38:51.608807 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:51.860527 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-4376-199b-806c-f36620bc62bb) - Created
[0m18:38:52.023997 [debug] [Thread-2 (]: SQL status: OK in 0.420 seconds
[0m18:38:52.026007 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-4376-199b-806c-f36620bc62bb, command-id=01f086bb-437f-1f38-a5de-f7366520bf69) - Closing
[0m18:38:52.026007 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m18:38:52.026007 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-4376-199b-806c-f36620bc62bb) - Closing
[0m18:38:52.114205 [info ] [Thread-2 (]: 3 of 5 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.52s]
[0m18:38:52.114205 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m18:38:52.114205 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:52.123966 [info ] [Thread-2 (]: 4 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m18:38:52.123966 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m18:38:52.123966 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m18:38:52.125977 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:52.134019 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:38:52.134019 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:52.138040 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:38:52.138040 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m18:38:52.138040 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m18:38:52.140050 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:52.397412 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-43c7-16be-bd18-464b0768c010) - Created
[0m18:38:52.702680 [debug] [Thread-2 (]: SQL status: OK in 0.560 seconds
[0m18:38:52.706697 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-43c7-16be-bd18-464b0768c010, command-id=01f086bb-43d2-15df-93f6-b846817d0fec) - Closing
[0m18:38:52.706697 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m18:38:52.706697 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-43c7-16be-bd18-464b0768c010) - Closing
[0m18:38:52.791186 [info ] [Thread-2 (]: 4 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 0.67s]
[0m18:38:52.793209 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m18:38:52.793209 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:52.793209 [info ] [Thread-2 (]: 5 of 5 START test unique_bronze_store_store_sk ................................. [RUN]
[0m18:38:52.795219 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m18:38:52.795219 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m18:38:52.795219 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:52.801249 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:38:52.801249 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:52.805273 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:38:52.805273 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m18:38:52.807026 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m18:38:52.807026 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m18:38:53.052166 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-442c-172c-aa39-ecd0e9013354) - Created
[0m18:38:53.323014 [debug] [Thread-2 (]: SQL status: OK in 0.510 seconds
[0m18:38:53.325020 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086bb-442c-172c-aa39-ecd0e9013354, command-id=01f086bb-4435-1f6e-a2ae-311c6825523c) - Closing
[0m18:38:53.327031 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m18:38:53.327031 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086bb-442c-172c-aa39-ecd0e9013354) - Closing
[0m18:38:53.421570 [info ] [Thread-2 (]: 5 of 5 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 0.63s]
[0m18:38:53.423848 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m18:38:53.425584 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m18:38:53.425584 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m18:38:53.427592 [info ] [MainThread]: 
[0m18:38:53.427592 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 4.00 seconds (4.00s).
[0m18:38:53.430569 [debug] [MainThread]: Command end result
[0m18:38:53.474406 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m18:38:53.482739 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m18:38:53.482739 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m18:38:53.482739 [info ] [MainThread]: 
[0m18:38:53.497250 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:38:53.498259 [info ] [MainThread]: 
[0m18:38:53.499049 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m18:38:53.499049 [debug] [MainThread]: Command `dbt test` succeeded at 18:38:53.499049 after 9.08 seconds
[0m18:38:53.499049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAFE34C530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAFE34C650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AAFE6229C0>]}
[0m18:38:53.499049 [debug] [MainThread]: Flushing usage events
[0m18:38:53.973821 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:06:56.166274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204D68109E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204D31C7A70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204D6D510D0>]}


============================== 19:06:56.175345 | e5257955-0b39-4864-a1d3-b97d30f1595c ==============================
[0m19:06:56.175345 [info ] [MainThread]: Running with dbt=1.10.10
[0m19:06:56.176500 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'None', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m19:06:57.338783 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:06:57.338783 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:06:57.338783 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:06:58.364241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e5257955-0b39-4864-a1d3-b97d30f1595c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020485FE0350>]}
[0m19:06:58.466175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e5257955-0b39-4864-a1d3-b97d30f1595c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204FFECFFB0>]}
[0m19:06:58.469459 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:06:58.984789 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m19:06:59.219577 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m19:06:59.219577 [debug] [MainThread]: Partial parsing: added file: dbt_databricks_proj://tests\generic\non_negitive.sql
[0m19:06:59.219577 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_proj://models\bronze\properties.yml
[0m19:06:59.679932 [error] [MainThread]: Encountered an error:
Compilation Error in test non_negitive_bronze_sales_gross_amount (models\bronze\properties.yml)
  macro 'dbt_macro__test_non_negitive' takes no keyword argument 'column_name'
[0m19:06:59.695823 [debug] [MainThread]: Command `dbt test` failed at 19:06:59.695823 after 3.71 seconds
[0m19:06:59.695823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204D6D510D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204D0812BD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204867AB920>]}
[0m19:06:59.696995 [debug] [MainThread]: Flushing usage events
[0m19:07:00.184276 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:08:29.341442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A55CAFDAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A55CAFFF80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A55CAFDDF0>]}


============================== 19:08:29.347148 | 233fc661-2779-4ef4-8e6b-9cb1f89db7c3 ==============================
[0m19:08:29.347148 [info ] [MainThread]: Running with dbt=1.10.10
[0m19:08:29.348217 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m19:08:30.486569 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:08:30.487260 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:08:30.487701 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:08:31.480976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '233fc661-2779-4ef4-8e6b-9cb1f89db7c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A55D8380B0>]}
[0m19:08:31.559583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '233fc661-2779-4ef4-8e6b-9cb1f89db7c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A55D50B200>]}
[0m19:08:31.559583 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:08:31.994696 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m19:08:32.225543 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m19:08:32.225543 [debug] [MainThread]: Partial parsing: added file: dbt_databricks_proj://tests\generic\non_negitive.sql
[0m19:08:32.225543 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_proj://models\bronze\properties.yml
[0m19:08:32.689362 [error] [MainThread]: Encountered an error:
Compilation Error in test non_negitive_bronze_sales_gross_amount (models\bronze\properties.yml)
  macro 'dbt_macro__test_non_negitive' takes no keyword argument 'column_name'
[0m19:08:32.692259 [debug] [MainThread]: Command `dbt test` failed at 19:08:32.692259 after 3.55 seconds
[0m19:08:32.692259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A55D18B890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A50E2324B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A55CA995E0>]}
[0m19:08:32.692259 [debug] [MainThread]: Flushing usage events
[0m19:08:33.195218 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:08:56.820560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F18861430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F1984B4A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F15D17A70>]}


============================== 19:08:56.829697 | f70af376-d8d3-4ac2-ad5d-09a635ac47fe ==============================
[0m19:08:56.829697 [info ] [MainThread]: Running with dbt=1.10.10
[0m19:08:56.829697 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'printer_width': '80', 'empty': 'None', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj'}
[0m19:08:57.922760 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:08:57.922760 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:08:57.922760 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:08:58.895010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f70af376-d8d3-4ac2-ad5d-09a635ac47fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F4887F710>]}
[0m19:08:58.974384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f70af376-d8d3-4ac2-ad5d-09a635ac47fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F4841B3B0>]}
[0m19:08:58.974384 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:08:59.464356 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m19:08:59.692885 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m19:08:59.697242 [debug] [MainThread]: Partial parsing: added file: dbt_databricks_proj://tests\generic\non_negitive.sql
[0m19:08:59.697242 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_proj://models\bronze\properties.yml
[0m19:09:00.161989 [error] [MainThread]: Encountered an error:
Compilation Error in test non_negitive_bronze_sales_gross_amount (models\bronze\properties.yml)
  macro 'dbt_macro__test_non_negitive' takes no keyword argument 'column_name'
[0m19:09:00.161989 [debug] [MainThread]: Command `dbt test` failed at 19:09:00.161989 after 3.52 seconds
[0m19:09:00.161989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F194EBF20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F19748E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F49080770>]}
[0m19:09:00.161989 [debug] [MainThread]: Flushing usage events
[0m19:09:00.593279 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:15:19.295065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB79C3AA80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB79C3AB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB79C3BB90>]}


============================== 19:15:19.298599 | a2e47366-40a3-48a2-9f19-933e0f1b3f5f ==============================
[0m19:15:19.298599 [info ] [MainThread]: Running with dbt=1.10.10
[0m19:15:19.298599 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt clean', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m19:15:19.466775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a2e47366-40a3-48a2-9f19-933e0f1b3f5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB77174890>]}
[0m19:15:19.510570 [debug] [MainThread]: Command `dbt clean` succeeded at 19:15:19.510570 after 0.40 seconds
[0m19:15:19.511418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB73BA4C20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB79549F70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB795489B0>]}
[0m19:15:19.511418 [debug] [MainThread]: Flushing usage events
[0m19:15:19.988706 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:22:12.390843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017617B5D4F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001761B1796D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001761B17B710>]}


============================== 19:22:12.390843 | 759123f8-c203-4d2e-a365-96fe3a722f61 ==============================
[0m19:22:12.390843 [info ] [MainThread]: Running with dbt=1.10.10
[0m19:22:12.390843 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m19:22:13.613659 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:22:13.621737 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:22:13.621737 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:22:14.635970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '759123f8-c203-4d2e-a365-96fe3a722f61', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001764A5AFEF0>]}
[0m19:22:14.709500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '759123f8-c203-4d2e-a365-96fe3a722f61', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001764888F1A0>]}
[0m19:22:14.709500 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:22:15.187911 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m19:22:15.433844 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:22:15.433844 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:22:15.433844 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_databricks_proj.gold
- models.dbt_databricks_proj.silver
[0m19:22:15.504572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '759123f8-c203-4d2e-a365-96fe3a722f61', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001764A9C83E0>]}
[0m19:22:15.610406 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m19:22:15.626870 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m19:22:15.650165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '759123f8-c203-4d2e-a365-96fe3a722f61', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001764B0209E0>]}
[0m19:22:15.650165 [info ] [MainThread]: Found 6 models, 6 data tests, 6 sources, 686 macros
[0m19:22:15.650165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '759123f8-c203-4d2e-a365-96fe3a722f61', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001764AABBF50>]}
[0m19:22:15.650165 [info ] [MainThread]: 
[0m19:22:15.650165 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:22:15.650165 [info ] [MainThread]: 
[0m19:22:15.665855 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:22:15.665855 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:22:15.674946 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m19:22:15.674946 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m19:22:15.685566 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m19:22:15.685566 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m19:22:15.685566 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:22:15.967609 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086c1-53a1-1ccb-a67b-6eb7abfa0001) - Created
[0m19:22:18.402841 [debug] [ThreadPool]: SQL status: OK in 2.720 seconds
[0m19:22:18.410375 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086c1-53a1-1ccb-a67b-6eb7abfa0001, command-id=01f086c1-53ac-1119-8501-ef00bf9c46c6) - Closing
[0m19:22:18.412385 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m19:22:18.412385 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086c1-53a1-1ccb-a67b-6eb7abfa0001) - Closing
[0m19:22:18.511241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '759123f8-c203-4d2e-a365-96fe3a722f61', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001764AF9B800>]}
[0m19:22:18.515256 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m19:22:18.516765 [info ] [Thread-2 (]: 1 of 6 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m19:22:18.517514 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m19:22:18.517514 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m19:22:18.517514 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m19:22:18.546692 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m19:22:18.551050 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m19:22:18.571959 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m19:22:18.581704 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m19:22:18.582379 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m19:22:18.582379 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:22:18.841315 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-5557-1235-93bf-e68644d7a931) - Created
[0m19:22:19.825921 [debug] [Thread-2 (]: SQL status: OK in 1.240 seconds
[0m19:22:19.833236 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-5557-1235-93bf-e68644d7a931, command-id=01f086c1-5561-1608-921f-998d7c790845) - Closing
[0m19:22:19.838755 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m19:22:19.838755 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-5557-1235-93bf-e68644d7a931) - Closing
[0m19:22:19.929046 [info ] [Thread-2 (]: 1 of 6 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 1.40s]
[0m19:22:19.930424 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m19:22:19.931828 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.non_negitive_test
[0m19:22:19.933196 [info ] [Thread-2 (]: 2 of 6 START test non_negitive_test ............................................ [RUN]
[0m19:22:19.933196 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_test) - Creating connection
[0m19:22:19.935210 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_test'
[0m19:22:19.937223 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.non_negitive_test
[0m19:22:19.943723 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_test"
[0m19:22:19.945537 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.non_negitive_test
[0m19:22:19.948395 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_test"
[0m19:22:19.950492 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.non_negitive_test"
[0m19:22:19.950492 [debug] [Thread-2 (]: On test.dbt_databricks_proj.non_negitive_test: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.non_negitive_test"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  select *
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales` 
where gross_amount < 0 and net_amount < 0
  
  
      
    ) dbt_internal_test
[0m19:22:19.950492 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:22:20.241332 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-5628-1696-aaa1-9ebf7ac39253) - Created
[0m19:22:21.878834 [debug] [Thread-2 (]: SQL status: OK in 1.930 seconds
[0m19:22:21.883564 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-5628-1696-aaa1-9ebf7ac39253, command-id=01f086c1-5638-1578-a865-5b66e74dcdcb) - Closing
[0m19:22:21.887020 [debug] [Thread-2 (]: On test.dbt_databricks_proj.non_negitive_test: Close
[0m19:22:21.887020 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-5628-1696-aaa1-9ebf7ac39253) - Closing
[0m19:22:21.973427 [info ] [Thread-2 (]: 2 of 6 PASS non_negitive_test .................................................. [[32mPASS[0m in 2.04s]
[0m19:22:21.976519 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.non_negitive_test
[0m19:22:21.976519 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:22:21.978281 [info ] [Thread-2 (]: 3 of 6 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m19:22:21.979947 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m19:22:21.980313 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m19:22:21.981182 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:22:21.992728 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m19:22:21.996511 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:22:22.003790 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m19:22:22.003790 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m19:22:22.003790 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m19:22:22.007542 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:22:22.266448 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-5762-1a42-ad50-0ca4d2784b1a) - Created
[0m19:22:22.736609 [debug] [Thread-2 (]: SQL status: OK in 0.730 seconds
[0m19:22:22.738619 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-5762-1a42-ad50-0ca4d2784b1a, command-id=01f086c1-576c-1e14-b2a2-97179c4e624b) - Closing
[0m19:22:22.740627 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m19:22:22.740627 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-5762-1a42-ad50-0ca4d2784b1a) - Closing
[0m19:22:22.828049 [info ] [Thread-2 (]: 3 of 6 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.85s]
[0m19:22:22.828049 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:22:22.830063 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m19:22:22.830063 [info ] [Thread-2 (]: 4 of 6 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m19:22:22.832075 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m19:22:22.832075 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m19:22:22.832075 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m19:22:22.838107 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m19:22:22.840116 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m19:22:22.843882 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m19:22:22.843882 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m19:22:22.845894 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m19:22:22.845894 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:22:23.108167 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-57e1-1c49-b848-a89393cb5780) - Created
[0m19:22:23.727357 [debug] [Thread-2 (]: SQL status: OK in 0.880 seconds
[0m19:22:23.731382 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-57e1-1c49-b848-a89393cb5780, command-id=01f086c1-57ed-13e8-9d30-7d82e7d3c4fb) - Closing
[0m19:22:23.733391 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m19:22:23.733391 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-57e1-1c49-b848-a89393cb5780) - Closing
[0m19:22:23.811401 [info ] [Thread-2 (]: 4 of 6 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.97s]
[0m19:22:23.811401 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m19:22:23.811401 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m19:22:23.813410 [info ] [Thread-2 (]: 5 of 6 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m19:22:23.813410 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m19:22:23.813410 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m19:22:23.813410 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m19:22:23.821447 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m19:22:23.823459 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m19:22:23.831239 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m19:22:23.831239 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m19:22:23.833250 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m19:22:23.833250 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:22:24.080323 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-5877-1c2a-86e6-83f56f4f5b52) - Created
[0m19:22:24.650466 [debug] [Thread-2 (]: SQL status: OK in 0.820 seconds
[0m19:22:24.652481 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-5877-1c2a-86e6-83f56f4f5b52, command-id=01f086c1-5881-1bba-b0ff-8cffbdbdb50b) - Closing
[0m19:22:24.654491 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m19:22:24.654491 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-5877-1c2a-86e6-83f56f4f5b52) - Closing
[0m19:22:24.748378 [info ] [Thread-2 (]: 5 of 6 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 0.93s]
[0m19:22:24.749490 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m19:22:24.749490 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m19:22:24.750676 [info ] [Thread-2 (]: 6 of 6 START test unique_bronze_store_store_sk ................................. [RUN]
[0m19:22:24.752355 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m19:22:24.752355 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m19:22:24.752355 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m19:22:24.758743 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m19:22:24.760495 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m19:22:24.762508 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m19:22:24.764532 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m19:22:24.764532 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m19:22:24.764532 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:22:25.027078 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-5906-125a-b86c-134f8eba2620) - Created
[0m19:22:25.569335 [debug] [Thread-2 (]: SQL status: OK in 0.800 seconds
[0m19:22:25.573360 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-5906-125a-b86c-134f8eba2620, command-id=01f086c1-5911-1510-bf3e-40e70fc72c46) - Closing
[0m19:22:25.573360 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m19:22:25.575370 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-5906-125a-b86c-134f8eba2620) - Closing
[0m19:22:25.663939 [info ] [Thread-2 (]: 6 of 6 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 0.91s]
[0m19:22:25.663939 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m19:22:25.667455 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:22:25.667455 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:22:25.667455 [info ] [MainThread]: 
[0m19:22:25.669464 [info ] [MainThread]: Finished running 6 data tests in 0 hours 0 minutes and 10.00 seconds (10.00s).
[0m19:22:25.671981 [debug] [MainThread]: Command end result
[0m19:22:25.828402 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m19:22:25.842201 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m19:22:25.845579 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m19:22:25.853317 [info ] [MainThread]: 
[0m19:22:25.854339 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:22:25.854339 [info ] [MainThread]: 
[0m19:22:25.856346 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m19:22:25.858098 [debug] [MainThread]: Command `dbt test` succeeded at 19:22:25.858098 after 13.65 seconds
[0m19:22:25.858098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001761A64A180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001761AACF470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001761AACFEF0>]}
[0m19:22:25.858098 [debug] [MainThread]: Flushing usage events
[0m19:22:26.347012 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:23:29.453985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022473A72CC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022473F47DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000224704597F0>]}


============================== 19:23:29.455997 | 96fc2841-4993-4415-820b-79d948c0e660 ==============================
[0m19:23:29.455997 [info ] [MainThread]: Running with dbt=1.10.10
[0m19:23:29.455997 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj'}
[0m19:23:30.635120 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:23:30.635120 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:23:30.635120 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:23:31.622618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '96fc2841-4993-4415-820b-79d948c0e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000224740CDE80>]}
[0m19:23:31.701560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '96fc2841-4993-4415-820b-79d948c0e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002247F1D03E0>]}
[0m19:23:31.701560 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:23:32.130895 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m19:23:32.355614 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:23:32.356170 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:23:32.359671 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_databricks_proj.gold
- models.dbt_databricks_proj.silver
[0m19:23:32.421469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96fc2841-4993-4415-820b-79d948c0e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002242324CFB0>]}
[0m19:23:32.534965 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m19:23:32.541005 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m19:23:32.558839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96fc2841-4993-4415-820b-79d948c0e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022423AE10A0>]}
[0m19:23:32.558839 [info ] [MainThread]: Found 6 models, 7 data tests, 6 sources, 687 macros
[0m19:23:32.558839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96fc2841-4993-4415-820b-79d948c0e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002247383ADE0>]}
[0m19:23:32.574529 [info ] [MainThread]: 
[0m19:23:32.574529 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:23:32.574529 [info ] [MainThread]: 
[0m19:23:32.574529 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:23:32.574529 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:23:32.574529 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m19:23:32.574529 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m19:23:32.607129 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m19:23:32.609139 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m19:23:32.609139 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:23:32.923611 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086c1-817f-1b38-b5a2-72fc6373a595) - Created
[0m19:23:33.358305 [debug] [ThreadPool]: SQL status: OK in 0.750 seconds
[0m19:23:33.368397 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086c1-817f-1b38-b5a2-72fc6373a595, command-id=01f086c1-8189-1ee9-afe3-0ebbf9c56474) - Closing
[0m19:23:33.370133 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m19:23:33.370133 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086c1-817f-1b38-b5a2-72fc6373a595) - Closing
[0m19:23:33.458199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96fc2841-4993-4415-820b-79d948c0e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002242373E090>]}
[0m19:23:33.465252 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m19:23:33.467266 [info ] [Thread-2 (]: 1 of 7 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m19:23:33.469278 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m19:23:33.469278 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m19:23:33.469278 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m19:23:33.506892 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m19:23:33.506892 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m19:23:33.532983 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m19:23:33.538224 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m19:23:33.538224 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m19:23:33.538224 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:23:33.796706 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-8204-1fa5-865a-b529eec9f0b9) - Created
[0m19:23:34.176460 [debug] [Thread-2 (]: SQL status: OK in 0.640 seconds
[0m19:23:34.180485 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-8204-1fa5-865a-b529eec9f0b9, command-id=01f086c1-820e-1c3d-a853-df0dcd0528be) - Closing
[0m19:23:34.184500 [debug] [Thread-2 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m19:23:34.184500 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-8204-1fa5-865a-b529eec9f0b9) - Closing
[0m19:23:34.280879 [info ] [Thread-2 (]: 1 of 7 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 0.81s]
[0m19:23:34.282886 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m19:23:34.282886 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m19:23:34.282886 [info ] [Thread-2 (]: 2 of 7 START test non_negitive_bronze_sales_gross_amount ....................... [RUN]
[0m19:23:34.284895 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13) - Creating connection
[0m19:23:34.284895 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13'
[0m19:23:34.286904 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m19:23:34.294689 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m19:23:34.296699 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m19:23:34.300718 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m19:23:34.302725 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m19:23:34.302725 [debug] [Thread-2 (]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

select 
    *
from 
    `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where 
    gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m19:23:34.302725 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:23:34.566981 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-827a-10c8-b906-f171bdc38f87) - Created
[0m19:23:35.301103 [debug] [Thread-2 (]: SQL status: OK in 1.000 seconds
[0m19:23:35.307875 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-827a-10c8-b906-f171bdc38f87, command-id=01f086c1-8284-1ebe-8a67-0727b9480bc9) - Closing
[0m19:23:35.307875 [debug] [Thread-2 (]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: Close
[0m19:23:35.307875 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-827a-10c8-b906-f171bdc38f87) - Closing
[0m19:23:35.395918 [info ] [Thread-2 (]: 2 of 7 PASS non_negitive_bronze_sales_gross_amount ............................. [[32mPASS[0m in 1.11s]
[0m19:23:35.397932 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m19:23:35.397932 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.non_negitive_test
[0m19:23:35.399947 [info ] [Thread-2 (]: 3 of 7 START test non_negitive_test ............................................ [RUN]
[0m19:23:35.401961 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_test) - Creating connection
[0m19:23:35.401961 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_test'
[0m19:23:35.401961 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.non_negitive_test
[0m19:23:35.405989 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_test"
[0m19:23:35.408000 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.non_negitive_test
[0m19:23:35.411028 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_test"
[0m19:23:35.411028 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.non_negitive_test"
[0m19:23:35.413040 [debug] [Thread-2 (]: On test.dbt_databricks_proj.non_negitive_test: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.non_negitive_test"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  select *
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales` 
where gross_amount < 0 and net_amount < 0
  
  
      
    ) dbt_internal_test
[0m19:23:35.413040 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:23:35.713282 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-8329-143a-afd6-716bd3795d51) - Created
[0m19:23:35.930626 [debug] [Thread-2 (]: SQL status: OK in 0.520 seconds
[0m19:23:35.934388 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-8329-143a-afd6-716bd3795d51, command-id=01f086c1-8334-1031-9b15-66b16f3c6da2) - Closing
[0m19:23:35.934388 [debug] [Thread-2 (]: On test.dbt_databricks_proj.non_negitive_test: Close
[0m19:23:35.936399 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-8329-143a-afd6-716bd3795d51) - Closing
[0m19:23:36.011569 [info ] [Thread-2 (]: 3 of 7 PASS non_negitive_test .................................................. [[32mPASS[0m in 0.61s]
[0m19:23:36.026638 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.non_negitive_test
[0m19:23:36.028648 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:23:36.029811 [info ] [Thread-2 (]: 4 of 7 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m19:23:36.030768 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m19:23:36.030768 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m19:23:36.030768 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:23:36.040711 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m19:23:36.046392 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:23:36.049019 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m19:23:36.049019 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m19:23:36.049019 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m19:23:36.055530 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:23:36.306401 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-8384-156d-96fb-073164f2496d) - Created
[0m19:23:36.633719 [debug] [Thread-2 (]: SQL status: OK in 0.580 seconds
[0m19:23:36.635728 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-8384-156d-96fb-073164f2496d, command-id=01f086c1-838d-19dd-8d11-e20085a08eb9) - Closing
[0m19:23:36.637738 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m19:23:36.637738 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-8384-156d-96fb-073164f2496d) - Closing
[0m19:23:36.720342 [info ] [Thread-2 (]: 4 of 7 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.69s]
[0m19:23:36.724372 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:23:36.726386 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m19:23:36.726386 [info ] [Thread-2 (]: 5 of 7 START test not_null_bronze_store_store_sk ............................... [RUN]
[0m19:23:36.726386 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m19:23:36.728401 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m19:23:36.728401 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m19:23:36.738241 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m19:23:36.740623 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m19:23:36.865193 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m19:23:36.865193 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m19:23:36.865193 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m19:23:36.865193 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:23:37.134915 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-8403-123d-a792-a58266a1ed69) - Created
[0m19:23:37.323706 [debug] [Thread-2 (]: SQL status: OK in 0.460 seconds
[0m19:23:37.333596 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-8403-123d-a792-a58266a1ed69, command-id=01f086c1-840d-1592-bd41-bacdb190d5fb) - Closing
[0m19:23:37.333596 [debug] [Thread-2 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m19:23:37.335609 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-8403-123d-a792-a58266a1ed69) - Closing
[0m19:23:37.432036 [info ] [Thread-2 (]: 5 of 7 PASS not_null_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.70s]
[0m19:23:37.432036 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m19:23:37.434042 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m19:23:37.434042 [info ] [Thread-2 (]: 6 of 7 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m19:23:37.436047 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m19:23:37.436047 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m19:23:37.438052 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m19:23:37.448323 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m19:23:37.448323 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m19:23:37.454210 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m19:23:37.454210 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m19:23:37.454210 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m19:23:37.454210 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:23:37.761320 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-845f-1ba8-90c1-983578f8531d) - Created
[0m19:23:38.065644 [debug] [Thread-2 (]: SQL status: OK in 0.610 seconds
[0m19:23:38.069658 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-845f-1ba8-90c1-983578f8531d, command-id=01f086c1-846c-17d3-a746-6fad5a2c7119) - Closing
[0m19:23:38.072073 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m19:23:38.072073 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-845f-1ba8-90c1-983578f8531d) - Closing
[0m19:23:38.148460 [info ] [Thread-2 (]: 6 of 7 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 0.71s]
[0m19:23:38.154584 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m19:23:38.156590 [debug] [Thread-2 (]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m19:23:38.156590 [info ] [Thread-2 (]: 7 of 7 START test unique_bronze_store_store_sk ................................. [RUN]
[0m19:23:38.158597 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m19:23:38.158597 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m19:23:38.158597 [debug] [Thread-2 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m19:23:38.170939 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m19:23:38.173316 [debug] [Thread-2 (]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m19:23:38.177700 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m19:23:38.177700 [debug] [Thread-2 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m19:23:38.179614 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m19:23:38.180702 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:23:38.441468 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-84c8-1e28-a6f4-1cc97d267af4) - Created
[0m19:23:38.678609 [debug] [Thread-2 (]: SQL status: OK in 0.500 seconds
[0m19:23:38.678609 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f086c1-84c8-1e28-a6f4-1cc97d267af4, command-id=01f086c1-84d3-18e5-8a04-7197e1a1fb3f) - Closing
[0m19:23:38.678609 [debug] [Thread-2 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m19:23:38.678609 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f086c1-84c8-1e28-a6f4-1cc97d267af4) - Closing
[0m19:23:38.763255 [info ] [Thread-2 (]: 7 of 7 PASS unique_bronze_store_store_sk ....................................... [[32mPASS[0m in 0.61s]
[0m19:23:38.763255 [debug] [Thread-2 (]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m19:23:38.763255 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:23:38.763255 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:23:38.763255 [info ] [MainThread]: 
[0m19:23:38.763255 [info ] [MainThread]: Finished running 7 data tests in 0 hours 0 minutes and 6.19 seconds (6.19s).
[0m19:23:38.775397 [debug] [MainThread]: Command end result
[0m19:23:38.830324 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m19:23:38.830324 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m19:23:38.847208 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m19:23:38.847208 [info ] [MainThread]: 
[0m19:23:38.849215 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:23:38.849215 [info ] [MainThread]: 
[0m19:23:38.851223 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m19:23:38.851223 [debug] [MainThread]: Command `dbt test` succeeded at 19:23:38.851223 after 9.58 seconds
[0m19:23:38.851223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000224704597F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002247340EC00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002247338FA10>]}
[0m19:23:38.854046 [debug] [MainThread]: Flushing usage events
[0m19:23:39.322529 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:01:43.562011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDAF3A8B00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDB03334A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDB02290D0>]}


============================== 22:01:43.569436 | 288f4258-a554-45c4-9887-6db4573b6dee ==============================
[0m22:01:43.569436 [info ] [MainThread]: Running with dbt=1.10.10
[0m22:01:43.569436 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt seed', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'printer_width': '80', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj'}
[0m22:01:44.761577 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m22:01:44.761577 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m22:01:44.761577 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m22:01:45.857981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '288f4258-a554-45c4-9887-6db4573b6dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDAFE64F80>]}
[0m22:01:45.958274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '288f4258-a554-45c4-9887-6db4573b6dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDAF7ECBF0>]}
[0m22:01:45.958274 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m22:01:46.442990 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m22:01:46.657501 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:01:46.657501 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:01:46.665411 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_databricks_proj.gold
- models.dbt_databricks_proj.silver
[0m22:01:46.724216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '288f4258-a554-45c4-9887-6db4573b6dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDF90ECF0>]}
[0m22:01:46.841503 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m22:01:46.842737 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m22:01:46.920242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '288f4258-a554-45c4-9887-6db4573b6dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDFBBF410>]}
[0m22:01:46.921436 [info ] [MainThread]: Found 6 models, 7 data tests, 1 seed, 6 sources, 687 macros
[0m22:01:46.922213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '288f4258-a554-45c4-9887-6db4573b6dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDF32F6E0>]}
[0m22:01:46.925172 [info ] [MainThread]: 
[0m22:01:46.925645 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:01:46.926036 [info ] [MainThread]: 
[0m22:01:46.926036 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m22:01:46.926036 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:01:46.928355 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m22:01:46.930215 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m22:01:46.930215 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m22:01:46.930215 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m22:01:46.932309 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:01:47.730425 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086d7-9c96-12fd-97c0-e491d9d12283) - Created
[0m22:02:49.366292 [debug] [ThreadPool]: SQL status: OK in 62.430 seconds
[0m22:02:49.368308 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086d7-9c96-12fd-97c0-e491d9d12283, command-id=01f086d7-c09c-13c8-8368-fd8b6f88f713) - Closing
[0m22:02:49.370325 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m22:02:49.370325 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086d7-9c96-12fd-97c0-e491d9d12283) - Closing
[0m22:02:49.479943 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m22:02:49.482162 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m22:02:49.500124 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m22:02:49.500124 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m22:02:49.500124 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:02:49.869876 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086d7-c1c4-1332-b048-cf80df227f90) - Created
[0m22:02:53.170329 [debug] [ThreadPool]: SQL status: OK in 3.670 seconds
[0m22:02:53.180054 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086d7-c1c4-1332-b048-cf80df227f90, command-id=01f086d7-c1d0-1ee6-b94a-18699abe471a) - Closing
[0m22:02:53.180054 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m22:02:53.182425 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086d7-c1c4-1332-b048-cf80df227f90) - Closing
[0m22:02:53.282079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '288f4258-a554-45c4-9887-6db4573b6dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDB042CBF0>]}
[0m22:02:53.285821 [debug] [Thread-3 (]: Began running node seed.dbt_databricks_proj.lookup
[0m22:02:53.285821 [info ] [Thread-3 (]: 1 of 1 START seed file bronze.lookup ........................................... [RUN]
[0m22:02:53.288955 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_databricks_proj.lookup) - Creating connection
[0m22:02:53.289963 [debug] [Thread-3 (]: Acquiring new databricks connection 'seed.dbt_databricks_proj.lookup'
[0m22:02:53.289963 [debug] [Thread-3 (]: Began compiling node seed.dbt_databricks_proj.lookup
[0m22:02:53.289963 [debug] [Thread-3 (]: Began executing node seed.dbt_databricks_proj.lookup
[0m22:02:53.297949 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m22:02:53.299174 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '288f4258-a554-45c4-9887-6db4573b6dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDFC52060>]}
[0m22:02:53.366112 [debug] [Thread-3 (]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m22:02:53.370065 [debug] [Thread-3 (]: On seed.dbt_databricks_proj.lookup: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "seed.dbt_databricks_proj.lookup"} */

    create  table `dbt_databricks_proj_dev`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_email` string )
    
  using delta
    
    
    
    
    
  
[0m22:02:53.370065 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m22:02:53.639855 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086d7-c406-15cb-bb52-3dba0cf30b81) - Created
[0m22:02:59.276776 [debug] [Thread-3 (]: SQL status: OK in 5.910 seconds
[0m22:02:59.278785 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086d7-c406-15cb-bb52-3dba0cf30b81, command-id=01f086d7-c410-1395-b153-4e13bb9e6de5) - Closing
[0m22:02:59.403289 [debug] [Thread-3 (]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m22:02:59.403289 [debug] [Thread-3 (]: On seed.dbt_databricks_proj.lookup: 
          insert overwrite `dbt_databricks_proj_dev`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m22:03:06.321056 [debug] [Thread-3 (]: SQL status: OK in 6.920 seconds
[0m22:03:06.322976 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f086d7-c406-15cb-bb52-3dba0cf30b81, command-id=01f086d7-c77f-17dd-b0c5-b5dfd8d70533) - Closing
[0m22:03:06.450646 [debug] [Thread-3 (]: Writing runtime SQL for node "seed.dbt_databricks_proj.lookup"
[0m22:03:06.468408 [debug] [Thread-3 (]: On seed.dbt_databricks_proj.lookup: Close
[0m22:03:06.468408 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f086d7-c406-15cb-bb52-3dba0cf30b81) - Closing
[0m22:03:06.564039 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '288f4258-a554-45c4-9887-6db4573b6dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDDF6C3590>]}
[0m22:03:06.564039 [info ] [Thread-3 (]: 1 of 1 OK loaded seed file bronze.lookup ....................................... [[32mINSERT 3[0m in 13.27s]
[0m22:03:06.566287 [debug] [Thread-3 (]: Finished running node seed.dbt_databricks_proj.lookup
[0m22:03:06.568735 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m22:03:06.569278 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:03:06.569785 [info ] [MainThread]: 
[0m22:03:06.570595 [info ] [MainThread]: Finished running 1 seed in 0 hours 1 minutes and 19.64 seconds (79.64s).
[0m22:03:06.570595 [debug] [MainThread]: Command end result
[0m22:03:06.612799 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m22:03:06.618392 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m22:03:06.629397 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m22:03:06.629397 [info ] [MainThread]: 
[0m22:03:06.631151 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:03:06.632262 [info ] [MainThread]: 
[0m22:03:06.632262 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m22:03:06.632262 [debug] [MainThread]: Command `dbt seed` succeeded at 22:03:06.632262 after 83.27 seconds
[0m22:03:06.632262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDAF76E120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDAF76DEB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DDAF76ECF0>]}
[0m22:03:06.635534 [debug] [MainThread]: Flushing usage events
[0m22:03:07.107144 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:42:58.006970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EACC4AB440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EACC4AB800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EACC4A9400>]}


============================== 00:42:58.013763 | b676f2c2-cb20-4f93-9bd4-8ce7b936bf16 ==============================
[0m00:42:58.013763 [info ] [MainThread]: Running with dbt=1.10.10
[0m00:42:58.013763 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run --select models/silver', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m00:42:59.169005 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m00:42:59.169005 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m00:42:59.169005 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m00:43:00.216538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b676f2c2-cb20-4f93-9bd4-8ce7b936bf16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAFBD38560>]}
[0m00:43:00.300468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b676f2c2-cb20-4f93-9bd4-8ce7b936bf16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EACF5C1640>]}
[0m00:43:00.300468 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m00:43:00.909410 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m00:43:01.165374 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:43:01.165374 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:43:01.174638 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_proj.gold
[0m00:43:01.252236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b676f2c2-cb20-4f93-9bd4-8ce7b936bf16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAFBE329F0>]}
[0m00:43:01.382165 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m00:43:01.420665 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m00:43:01.447191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b676f2c2-cb20-4f93-9bd4-8ce7b936bf16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAFC2DCDA0>]}
[0m00:43:01.448575 [info ] [MainThread]: Found 7 models, 7 data tests, 1 seed, 4 analyses, 6 sources, 688 macros
[0m00:43:01.449534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b676f2c2-cb20-4f93-9bd4-8ce7b936bf16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAFB4F0830>]}
[0m00:43:01.451733 [info ] [MainThread]: 
[0m00:43:01.454462 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:43:01.454973 [info ] [MainThread]: 
[0m00:43:01.456273 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m00:43:01.457201 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m00:43:01.458224 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m00:43:01.458224 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m00:43:01.458224 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m00:43:01.460297 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m00:43:01.460297 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:43:01.829871 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ee-22e6-1f3b-9852-a9f00c3110ba) - Created
[0m00:43:02.326477 [debug] [ThreadPool]: SQL status: OK in 0.870 seconds
[0m00:43:02.328492 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086ee-22e6-1f3b-9852-a9f00c3110ba, command-id=01f086ee-22f2-133e-bb2c-6e24609266ea) - Closing
[0m00:43:02.328492 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m00:43:02.330501 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ee-22e6-1f3b-9852-a9f00c3110ba) - Closing
[0m00:43:02.411914 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_databricks_proj_dev_silver) - Creating connection
[0m00:43:02.411914 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_databricks_proj_dev_silver'
[0m00:43:02.413926 [debug] [ThreadPool]: Creating schema "database: "dbt_databricks_proj_dev"
schema: "silver"
"
[0m00:43:02.426363 [debug] [ThreadPool]: Using databricks connection "create_dbt_databricks_proj_dev_silver"
[0m00:43:02.426363 [debug] [ThreadPool]: On create_dbt_databricks_proj_dev_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "create_dbt_databricks_proj_dev_silver"} */
create schema if not exists `dbt_databricks_proj_dev`.`silver`
  
[0m00:43:02.427870 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:43:02.686400 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ee-236a-1100-9e91-3f1b6792e779) - Created
[0m00:43:03.455046 [debug] [ThreadPool]: SQL status: OK in 1.030 seconds
[0m00:43:03.455046 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086ee-236a-1100-9e91-3f1b6792e779, command-id=01f086ee-2374-1648-91a1-17e33345cfff) - Closing
[0m00:43:03.455046 [debug] [ThreadPool]: On create_dbt_databricks_proj_dev_silver: Close
[0m00:43:03.455046 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ee-236a-1100-9e91-3f1b6792e779) - Closing
[0m00:43:03.563129 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_silver) - Creating connection
[0m00:43:03.563129 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_silver'
[0m00:43:03.570897 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_silver"
[0m00:43:03.570897 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'silver'

  
[0m00:43:03.570897 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:43:03.827441 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ee-2418-1bee-a9c3-ae35d807b2ca) - Created
[0m00:43:04.684084 [debug] [ThreadPool]: SQL status: OK in 1.110 seconds
[0m00:43:04.691942 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086ee-2418-1bee-a9c3-ae35d807b2ca, command-id=01f086ee-2423-146f-a74b-90cc2757393a) - Closing
[0m00:43:04.691942 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_silver: Close
[0m00:43:04.691942 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ee-2418-1bee-a9c3-ae35d807b2ca) - Closing
[0m00:43:04.776449 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m00:43:04.777955 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m00:43:04.781965 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m00:43:04.781965 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m00:43:04.781965 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:43:05.037525 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ee-24d0-1551-87c3-393a0424c9a1) - Created
[0m00:43:05.915721 [debug] [ThreadPool]: SQL status: OK in 1.130 seconds
[0m00:43:05.921766 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f086ee-24d0-1551-87c3-393a0424c9a1, command-id=01f086ee-24dd-13f0-ba9e-d663a96ddff3) - Closing
[0m00:43:05.921766 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m00:43:05.923780 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f086ee-24d0-1551-87c3-393a0424c9a1) - Closing
[0m00:43:06.021238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b676f2c2-cb20-4f93-9bd4-8ce7b936bf16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EACB8FD0D0>]}
[0m00:43:06.026646 [debug] [Thread-5 (]: Began running node model.dbt_databricks_proj.silver_salesinfo
[0m00:43:06.026646 [info ] [Thread-5 (]: 1 of 1 START sql table model silver.silver_salesinfo ........................... [RUN]
[0m00:43:06.029534 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.silver_salesinfo) - Creating connection
[0m00:43:06.030597 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.silver_salesinfo'
[0m00:43:06.030597 [debug] [Thread-5 (]: Began compiling node model.dbt_databricks_proj.silver_salesinfo
[0m00:43:06.051842 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_databricks_proj.silver_salesinfo"
[0m00:43:06.055244 [debug] [Thread-5 (]: Began executing node model.dbt_databricks_proj.silver_salesinfo
[0m00:43:06.068660 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m00:43:06.080727 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m00:43:06.081733 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'b676f2c2-cb20-4f93-9bd4-8ce7b936bf16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAFC36E4E0>]}
[0m00:43:06.141333 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_databricks_proj.silver_salesinfo"
[0m00:43:06.143923 [debug] [Thread-5 (]: Using databricks connection "model.dbt_databricks_proj.silver_salesinfo"
[0m00:43:06.143923 [debug] [Thread-5 (]: On model.dbt_databricks_proj.silver_salesinfo: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.silver_salesinfo"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`silver`.`silver_salesinfo`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with customers as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_customer`
),
products as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
),
sales as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
),
joined_data as (

select 
    s.sales_id,
    
    s.quantity * s.unit_price
 as gross_amount,
    
    s.payment_method,
    c.gender,
    p.category
from sales s
join customers c on s.customer_sk = c.customer_sk  
join products p on s.product_sk = p.product_sk

)

select 
    category,
    gender,
    sum(gross_amount) as total_gross_amount
from joined_data
group by 
    category,gender
order by
    total_gross_amount desc
  
[0m00:43:06.143923 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m00:43:06.404579 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f086ee-25a2-11d2-99a7-521f140b640c) - Created
[0m00:43:14.033063 [debug] [Thread-5 (]: SQL status: OK in 7.890 seconds
[0m00:43:14.035070 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f086ee-25a2-11d2-99a7-521f140b640c, command-id=01f086ee-25ac-15f8-b612-f1166844979d) - Closing
[0m00:43:14.149302 [debug] [Thread-5 (]: Applying tags to relation None
[0m00:43:14.169092 [debug] [Thread-5 (]: On model.dbt_databricks_proj.silver_salesinfo: Close
[0m00:43:14.169092 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f086ee-25a2-11d2-99a7-521f140b640c) - Closing
[0m00:43:14.260036 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b676f2c2-cb20-4f93-9bd4-8ce7b936bf16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAC99F38C0>]}
[0m00:43:14.264258 [info ] [Thread-5 (]: 1 of 1 OK created sql table model silver.silver_salesinfo ...................... [[32mOK[0m in 8.23s]
[0m00:43:14.264675 [debug] [Thread-5 (]: Finished running node model.dbt_databricks_proj.silver_salesinfo
[0m00:43:14.264675 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m00:43:14.264675 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m00:43:14.264675 [info ] [MainThread]: 
[0m00:43:14.264675 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 12.81 seconds (12.81s).
[0m00:43:14.271600 [debug] [MainThread]: Command end result
[0m00:43:14.426322 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m00:43:14.426322 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m00:43:14.434861 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m00:43:14.434861 [info ] [MainThread]: 
[0m00:43:14.434861 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:43:14.434861 [info ] [MainThread]: 
[0m00:43:14.434861 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m00:43:14.434861 [debug] [MainThread]: Command `dbt run` succeeded at 00:43:14.434861 after 16.64 seconds
[0m00:43:14.434861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EACC305E20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EACC3057C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EACF60DF70>]}
[0m00:43:14.434861 [debug] [MainThread]: Flushing usage events
[0m00:43:14.916101 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:51:40.718076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B39D40770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B3B65DEB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B3B65C7A0>]}


============================== 10:51:40.728106 | 6f927096-5ab9-403b-ab07-b0da150a598f ==============================
[0m10:51:40.728106 [info ] [MainThread]: Running with dbt=1.10.10
[0m10:51:40.728106 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt snapshot', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'static_parser': 'True', 'write_json': 'True'}
[0m10:51:41.928240 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:51:41.928240 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:51:41.928240 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:51:42.948032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6f927096-5ab9-403b-ab07-b0da150a598f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B69367170>]}
[0m10:51:43.028240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6f927096-5ab9-403b-ab07-b0da150a598f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B6ADD4860>]}
[0m10:51:43.028240 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m10:51:43.618123 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m10:51:43.898122 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:51:43.898122 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_proj://snapshots\gold_items.yml
[0m10:51:44.199065 [error] [MainThread]: Encountered an error:
Compilation Error
  Snapshot 'snapshot.dbt_databricks_proj.gold_items_snapshot' (snapshots\gold_items.yml) depends on a node named 'gold_items' which was not found
[0m10:51:44.199065 [debug] [MainThread]: Command `dbt snapshot` failed at 10:51:44.199065 after 3.71 seconds
[0m10:51:44.208124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B3BFD8320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B6BB5A150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B6BB5A180>]}
[0m10:51:44.208124 [debug] [MainThread]: Flushing usage events
[0m10:51:44.707969 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:52:26.364267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017547A8BD70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000175474BF020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000175474BFD70>]}


============================== 10:52:26.373257 | 21522e58-a223-49a9-90ed-a75a01e6ec53 ==============================
[0m10:52:26.373257 [info ] [MainThread]: Running with dbt=1.10.10
[0m10:52:26.373257 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj'}
[0m10:52:27.518124 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:52:27.518124 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:52:27.520179 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:52:28.520060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '21522e58-a223-49a9-90ed-a75a01e6ec53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017576D78C80>]}
[0m10:52:28.598006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '21522e58-a223-49a9-90ed-a75a01e6ec53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017576D78800>]}
[0m10:52:28.598006 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m10:52:29.004266 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m10:52:29.249126 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:52:29.249126 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_proj://snapshots\gold_items.yml
[0m10:52:29.540160 [error] [MainThread]: Encountered an error:
Compilation Error
  Snapshot 'snapshot.dbt_databricks_proj.gold_items_snapshot' (snapshots\gold_items.yml) depends on a node named 'gold_items' which was not found
[0m10:52:29.540160 [debug] [MainThread]: Command `dbt build` failed at 10:52:29.540160 after 3.37 seconds
[0m10:52:29.540160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001754498C2C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017547C8E2D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017576E255B0>]}
[0m10:52:29.540160 [debug] [MainThread]: Flushing usage events
[0m10:52:29.990998 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:53:17.483043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E0228F650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E04DBE090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E04DBF590>]}


============================== 10:53:17.486347 | b608b72c-c4f5-44b4-bd44-0028bd8b826b ==============================
[0m10:53:17.486347 [info ] [MainThread]: Running with dbt=1.10.10
[0m10:53:17.486347 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'empty': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj'}
[0m10:53:18.504064 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:53:18.504064 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:53:18.504064 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:53:19.534448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b608b72c-c4f5-44b4-bd44-0028bd8b826b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E34407EF0>]}
[0m10:53:19.619413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b608b72c-c4f5-44b4-bd44-0028bd8b826b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E33C2F1D0>]}
[0m10:53:19.620661 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m10:53:20.046800 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m10:53:20.289490 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:53:20.297515 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_proj://snapshots\gold_items.yml
[0m10:53:20.563620 [error] [MainThread]: Encountered an error:
Compilation Error
  Snapshot 'snapshot.dbt_databricks_proj.gold_items_snapshot' (snapshots\gold_items.yml) depends on a node named 'gold_items' which was not found
[0m10:53:20.578050 [debug] [MainThread]: Command `dbt run` failed at 10:53:20.578050 after 3.28 seconds
[0m10:53:20.578050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E05325790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E34D44AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E34D47FB0>]}
[0m10:53:20.578050 [debug] [MainThread]: Flushing usage events
[0m10:53:21.036539 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:53:45.771350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D3C4CAB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D397FC320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D3A2CB2C0>]}


============================== 10:53:45.776623 | ebf5224e-2e03-4a68-a5ef-3fd49073015e ==============================
[0m10:53:45.776623 [info ] [MainThread]: Running with dbt=1.10.10
[0m10:53:45.778633 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m10:53:46.830863 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:53:46.830863 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:53:46.830863 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:53:47.746113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D3CAFD1C0>]}
[0m10:53:47.824925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6B76CBF0>]}
[0m10:53:47.824925 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m10:53:48.195050 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m10:53:48.436775 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:53:48.436775 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_proj://snapshots\gold_items.yml
[0m10:53:48.813052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6C5EF1A0>]}
[0m10:53:49.097901 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m10:53:49.127707 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m10:53:49.278228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6C46E030>]}
[0m10:53:49.278228 [info ] [MainThread]: Found 1 seed, 4 analyses, 8 models, 7 data tests, 1 snapshot, 7 sources, 688 macros
[0m10:53:49.282780 [info ] [MainThread]: 
[0m10:53:49.283788 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:53:49.284755 [info ] [MainThread]: 
[0m10:53:49.286491 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:53:49.286491 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:53:49.298042 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m10:53:49.298042 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m10:53:49.298042 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m10:53:49.298042 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m10:53:49.299936 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:49.935424 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-765b-18c8-a687-a821dcc011ad) - Created
[0m10:56:51.413820 [debug] [ThreadPool]: SQL status: OK in 182.110 seconds
[0m10:56:51.417360 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08743-765b-18c8-a687-a821dcc011ad, command-id=01f08743-e1fe-179e-8b66-69d87f30eb2d) - Closing
[0m10:56:51.420171 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m10:56:51.420171 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-765b-18c8-a687-a821dcc011ad) - Closing
[0m10:56:51.517230 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m10:56:51.517230 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m10:56:51.517230 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m10:56:51.517230 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m10:56:51.520931 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:56:51.947626 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e2f9-1c1d-af62-09026f124544) - Created
[0m10:56:52.208466 [debug] [ThreadPool]: SQL status: OK in 0.690 seconds
[0m10:56:52.208466 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08743-e2f9-1c1d-af62-09026f124544, command-id=01f08743-e306-1c09-9eb1-f385f817fc9c) - Closing
[0m10:56:52.208466 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m10:56:52.217604 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e2f9-1c1d-af62-09026f124544) - Closing
[0m10:56:52.298201 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m10:56:52.298201 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m10:56:52.300746 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m10:56:52.300746 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m10:56:52.300746 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:56:52.662958 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e366-18eb-bb74-ab786f3c94a6) - Created
[0m10:56:52.929848 [debug] [ThreadPool]: SQL status: OK in 0.630 seconds
[0m10:56:52.932849 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08743-e366-18eb-bb74-ab786f3c94a6, command-id=01f08743-e374-167d-a895-887c4543cd1f) - Closing
[0m10:56:52.934865 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m10:56:52.934865 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e366-18eb-bb74-ab786f3c94a6) - Closing
[0m10:56:53.031198 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_databricks_proj_dev_gold) - Creating connection
[0m10:56:53.031198 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_databricks_proj_dev_gold'
[0m10:56:53.039266 [debug] [ThreadPool]: Creating schema "database: "dbt_databricks_proj_dev"
schema: "gold"
"
[0m10:56:53.065889 [debug] [ThreadPool]: Using databricks connection "create_dbt_databricks_proj_dev_gold"
[0m10:56:53.067401 [debug] [ThreadPool]: On create_dbt_databricks_proj_dev_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "create_dbt_databricks_proj_dev_gold"} */
create schema if not exists `dbt_databricks_proj_dev`.`gold`
  
[0m10:56:53.067401 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:56:53.412892 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e3d9-1273-a7c4-f6d22a181987) - Created
[0m10:56:54.638157 [debug] [ThreadPool]: SQL status: OK in 1.570 seconds
[0m10:56:54.644677 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08743-e3d9-1273-a7c4-f6d22a181987, command-id=01f08743-e3e6-1b21-9948-d9629a045e5b) - Closing
[0m10:56:54.646379 [debug] [ThreadPool]: On create_dbt_databricks_proj_dev_gold: Close
[0m10:56:54.647397 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e3d9-1273-a7c4-f6d22a181987) - Closing
[0m10:56:54.732715 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_silver) - Creating connection
[0m10:56:54.734728 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_silver'
[0m10:56:54.787923 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_silver"
[0m10:56:54.788830 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'silver'

  
[0m10:56:54.788830 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:56:55.145043 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e4e1-19ec-9081-5ea1827d4865) - Created
[0m10:56:58.158197 [debug] [ThreadPool]: SQL status: OK in 3.370 seconds
[0m10:56:58.167228 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08743-e4e1-19ec-9081-5ea1827d4865, command-id=01f08743-e4ee-195b-8468-a3f8e04809da) - Closing
[0m10:56:58.174507 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_silver: Close
[0m10:56:58.174507 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e4e1-19ec-9081-5ea1827d4865) - Closing
[0m10:56:58.257709 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m10:56:58.257709 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m10:56:58.267112 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m10:56:58.267112 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m10:56:58.267112 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:56:58.629015 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e6f7-1ec3-b0e5-eea6be066182) - Created
[0m10:56:59.203618 [debug] [ThreadPool]: SQL status: OK in 0.940 seconds
[0m10:56:59.211809 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08743-e6f7-1ec3-b0e5-eea6be066182, command-id=01f08743-e702-1472-87d9-94b029a77623) - Closing
[0m10:56:59.213826 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m10:56:59.213826 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e6f7-1ec3-b0e5-eea6be066182) - Closing
[0m10:56:59.301529 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_gold) - Creating connection
[0m10:56:59.307439 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_gold'
[0m10:56:59.317544 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_gold"
[0m10:56:59.317544 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'gold'

  
[0m10:56:59.317544 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:56:59.647114 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e794-1072-ab9a-a01dfd55a6a9) - Created
[0m10:57:00.405607 [debug] [ThreadPool]: SQL status: OK in 1.090 seconds
[0m10:57:00.409543 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08743-e794-1072-ab9a-a01dfd55a6a9, command-id=01f08743-e79d-1e16-925b-0597f897f1e2) - Closing
[0m10:57:00.411553 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_gold: Close
[0m10:57:00.411553 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08743-e794-1072-ab9a-a01dfd55a6a9) - Closing
[0m10:57:00.504942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6C46C500>]}
[0m10:57:00.523484 [debug] [Thread-8 (]: Began running node model.dbt_databricks_proj.bronze_customer
[0m10:57:00.524500 [info ] [Thread-8 (]: 1 of 17 START sql table model bronze.bronze_customer ........................... [RUN]
[0m10:57:00.530439 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_customer) - Creating connection
[0m10:57:00.532458 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_customer'
[0m10:57:00.532458 [debug] [Thread-8 (]: Began compiling node model.dbt_databricks_proj.bronze_customer
[0m10:57:00.557131 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_customer"
[0m10:57:00.567545 [debug] [Thread-8 (]: Began executing node model.dbt_databricks_proj.bronze_customer
[0m10:57:00.612428 [debug] [Thread-8 (]: MATERIALIZING TABLE
[0m10:57:00.613711 [warn ] [Thread-8 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:57:00.614800 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6D627710>]}
[0m10:57:00.726808 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_customer"
[0m10:57:00.733193 [debug] [Thread-8 (]: Using databricks connection "model.dbt_databricks_proj.bronze_customer"
[0m10:57:00.735298 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_customer"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_customer`
  
[0m10:57:00.735827 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:01.077330 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-e86d-1d1b-914b-a78597c71ece) - Created
[0m10:57:11.319376 [debug] [Thread-8 (]: SQL status: OK in 10.580 seconds
[0m10:57:11.319376 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-e86d-1d1b-914b-a78597c71ece, command-id=01f08743-e877-1525-a3aa-cfc682402fe4) - Closing
[0m10:57:11.467425 [debug] [Thread-8 (]: Applying tags to relation None
[0m10:57:11.531423 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_customer: Close
[0m10:57:11.531423 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-e86d-1d1b-914b-a78597c71ece) - Closing
[0m10:57:11.613466 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6D62F8C0>]}
[0m10:57:11.615728 [info ] [Thread-8 (]: 1 of 17 OK created sql table model bronze.bronze_customer ...................... [[32mOK[0m in 11.08s]
[0m10:57:11.617967 [debug] [Thread-8 (]: Finished running node model.dbt_databricks_proj.bronze_customer
[0m10:57:11.619198 [debug] [Thread-8 (]: Began running node model.dbt_databricks_proj.bronze_date
[0m10:57:11.620275 [info ] [Thread-8 (]: 2 of 17 START sql view model bronze.bronze_date ................................ [RUN]
[0m10:57:11.622245 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_date) - Creating connection
[0m10:57:11.622901 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_date'
[0m10:57:11.623454 [debug] [Thread-8 (]: Began compiling node model.dbt_databricks_proj.bronze_date
[0m10:57:11.632234 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_date"
[0m10:57:11.634923 [debug] [Thread-8 (]: Began executing node model.dbt_databricks_proj.bronze_date
[0m10:57:11.668562 [debug] [Thread-8 (]: MATERIALIZING VIEW
[0m10:57:11.697306 [debug] [Thread-8 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_date`
[0m10:57:11.701713 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_date"
[0m10:57:11.701713 [debug] [Thread-8 (]: Using databricks connection "model.dbt_databricks_proj.bronze_date"
[0m10:57:11.705758 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_date"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_date`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`dim_date`
  )

[0m10:57:11.707270 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:12.077201 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-eefb-1cc1-8bc0-e421b2cb1f05) - Created
[0m10:57:12.997403 [debug] [Thread-8 (]: SQL status: OK in 1.290 seconds
[0m10:57:13.002167 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-eefb-1cc1-8bc0-e421b2cb1f05, command-id=01f08743-ef06-1ee9-aedc-da6b3088ffe9) - Closing
[0m10:57:13.002167 [debug] [Thread-8 (]: Applying tags to relation None
[0m10:57:13.014763 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_date: Close
[0m10:57:13.014763 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-eefb-1cc1-8bc0-e421b2cb1f05) - Closing
[0m10:57:13.107810 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6C0F04A0>]}
[0m10:57:13.110228 [info ] [Thread-8 (]: 2 of 17 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 1.49s]
[0m10:57:13.110228 [debug] [Thread-8 (]: Finished running node model.dbt_databricks_proj.bronze_date
[0m10:57:13.110228 [debug] [Thread-8 (]: Began running node model.dbt_databricks_proj.bronze_product
[0m10:57:13.113699 [info ] [Thread-8 (]: 3 of 17 START sql view model bronze.bronze_product ............................. [RUN]
[0m10:57:13.115444 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_product) - Creating connection
[0m10:57:13.116960 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_product'
[0m10:57:13.119023 [debug] [Thread-8 (]: Began compiling node model.dbt_databricks_proj.bronze_product
[0m10:57:13.127296 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_product"
[0m10:57:13.132199 [debug] [Thread-8 (]: Began executing node model.dbt_databricks_proj.bronze_product
[0m10:57:13.136941 [debug] [Thread-8 (]: MATERIALIZING VIEW
[0m10:57:13.139952 [debug] [Thread-8 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
[0m10:57:13.139952 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_product"
[0m10:57:13.145263 [debug] [Thread-8 (]: Using databricks connection "model.dbt_databricks_proj.bronze_product"
[0m10:57:13.146158 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_product"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`dim_product`
  )

[0m10:57:13.147168 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:13.484319 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-efd2-11fb-9872-53c70e6ae26e) - Created
[0m10:57:14.023173 [debug] [Thread-8 (]: SQL status: OK in 0.880 seconds
[0m10:57:14.027368 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-efd2-11fb-9872-53c70e6ae26e, command-id=01f08743-efdc-1d6a-b281-687d773bf2d8) - Closing
[0m10:57:14.027368 [debug] [Thread-8 (]: Applying tags to relation None
[0m10:57:14.031890 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_product: Close
[0m10:57:14.032902 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-efd2-11fb-9872-53c70e6ae26e) - Closing
[0m10:57:14.123374 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6D5CF9E0>]}
[0m10:57:14.125384 [info ] [Thread-8 (]: 3 of 17 OK created sql view model bronze.bronze_product ........................ [[32mOK[0m in 1.01s]
[0m10:57:14.127392 [debug] [Thread-8 (]: Finished running node model.dbt_databricks_proj.bronze_product
[0m10:57:14.127392 [debug] [Thread-8 (]: Began running node model.dbt_databricks_proj.bronze_returns
[0m10:57:14.130119 [info ] [Thread-8 (]: 4 of 17 START sql table model bronze.bronze_returns ............................ [RUN]
[0m10:57:14.132133 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_returns) - Creating connection
[0m10:57:14.132133 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_returns'
[0m10:57:14.132133 [debug] [Thread-8 (]: Began compiling node model.dbt_databricks_proj.bronze_returns
[0m10:57:14.142324 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_returns"
[0m10:57:14.145875 [debug] [Thread-8 (]: Began executing node model.dbt_databricks_proj.bronze_returns
[0m10:57:14.151791 [debug] [Thread-8 (]: MATERIALIZING TABLE
[0m10:57:14.152607 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_returns"
[0m10:57:14.157084 [debug] [Thread-8 (]: Using databricks connection "model.dbt_databricks_proj.bronze_returns"
[0m10:57:14.157084 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_returns"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`fact_returns`
  
[0m10:57:14.160220 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:14.517048 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f06f-1e1f-8cf8-5e825c3a9942) - Created
[0m10:57:17.708773 [debug] [Thread-8 (]: SQL status: OK in 3.550 seconds
[0m10:57:17.716459 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-f06f-1e1f-8cf8-5e825c3a9942, command-id=01f08743-f07a-1c6d-8e50-9503338a1d36) - Closing
[0m10:57:17.716969 [debug] [Thread-8 (]: Applying tags to relation None
[0m10:57:17.716969 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_returns: Close
[0m10:57:17.716969 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f06f-1e1f-8cf8-5e825c3a9942) - Closing
[0m10:57:17.807280 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6D670830>]}
[0m10:57:17.811332 [info ] [Thread-8 (]: 4 of 17 OK created sql table model bronze.bronze_returns ....................... [[32mOK[0m in 3.67s]
[0m10:57:17.817122 [debug] [Thread-8 (]: Finished running node model.dbt_databricks_proj.bronze_returns
[0m10:57:17.819242 [debug] [Thread-8 (]: Began running node model.dbt_databricks_proj.bronze_sales
[0m10:57:17.819242 [info ] [Thread-8 (]: 5 of 17 START sql view model bronze.bronze_sales ............................... [RUN]
[0m10:57:17.823271 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_sales) - Creating connection
[0m10:57:17.823271 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_sales'
[0m10:57:17.823271 [debug] [Thread-8 (]: Began compiling node model.dbt_databricks_proj.bronze_sales
[0m10:57:17.834891 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_sales"
[0m10:57:17.839520 [debug] [Thread-8 (]: Began executing node model.dbt_databricks_proj.bronze_sales
[0m10:57:17.854977 [debug] [Thread-8 (]: MATERIALIZING VIEW
[0m10:57:17.857607 [debug] [Thread-8 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
[0m10:57:17.860803 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_sales"
[0m10:57:17.864665 [debug] [Thread-8 (]: Using databricks connection "model.dbt_databricks_proj.bronze_sales"
[0m10:57:17.864665 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_sales"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`fact_sales`
  )

[0m10:57:17.864665 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:18.215207 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f2a3-1936-953a-b6f596dd3be1) - Created
[0m10:57:18.701667 [debug] [Thread-8 (]: SQL status: OK in 0.840 seconds
[0m10:57:18.706986 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-f2a3-1936-953a-b6f596dd3be1, command-id=01f08743-f2ae-1870-a0da-8683fc09a1e0) - Closing
[0m10:57:18.709943 [debug] [Thread-8 (]: Applying tags to relation None
[0m10:57:18.711860 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_sales: Close
[0m10:57:18.713876 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f2a3-1936-953a-b6f596dd3be1) - Closing
[0m10:57:18.815031 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6D689E50>]}
[0m10:57:18.817042 [info ] [Thread-8 (]: 5 of 17 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 0.99s]
[0m10:57:18.820117 [debug] [Thread-8 (]: Finished running node model.dbt_databricks_proj.bronze_sales
[0m10:57:18.820117 [debug] [Thread-8 (]: Began running node model.dbt_databricks_proj.bronze_store
[0m10:57:18.820117 [info ] [Thread-8 (]: 6 of 17 START sql table model bronze.bronze_store .............................. [RUN]
[0m10:57:18.820117 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_store) - Creating connection
[0m10:57:18.831268 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_store'
[0m10:57:18.831268 [debug] [Thread-8 (]: Began compiling node model.dbt_databricks_proj.bronze_store
[0m10:57:18.843530 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_store"
[0m10:57:18.847285 [debug] [Thread-8 (]: Began executing node model.dbt_databricks_proj.bronze_store
[0m10:57:18.851441 [debug] [Thread-8 (]: MATERIALIZING TABLE
[0m10:57:18.855561 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_store"
[0m10:57:18.859223 [debug] [Thread-8 (]: Using databricks connection "model.dbt_databricks_proj.bronze_store"
[0m10:57:18.860788 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_store"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_store`
  
[0m10:57:18.862550 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:19.210250 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f33d-1329-937d-731dd773ce8a) - Created
[0m10:57:22.208706 [debug] [Thread-8 (]: SQL status: OK in 3.350 seconds
[0m10:57:22.219487 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-f33d-1329-937d-731dd773ce8a, command-id=01f08743-f347-1999-aa56-8a289cbd6713) - Closing
[0m10:57:22.219487 [debug] [Thread-8 (]: Applying tags to relation None
[0m10:57:22.219487 [debug] [Thread-8 (]: On model.dbt_databricks_proj.bronze_store: Close
[0m10:57:22.225363 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f33d-1329-937d-731dd773ce8a) - Closing
[0m10:57:22.299479 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6D5C9BB0>]}
[0m10:57:22.299479 [info ] [Thread-8 (]: 6 of 17 OK created sql table model bronze.bronze_store ......................... [[32mOK[0m in 3.48s]
[0m10:57:22.304790 [debug] [Thread-8 (]: Finished running node model.dbt_databricks_proj.bronze_store
[0m10:57:22.304790 [debug] [Thread-8 (]: Began running node model.dbt_databricks_proj.source_gold_items
[0m10:57:22.307613 [info ] [Thread-8 (]: 7 of 17 START sql table model gold.source_gold_items ........................... [RUN]
[0m10:57:22.309623 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.source_gold_items) - Creating connection
[0m10:57:22.311638 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.source_gold_items'
[0m10:57:22.311638 [debug] [Thread-8 (]: Began compiling node model.dbt_databricks_proj.source_gold_items
[0m10:57:22.319462 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_databricks_proj.source_gold_items"
[0m10:57:22.323485 [debug] [Thread-8 (]: Began executing node model.dbt_databricks_proj.source_gold_items
[0m10:57:22.328538 [debug] [Thread-8 (]: MATERIALIZING TABLE
[0m10:57:22.331813 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_databricks_proj.source_gold_items"
[0m10:57:22.331813 [debug] [Thread-8 (]: Using databricks connection "model.dbt_databricks_proj.source_gold_items"
[0m10:57:22.337118 [debug] [Thread-8 (]: On model.dbt_databricks_proj.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.source_gold_items"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`gold`.`source_gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with cte1 as (
select *,
row_number() over (partition by id order by updatedDate desc) as dedup_id
from 
`dbt_databricks_proj_dev`.`source`.`items`

)

select id,name,category,updatedDate from cte1
where dedup_id=1
  
[0m10:57:22.337651 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:22.657048 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f54a-1756-b3a8-509db2443207) - Created
[0m10:57:26.211673 [debug] [Thread-8 (]: SQL status: OK in 3.870 seconds
[0m10:57:26.214676 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-f54a-1756-b3a8-509db2443207, command-id=01f08743-f554-1aac-a043-335cfd9330d3) - Closing
[0m10:57:26.218318 [debug] [Thread-8 (]: Applying tags to relation None
[0m10:57:26.220998 [debug] [Thread-8 (]: On model.dbt_databricks_proj.source_gold_items: Close
[0m10:57:26.220998 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f54a-1756-b3a8-509db2443207) - Closing
[0m10:57:26.299106 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6C341DF0>]}
[0m10:57:26.299106 [info ] [Thread-8 (]: 7 of 17 OK created sql table model gold.source_gold_items ...................... [[32mOK[0m in 3.99s]
[0m10:57:26.307112 [debug] [Thread-8 (]: Finished running node model.dbt_databricks_proj.source_gold_items
[0m10:57:26.307112 [debug] [Thread-8 (]: Began running node seed.dbt_databricks_proj.lookup
[0m10:57:26.309850 [info ] [Thread-8 (]: 8 of 17 START seed file bronze.lookup .......................................... [RUN]
[0m10:57:26.312875 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_databricks_proj.lookup) - Creating connection
[0m10:57:26.312875 [debug] [Thread-8 (]: Acquiring new databricks connection 'seed.dbt_databricks_proj.lookup'
[0m10:57:26.312875 [debug] [Thread-8 (]: Began compiling node seed.dbt_databricks_proj.lookup
[0m10:57:26.315625 [debug] [Thread-8 (]: Began executing node seed.dbt_databricks_proj.lookup
[0m10:57:26.398493 [debug] [Thread-8 (]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m10:57:26.398493 [debug] [Thread-8 (]: On seed.dbt_databricks_proj.lookup: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "seed.dbt_databricks_proj.lookup"} */

    create or replace table `dbt_databricks_proj_dev`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_email` string )
    
  using delta
    
    
    
    
    
  
[0m10:57:26.398493 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:26.773523 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f7bd-1953-816f-c0892772815a) - Created
[0m10:57:28.359922 [debug] [Thread-8 (]: SQL status: OK in 1.960 seconds
[0m10:57:28.359922 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-f7bd-1953-816f-c0892772815a, command-id=01f08743-f7c8-1b4a-83c2-861bd0573363) - Closing
[0m10:57:28.400409 [debug] [Thread-8 (]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m10:57:28.408849 [debug] [Thread-8 (]: On seed.dbt_databricks_proj.lookup: 
          insert overwrite `dbt_databricks_proj_dev`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m10:57:29.895112 [debug] [Thread-8 (]: SQL status: OK in 1.480 seconds
[0m10:57:29.897200 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-f7bd-1953-816f-c0892772815a, command-id=01f08743-f8c2-1827-bf66-b31dcd8d92ac) - Closing
[0m10:57:29.909006 [debug] [Thread-8 (]: Writing runtime SQL for node "seed.dbt_databricks_proj.lookup"
[0m10:57:29.919367 [debug] [Thread-8 (]: On seed.dbt_databricks_proj.lookup: Close
[0m10:57:29.919367 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f7bd-1953-816f-c0892772815a) - Closing
[0m10:57:30.017247 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6C4BFE00>]}
[0m10:57:30.020404 [info ] [Thread-8 (]: 8 of 17 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 3.71s]
[0m10:57:30.022420 [debug] [Thread-8 (]: Finished running node seed.dbt_databricks_proj.lookup
[0m10:57:30.024180 [debug] [Thread-8 (]: Began running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m10:57:30.024180 [info ] [Thread-8 (]: 9 of 17 START test non_negitive_bronze_sales_gross_amount ...................... [RUN]
[0m10:57:30.027110 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13) - Creating connection
[0m10:57:30.027110 [debug] [Thread-8 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13'
[0m10:57:30.027110 [debug] [Thread-8 (]: Began compiling node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m10:57:30.048056 [debug] [Thread-8 (]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m10:57:30.059205 [debug] [Thread-8 (]: Began executing node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m10:57:30.128859 [debug] [Thread-8 (]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m10:57:30.134902 [debug] [Thread-8 (]: Using databricks connection "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m10:57:30.136252 [debug] [Thread-8 (]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

select 
    *
from 
    `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where 
    gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m10:57:30.137471 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:30.477706 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f9f2-199e-8cba-a26c77707c5b) - Created
[0m10:57:31.433986 [debug] [Thread-8 (]: SQL status: OK in 1.300 seconds
[0m10:57:31.444283 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-f9f2-199e-8cba-a26c77707c5b, command-id=01f08743-f9fe-1005-a914-5012b01043b2) - Closing
[0m10:57:31.450579 [debug] [Thread-8 (]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: Close
[0m10:57:31.450579 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-f9f2-199e-8cba-a26c77707c5b) - Closing
[0m10:57:31.538193 [info ] [Thread-8 (]: 9 of 17 PASS non_negitive_bronze_sales_gross_amount ............................ [[32mPASS[0m in 1.51s]
[0m10:57:31.541920 [debug] [Thread-8 (]: Finished running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m10:57:31.541920 [debug] [Thread-8 (]: Began running node test.dbt_databricks_proj.non_negitive_test
[0m10:57:31.545949 [info ] [Thread-8 (]: 10 of 17 START test non_negitive_test .......................................... [RUN]
[0m10:57:31.547170 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_test) - Creating connection
[0m10:57:31.547863 [debug] [Thread-8 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_test'
[0m10:57:31.547863 [debug] [Thread-8 (]: Began compiling node test.dbt_databricks_proj.non_negitive_test
[0m10:57:31.560091 [debug] [Thread-8 (]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_test"
[0m10:57:31.566333 [debug] [Thread-8 (]: Began executing node test.dbt_databricks_proj.non_negitive_test
[0m10:57:31.572218 [debug] [Thread-8 (]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_test"
[0m10:57:31.579326 [debug] [Thread-8 (]: Using databricks connection "test.dbt_databricks_proj.non_negitive_test"
[0m10:57:31.580685 [debug] [Thread-8 (]: On test.dbt_databricks_proj.non_negitive_test: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.non_negitive_test"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  select *
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales` 
where gross_amount < 0 and net_amount < 0
  
  
      
    ) dbt_internal_test
[0m10:57:31.580685 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:31.932836 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fad1-1a46-9482-c1b567c9d497) - Created
[0m10:57:32.559287 [debug] [Thread-8 (]: SQL status: OK in 0.980 seconds
[0m10:57:32.564475 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-fad1-1a46-9482-c1b567c9d497, command-id=01f08743-fadc-178a-810a-99161ef86db5) - Closing
[0m10:57:32.567226 [debug] [Thread-8 (]: On test.dbt_databricks_proj.non_negitive_test: Close
[0m10:57:32.567226 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fad1-1a46-9482-c1b567c9d497) - Closing
[0m10:57:32.650356 [info ] [Thread-8 (]: 10 of 17 PASS non_negitive_test ................................................ [[32mPASS[0m in 1.10s]
[0m10:57:32.655590 [debug] [Thread-8 (]: Finished running node test.dbt_databricks_proj.non_negitive_test
[0m10:57:32.656318 [debug] [Thread-8 (]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m10:57:32.657329 [info ] [Thread-8 (]: 11 of 17 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m10:57:32.661428 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m10:57:32.662207 [debug] [Thread-8 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m10:57:32.663967 [debug] [Thread-8 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m10:57:32.682617 [debug] [Thread-8 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m10:57:32.687108 [debug] [Thread-8 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m10:57:32.693574 [debug] [Thread-8 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m10:57:32.694987 [debug] [Thread-8 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m10:57:32.697420 [debug] [Thread-8 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m10:57:32.698643 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:33.050270 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fb7b-1ff6-b4f0-70ea06078017) - Created
[0m10:57:33.590080 [debug] [Thread-8 (]: SQL status: OK in 0.890 seconds
[0m10:57:33.598828 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-fb7b-1ff6-b4f0-70ea06078017, command-id=01f08743-fb88-14d5-8786-52e2d38f191f) - Closing
[0m10:57:33.600858 [debug] [Thread-8 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m10:57:33.600858 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fb7b-1ff6-b4f0-70ea06078017) - Closing
[0m10:57:33.672303 [info ] [Thread-8 (]: 11 of 17 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 1.01s]
[0m10:57:33.677307 [debug] [Thread-8 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m10:57:33.679808 [debug] [Thread-8 (]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m10:57:33.679808 [info ] [Thread-8 (]: 12 of 17 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m10:57:33.684946 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m10:57:33.684946 [debug] [Thread-8 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m10:57:33.684946 [debug] [Thread-8 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m10:57:33.717376 [debug] [Thread-8 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m10:57:33.721486 [debug] [Thread-8 (]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m10:57:33.732857 [debug] [Thread-8 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m10:57:33.736352 [debug] [Thread-8 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m10:57:33.737992 [debug] [Thread-8 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m10:57:33.737992 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:34.101141 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fc1c-1128-917b-1b44b801f8a1) - Created
[0m10:57:34.807283 [debug] [Thread-8 (]: SQL status: OK in 1.070 seconds
[0m10:57:34.817331 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-fc1c-1128-917b-1b44b801f8a1, command-id=01f08743-fc27-1125-a440-94a4bbcc9b71) - Closing
[0m10:57:34.817331 [debug] [Thread-8 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m10:57:34.821948 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fc1c-1128-917b-1b44b801f8a1) - Closing
[0m10:57:34.909126 [info ] [Thread-8 (]: 12 of 17 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.23s]
[0m10:57:34.913161 [debug] [Thread-8 (]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m10:57:34.915180 [debug] [Thread-8 (]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m10:57:34.917195 [info ] [Thread-8 (]: 13 of 17 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m10:57:34.921852 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m10:57:34.922382 [debug] [Thread-8 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m10:57:34.922382 [debug] [Thread-8 (]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m10:57:34.950636 [debug] [Thread-8 (]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m10:57:34.952648 [debug] [Thread-8 (]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m10:57:34.959756 [debug] [Thread-8 (]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m10:57:34.961768 [debug] [Thread-8 (]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m10:57:34.963062 [debug] [Thread-8 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m10:57:34.964518 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:35.282350 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fcd1-1454-818c-461d5b8e3ea0) - Created
[0m10:57:36.437593 [debug] [Thread-8 (]: SQL status: OK in 1.470 seconds
[0m10:57:36.444906 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-fcd1-1454-818c-461d5b8e3ea0, command-id=01f08743-fcda-1b19-93c9-491af6cdfd54) - Closing
[0m10:57:36.447453 [debug] [Thread-8 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m10:57:36.447453 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fcd1-1454-818c-461d5b8e3ea0) - Closing
[0m10:57:36.537507 [info ] [Thread-8 (]: 13 of 17 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 1.62s]
[0m10:57:36.543914 [debug] [Thread-8 (]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m10:57:36.546967 [debug] [Thread-8 (]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m10:57:36.546967 [info ] [Thread-8 (]: 14 of 17 START test not_null_bronze_store_store_sk ............................. [RUN]
[0m10:57:36.546967 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m10:57:36.552067 [debug] [Thread-8 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m10:57:36.552067 [debug] [Thread-8 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m10:57:36.568521 [debug] [Thread-8 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m10:57:36.568521 [debug] [Thread-8 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m10:57:36.581754 [debug] [Thread-8 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m10:57:36.585195 [debug] [Thread-8 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m10:57:36.587207 [debug] [Thread-8 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m10:57:36.587207 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:36.961547 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fdd0-18dd-ad09-e3ef22d2ef92) - Created
[0m10:57:37.517368 [debug] [Thread-8 (]: SQL status: OK in 0.930 seconds
[0m10:57:37.524941 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-fdd0-18dd-ad09-e3ef22d2ef92, command-id=01f08743-fddb-1749-abad-cd004ada1b75) - Closing
[0m10:57:37.527433 [debug] [Thread-8 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m10:57:37.528481 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fdd0-18dd-ad09-e3ef22d2ef92) - Closing
[0m10:57:37.610375 [info ] [Thread-8 (]: 14 of 17 PASS not_null_bronze_store_store_sk ................................... [[32mPASS[0m in 1.06s]
[0m10:57:37.610375 [debug] [Thread-8 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m10:57:37.617605 [debug] [Thread-8 (]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m10:57:37.617605 [info ] [Thread-8 (]: 15 of 17 START test unique_bronze_store_store_sk ............................... [RUN]
[0m10:57:37.617605 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m10:57:37.617605 [debug] [Thread-8 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m10:57:37.617605 [debug] [Thread-8 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m10:57:37.637131 [debug] [Thread-8 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m10:57:37.644548 [debug] [Thread-8 (]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m10:57:37.650215 [debug] [Thread-8 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m10:57:37.650215 [debug] [Thread-8 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m10:57:37.650215 [debug] [Thread-8 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m10:57:37.650215 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:37.998465 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fe6f-1101-a5d7-9de5e2f1b3e4) - Created
[0m10:57:38.649546 [debug] [Thread-8 (]: SQL status: OK in 1.000 seconds
[0m10:57:38.654172 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-fe6f-1101-a5d7-9de5e2f1b3e4, command-id=01f08743-fe79-1ebf-ba5d-bdaf0cbab8b3) - Closing
[0m10:57:38.657203 [debug] [Thread-8 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m10:57:38.659740 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-fe6f-1101-a5d7-9de5e2f1b3e4) - Closing
[0m10:57:38.775637 [info ] [Thread-8 (]: 15 of 17 PASS unique_bronze_store_store_sk ..................................... [[32mPASS[0m in 1.16s]
[0m10:57:38.777150 [debug] [Thread-8 (]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m10:57:38.777150 [debug] [Thread-8 (]: Began running node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m10:57:38.777150 [info ] [Thread-8 (]: 16 of 17 START snapshot gold.gold_items_snapshot ............................... [RUN]
[0m10:57:38.781954 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.dbt_databricks_proj.gold_items_snapshot) - Creating connection
[0m10:57:38.781954 [debug] [Thread-8 (]: Acquiring new databricks connection 'snapshot.dbt_databricks_proj.gold_items_snapshot'
[0m10:57:38.785376 [debug] [Thread-8 (]: Began compiling node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m10:57:38.797074 [debug] [Thread-8 (]: Began executing node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m10:57:38.956321 [debug] [Thread-8 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:57:38.957964 [debug] [Thread-8 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */
select * from (
        
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedDate as string ), '')
        ) as dbt_scd_id,
        updatedDate as dbt_updated_at,
        updatedDate as dbt_valid_from,
        
  
  coalesce(nullif(updatedDate, updatedDate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt_databricks_proj_dev`.`gold`.`source_gold_items`
    ) sbq



    ) as __dbt_sbq
    where false
    limit 0

[0m10:57:38.959655 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:39.339198 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-ff3c-1a31-b060-83b0b675cfba) - Created
[0m10:57:39.845432 [debug] [Thread-8 (]: SQL status: OK in 0.890 seconds
[0m10:57:39.857267 [debug] [Thread-8 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:57:39.860062 [debug] [Thread-8 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m10:57:39.860062 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-ff3c-1a31-b060-83b0b675cfba, command-id=01f08743-ff46-1de8-973b-79ae7d96ce70) - Closing
[0m10:57:40.077332 [debug] [Thread-8 (]: SQL status: OK in 0.220 seconds
[0m10:57:40.077332 [debug] [Thread-8 (]: Writing runtime sql for node "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:57:40.086944 [debug] [Thread-8 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:57:40.086944 [debug] [Thread-8 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

      
  
    
        create or replace table `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot`
      
      
  using delta
      
      
      
      
      
      
      
      as
      
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedDate as string ), '')
        ) as dbt_scd_id,
        updatedDate as dbt_updated_at,
        updatedDate as dbt_valid_from,
        
  
  coalesce(nullif(updatedDate, updatedDate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt_databricks_proj_dev`.`gold`.`source_gold_items`
    ) sbq



  
  
[0m10:57:40.089000 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-ff3c-1a31-b060-83b0b675cfba, command-id=01f08743-ff95-14b2-bbb3-34e81364bb79) - Closing
[0m10:57:43.516105 [debug] [Thread-8 (]: SQL status: OK in 3.430 seconds
[0m10:57:43.519113 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08743-ff3c-1a31-b060-83b0b675cfba, command-id=01f08743-ffb8-19f3-a5ed-c2d810f93109) - Closing
[0m10:57:43.531479 [debug] [Thread-8 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: Close
[0m10:57:43.531479 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08743-ff3c-1a31-b060-83b0b675cfba) - Closing
[0m10:57:43.621354 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6DA3D430>]}
[0m10:57:43.625893 [info ] [Thread-8 (]: 16 of 17 OK snapshotted gold.gold_items_snapshot ............................... [[32mOK[0m in 4.84s]
[0m10:57:43.627403 [debug] [Thread-8 (]: Finished running node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m10:57:43.629450 [debug] [Thread-8 (]: Began running node model.dbt_databricks_proj.silver_salesinfo
[0m10:57:43.631465 [info ] [Thread-8 (]: 17 of 17 START sql table model silver.silver_salesinfo ......................... [RUN]
[0m10:57:43.633480 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.silver_salesinfo) - Creating connection
[0m10:57:43.633480 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.silver_salesinfo'
[0m10:57:43.635495 [debug] [Thread-8 (]: Began compiling node model.dbt_databricks_proj.silver_salesinfo
[0m10:57:43.651966 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_databricks_proj.silver_salesinfo"
[0m10:57:43.657789 [debug] [Thread-8 (]: Began executing node model.dbt_databricks_proj.silver_salesinfo
[0m10:57:43.665685 [debug] [Thread-8 (]: MATERIALIZING TABLE
[0m10:57:43.667180 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_databricks_proj.silver_salesinfo"
[0m10:57:43.673334 [debug] [Thread-8 (]: Using databricks connection "model.dbt_databricks_proj.silver_salesinfo"
[0m10:57:43.675368 [debug] [Thread-8 (]: On model.dbt_databricks_proj.silver_salesinfo: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.silver_salesinfo"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`silver`.`silver_salesinfo`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with customers as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_customer`
),
products as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
),
sales as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
),
joined_data as (

select 
    s.sales_id,
    
    s.quantity * s.unit_price
 as gross_amount,
    
    s.payment_method,
    c.gender,
    p.category
from sales s
join customers c on s.customer_sk = c.customer_sk  
join products p on s.product_sk = p.product_sk

)

select 
    category,
    gender,
    sum(gross_amount) as total_gross_amount
from joined_data
group by 
    category,gender
order by
    total_gross_amount desc
  
[0m10:57:43.677385 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m10:57:44.029346 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08744-0207-1ddd-b972-a2a630d5c799) - Created
[0m10:57:47.611725 [debug] [Thread-8 (]: SQL status: OK in 3.930 seconds
[0m10:57:47.613735 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08744-0207-1ddd-b972-a2a630d5c799, command-id=01f08744-0212-1044-93f4-79a8699f3071) - Closing
[0m10:57:47.615746 [debug] [Thread-8 (]: Applying tags to relation None
[0m10:57:47.617256 [debug] [Thread-8 (]: On model.dbt_databricks_proj.silver_salesinfo: Close
[0m10:57:47.619299 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08744-0207-1ddd-b972-a2a630d5c799) - Closing
[0m10:57:47.712254 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebf5224e-2e03-4a68-a5ef-3fd49073015e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D6DA075C0>]}
[0m10:57:47.712254 [info ] [Thread-8 (]: 17 of 17 OK created sql table model silver.silver_salesinfo .................... [[32mOK[0m in 4.08s]
[0m10:57:47.717657 [debug] [Thread-8 (]: Finished running node model.dbt_databricks_proj.silver_salesinfo
[0m10:57:47.720695 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:57:47.720695 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:57:47.720695 [info ] [MainThread]: 
[0m10:57:47.728290 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 5 table models, 7 data tests, 3 view models in 0 hours 3 minutes and 58.44 seconds (238.44s).
[0m10:57:47.737066 [debug] [MainThread]: Command end result
[0m10:57:47.852458 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m10:57:47.860741 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m10:57:47.885347 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m10:57:47.887367 [info ] [MainThread]: 
[0m10:57:47.887367 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:57:47.887367 [info ] [MainThread]: 
[0m10:57:47.893697 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=17
[0m10:57:47.893697 [debug] [MainThread]: Command `dbt build` succeeded at 10:57:47.893697 after 242.30 seconds
[0m10:57:47.897233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D3CAFE1E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D3BE1F440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D3BE1EE40>]}
[0m10:57:47.897233 [debug] [MainThread]: Flushing usage events
[0m10:57:48.796292 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:58:57.275987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6BDF1C2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6BE818B00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6BB93F6E0>]}


============================== 10:58:57.275987 | 9d9e32cf-db77-4fd7-b412-1f8df1349e6d ==============================
[0m10:58:57.275987 [info ] [MainThread]: Running with dbt=1.10.10
[0m10:58:57.275987 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m10:58:58.537117 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:58:58.537117 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:58:58.537117 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:58:59.555461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6BBA64830>]}
[0m10:58:59.650124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EBB271A0>]}
[0m10:58:59.650124 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m10:59:00.136469 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m10:59:00.468313 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:59:00.468313 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:59:00.595496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EE34B9B0>]}
[0m10:59:00.753350 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m10:59:00.753350 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m10:59:00.800843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6BD91BA40>]}
[0m10:59:00.805681 [info ] [MainThread]: Found 1 seed, 4 analyses, 8 models, 7 data tests, 1 snapshot, 7 sources, 688 macros
[0m10:59:00.805681 [info ] [MainThread]: 
[0m10:59:00.805681 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:59:00.805681 [info ] [MainThread]: 
[0m10:59:00.805681 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:59:00.805681 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:59:00.830685 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m10:59:00.830685 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m10:59:00.830685 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m10:59:00.830685 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m10:59:00.832699 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:59:01.130822 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-2ffb-1952-8496-e1ed60b48af1) - Created
[0m10:59:01.300478 [debug] [ThreadPool]: SQL status: OK in 0.470 seconds
[0m10:59:01.302522 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08744-2ffb-1952-8496-e1ed60b48af1, command-id=01f08744-3005-1f34-a703-f5a40a337e69) - Closing
[0m10:59:01.304291 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m10:59:01.304291 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-2ffb-1952-8496-e1ed60b48af1) - Closing
[0m10:59:01.372209 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m10:59:01.372209 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m10:59:01.372209 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m10:59:01.372209 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m10:59:01.372209 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:59:01.622487 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-3047-1d27-bb35-c4c8196809ee) - Created
[0m10:59:01.845400 [debug] [ThreadPool]: SQL status: OK in 0.470 seconds
[0m10:59:01.850261 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08744-3047-1d27-bb35-c4c8196809ee, command-id=01f08744-3051-1120-860f-57fadd72b417) - Closing
[0m10:59:01.850261 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m10:59:01.851554 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-3047-1d27-bb35-c4c8196809ee) - Closing
[0m10:59:01.921859 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m10:59:01.921859 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m10:59:01.921859 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m10:59:01.921859 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m10:59:01.921859 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:59:02.185618 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-309e-1a5f-b8d5-e357666fd908) - Created
[0m10:59:02.350692 [debug] [ThreadPool]: SQL status: OK in 0.430 seconds
[0m10:59:02.350692 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08744-309e-1a5f-b8d5-e357666fd908, command-id=01f08744-30a8-1ffd-a63e-b19e97424d11) - Closing
[0m10:59:02.350692 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m10:59:02.350692 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-309e-1a5f-b8d5-e357666fd908) - Closing
[0m10:59:02.442241 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m10:59:02.442241 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m10:59:02.466445 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m10:59:02.469156 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m10:59:02.469156 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:59:02.708701 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-30ee-11c2-9239-433f01534f1d) - Created
[0m10:59:03.178909 [debug] [ThreadPool]: SQL status: OK in 0.710 seconds
[0m10:59:03.191581 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08744-30ee-11c2-9239-433f01534f1d, command-id=01f08744-30f7-19be-926e-7439c34bac65) - Closing
[0m10:59:03.191581 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m10:59:03.193594 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-30ee-11c2-9239-433f01534f1d) - Closing
[0m10:59:03.271270 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_gold) - Creating connection
[0m10:59:03.274227 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_gold'
[0m10:59:03.276431 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_gold"
[0m10:59:03.276431 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'gold'

  
[0m10:59:03.276431 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:59:03.518910 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-3169-17e5-ade7-e8bdf4ecec61) - Created
[0m10:59:03.900308 [debug] [ThreadPool]: SQL status: OK in 0.620 seconds
[0m10:59:03.904339 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08744-3169-17e5-ade7-e8bdf4ecec61, command-id=01f08744-3172-143f-91fc-68d8479f5dc4) - Closing
[0m10:59:03.904339 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_gold: Close
[0m10:59:03.906352 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-3169-17e5-ade7-e8bdf4ecec61) - Closing
[0m10:59:04.018113 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_silver) - Creating connection
[0m10:59:04.018113 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_silver'
[0m10:59:04.022558 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_silver"
[0m10:59:04.022558 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'silver'

  
[0m10:59:04.022558 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:59:04.277575 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-31dc-1117-a811-b65b416082b1) - Created
[0m10:59:04.604536 [debug] [ThreadPool]: SQL status: OK in 0.580 seconds
[0m10:59:04.617118 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08744-31dc-1117-a811-b65b416082b1, command-id=01f08744-31e7-141d-8ff8-6b386990f2b1) - Closing
[0m10:59:04.619758 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_silver: Close
[0m10:59:04.619758 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08744-31dc-1117-a811-b65b416082b1) - Closing
[0m10:59:04.696185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6C1649EB0>]}
[0m10:59:04.704650 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_customer
[0m10:59:04.704650 [info ] [Thread-7 (]: 1 of 17 START sql table model bronze.bronze_customer ........................... [RUN]
[0m10:59:04.704650 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_customer) - Creating connection
[0m10:59:04.704650 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_customer'
[0m10:59:04.704650 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_customer
[0m10:59:04.725378 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_customer"
[0m10:59:04.725378 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_customer
[0m10:59:04.747408 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m10:59:04.747408 [warn ] [Thread-7 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:59:04.755812 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EE583200>]}
[0m10:59:04.806191 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_customer"
[0m10:59:04.806191 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_customer"
[0m10:59:04.806191 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_customer"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_customer`
  
[0m10:59:04.819404 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:05.081506 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3256-1d4a-984c-e61766662150) - Created
[0m10:59:07.211434 [debug] [Thread-7 (]: SQL status: OK in 2.410 seconds
[0m10:59:07.211434 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3256-1d4a-984c-e61766662150, command-id=01f08744-3260-1af7-a7cf-4efe52af901b) - Closing
[0m10:59:07.228587 [debug] [Thread-7 (]: Applying tags to relation None
[0m10:59:07.252191 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_customer: Close
[0m10:59:07.252191 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3256-1d4a-984c-e61766662150) - Closing
[0m10:59:07.320655 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6BDE7D370>]}
[0m10:59:07.320655 [info ] [Thread-7 (]: 1 of 17 OK created sql table model bronze.bronze_customer ...................... [[32mOK[0m in 2.62s]
[0m10:59:07.320655 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_customer
[0m10:59:07.320655 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_date
[0m10:59:07.320655 [info ] [Thread-7 (]: 2 of 17 START sql view model bronze.bronze_date ................................ [RUN]
[0m10:59:07.320655 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_date) - Creating connection
[0m10:59:07.320655 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_date'
[0m10:59:07.320655 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_date
[0m10:59:07.471315 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_date"
[0m10:59:07.471315 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_date
[0m10:59:07.484526 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m10:59:07.504083 [debug] [Thread-7 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_date`
[0m10:59:07.504083 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_date"
[0m10:59:07.504083 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_date"
[0m10:59:07.504083 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_date"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_date`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`dim_date`
  )

[0m10:59:07.504083 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:07.763565 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-33f0-1d4c-89fb-e0ea10932ad8) - Created
[0m10:59:08.209604 [debug] [Thread-7 (]: SQL status: OK in 0.710 seconds
[0m10:59:08.209604 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-33f0-1d4c-89fb-e0ea10932ad8, command-id=01f08744-33fa-1d54-b9de-041276bab433) - Closing
[0m10:59:08.209604 [debug] [Thread-7 (]: Applying tags to relation None
[0m10:59:08.218754 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_date: Close
[0m10:59:08.218754 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-33f0-1d4c-89fb-e0ea10932ad8) - Closing
[0m10:59:08.288505 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EDDF87A0>]}
[0m10:59:08.296465 [info ] [Thread-7 (]: 2 of 17 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 0.97s]
[0m10:59:08.297476 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_date
[0m10:59:08.297476 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_product
[0m10:59:08.297476 [info ] [Thread-7 (]: 3 of 17 START sql view model bronze.bronze_product ............................. [RUN]
[0m10:59:08.297476 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_product) - Creating connection
[0m10:59:08.297476 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_product'
[0m10:59:08.297476 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_product
[0m10:59:08.307789 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_product"
[0m10:59:08.307789 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_product
[0m10:59:08.311811 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m10:59:08.313560 [debug] [Thread-7 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
[0m10:59:08.313560 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_product"
[0m10:59:08.315571 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_product"
[0m10:59:08.315571 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_product"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`dim_product`
  )

[0m10:59:08.315571 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:08.589637 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-346d-1c12-a73a-a77b28279c5f) - Created
[0m10:59:08.970160 [debug] [Thread-7 (]: SQL status: OK in 0.650 seconds
[0m10:59:08.970160 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-346d-1c12-a73a-a77b28279c5f, command-id=01f08744-3478-1d92-9054-e7ad61bfa88c) - Closing
[0m10:59:08.970160 [debug] [Thread-7 (]: Applying tags to relation None
[0m10:59:08.970160 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_product: Close
[0m10:59:08.970160 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-346d-1c12-a73a-a77b28279c5f) - Closing
[0m10:59:09.059122 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EDDD2E40>]}
[0m10:59:09.060277 [info ] [Thread-7 (]: 3 of 17 OK created sql view model bronze.bronze_product ........................ [[32mOK[0m in 0.76s]
[0m10:59:09.061968 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_product
[0m10:59:09.061968 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_returns
[0m10:59:09.061968 [info ] [Thread-7 (]: 4 of 17 START sql table model bronze.bronze_returns ............................ [RUN]
[0m10:59:09.061968 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_returns) - Creating connection
[0m10:59:09.061968 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_returns'
[0m10:59:09.061968 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_returns
[0m10:59:09.068249 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_returns"
[0m10:59:09.072205 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_returns
[0m10:59:09.076505 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m10:59:09.076505 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_returns"
[0m10:59:09.076505 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_returns"
[0m10:59:09.076505 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_returns"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`fact_returns`
  
[0m10:59:09.076505 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:09.355606 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-34e4-12a7-96f5-47b19157d547) - Created
[0m10:59:11.262810 [debug] [Thread-7 (]: SQL status: OK in 2.190 seconds
[0m10:59:11.271220 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-34e4-12a7-96f5-47b19157d547, command-id=01f08744-34ed-1caf-8c60-ed3ed4548dd9) - Closing
[0m10:59:11.271220 [debug] [Thread-7 (]: Applying tags to relation None
[0m10:59:11.271220 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_returns: Close
[0m10:59:11.271220 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-34e4-12a7-96f5-47b19157d547) - Closing
[0m10:59:11.362413 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EE4EAEA0>]}
[0m10:59:11.362413 [info ] [Thread-7 (]: 4 of 17 OK created sql table model bronze.bronze_returns ....................... [[32mOK[0m in 2.30s]
[0m10:59:11.362413 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_returns
[0m10:59:11.370556 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_sales
[0m10:59:11.371254 [info ] [Thread-7 (]: 5 of 17 START sql view model bronze.bronze_sales ............................... [RUN]
[0m10:59:11.371696 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_sales) - Creating connection
[0m10:59:11.372634 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_sales'
[0m10:59:11.372634 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_sales
[0m10:59:11.385477 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_sales"
[0m10:59:11.387088 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_sales
[0m10:59:11.391186 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m10:59:11.392725 [debug] [Thread-7 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
[0m10:59:11.392725 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_sales"
[0m10:59:11.395981 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_sales"
[0m10:59:11.395981 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_sales"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`fact_sales`
  )

[0m10:59:11.395981 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:11.694135 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3648-14a9-a8de-5ebc6f8da97d) - Created
[0m10:59:12.341634 [debug] [Thread-7 (]: SQL status: OK in 0.950 seconds
[0m10:59:12.341634 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3648-14a9-a8de-5ebc6f8da97d, command-id=01f08744-3652-1343-934e-f3e4c8af9f56) - Closing
[0m10:59:12.341634 [debug] [Thread-7 (]: Applying tags to relation None
[0m10:59:12.345651 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_sales: Close
[0m10:59:12.345651 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3648-14a9-a8de-5ebc6f8da97d) - Closing
[0m10:59:12.421599 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EE530770>]}
[0m10:59:12.421599 [info ] [Thread-7 (]: 5 of 17 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 1.05s]
[0m10:59:12.425093 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_sales
[0m10:59:12.425093 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_store
[0m10:59:12.425093 [info ] [Thread-7 (]: 6 of 17 START sql table model bronze.bronze_store .............................. [RUN]
[0m10:59:12.427808 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_store) - Creating connection
[0m10:59:12.427808 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_store'
[0m10:59:12.427808 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_store
[0m10:59:12.431287 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_store"
[0m10:59:12.431287 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_store
[0m10:59:12.437912 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m10:59:12.437912 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_store"
[0m10:59:12.441267 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_store"
[0m10:59:12.441267 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_store"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_store`
  
[0m10:59:12.443035 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:12.711683 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-36e3-1448-9b85-5b1c083897b2) - Created
[0m10:59:15.276322 [debug] [Thread-7 (]: SQL status: OK in 2.830 seconds
[0m10:59:15.281988 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-36e3-1448-9b85-5b1c083897b2, command-id=01f08744-36ee-1167-8a7a-b093e74c862f) - Closing
[0m10:59:15.285249 [debug] [Thread-7 (]: Applying tags to relation None
[0m10:59:15.289284 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_store: Close
[0m10:59:15.290689 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-36e3-1448-9b85-5b1c083897b2) - Closing
[0m10:59:15.389251 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EE4C3E90>]}
[0m10:59:15.391269 [info ] [Thread-7 (]: 6 of 17 OK created sql table model bronze.bronze_store ......................... [[32mOK[0m in 2.96s]
[0m10:59:15.393333 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_store
[0m10:59:15.393333 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.source_gold_items
[0m10:59:15.397576 [info ] [Thread-7 (]: 7 of 17 START sql table model gold.source_gold_items ........................... [RUN]
[0m10:59:15.397914 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.source_gold_items) - Creating connection
[0m10:59:15.397914 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.source_gold_items'
[0m10:59:15.401360 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.source_gold_items
[0m10:59:15.413305 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.source_gold_items"
[0m10:59:15.417610 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.source_gold_items
[0m10:59:15.423411 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m10:59:15.429155 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.source_gold_items"
[0m10:59:15.437334 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.source_gold_items"
[0m10:59:15.442251 [debug] [Thread-7 (]: On model.dbt_databricks_proj.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.source_gold_items"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`gold`.`source_gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with cte1 as (
select *,
row_number() over (partition by id order by updatedDate desc) as dedup_id
from 
`dbt_databricks_proj_dev`.`source`.`items`

)

select id,name,category,updatedDate from cte1
where dedup_id=1
  
[0m10:59:15.444266 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:15.812833 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-38bb-1f8a-87fe-84eaa8c27490) - Created
[0m10:59:17.850495 [debug] [Thread-7 (]: SQL status: OK in 2.400 seconds
[0m10:59:17.851506 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-38bb-1f8a-87fe-84eaa8c27490, command-id=01f08744-38c7-1fc9-b899-023df710c3f8) - Closing
[0m10:59:17.851506 [debug] [Thread-7 (]: Applying tags to relation None
[0m10:59:17.856637 [debug] [Thread-7 (]: On model.dbt_databricks_proj.source_gold_items: Close
[0m10:59:17.856637 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-38bb-1f8a-87fe-84eaa8c27490) - Closing
[0m10:59:17.955516 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EE2E28A0>]}
[0m10:59:17.957527 [info ] [Thread-7 (]: 7 of 17 OK created sql table model gold.source_gold_items ...................... [[32mOK[0m in 2.56s]
[0m10:59:17.959537 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.source_gold_items
[0m10:59:17.961550 [debug] [Thread-7 (]: Began running node seed.dbt_databricks_proj.lookup
[0m10:59:17.963106 [info ] [Thread-7 (]: 8 of 17 START seed file bronze.lookup .......................................... [RUN]
[0m10:59:17.963106 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_databricks_proj.lookup) - Creating connection
[0m10:59:17.963106 [debug] [Thread-7 (]: Acquiring new databricks connection 'seed.dbt_databricks_proj.lookup'
[0m10:59:17.967662 [debug] [Thread-7 (]: Began compiling node seed.dbt_databricks_proj.lookup
[0m10:59:17.967662 [debug] [Thread-7 (]: Began executing node seed.dbt_databricks_proj.lookup
[0m10:59:18.071540 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m10:59:18.071540 [debug] [Thread-7 (]: On seed.dbt_databricks_proj.lookup: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "seed.dbt_databricks_proj.lookup"} */

    create or replace table `dbt_databricks_proj_dev`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_email` string )
    
  using delta
    
    
    
    
    
  
[0m10:59:18.077724 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:18.421236 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3a49-1f8b-aa03-b90fffd009ae) - Created
[0m10:59:19.561343 [debug] [Thread-7 (]: SQL status: OK in 1.480 seconds
[0m10:59:19.561343 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3a49-1f8b-aa03-b90fffd009ae, command-id=01f08744-3a55-1588-9716-a044814276a8) - Closing
[0m10:59:19.581412 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m10:59:19.581412 [debug] [Thread-7 (]: On seed.dbt_databricks_proj.lookup: 
          insert overwrite `dbt_databricks_proj_dev`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m10:59:20.896218 [debug] [Thread-7 (]: SQL status: OK in 1.310 seconds
[0m10:59:20.896218 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3a49-1f8b-aa03-b90fffd009ae, command-id=01f08744-3b06-11aa-9df8-1049a253ea9f) - Closing
[0m10:59:20.905295 [debug] [Thread-7 (]: Writing runtime SQL for node "seed.dbt_databricks_proj.lookup"
[0m10:59:20.909559 [debug] [Thread-7 (]: On seed.dbt_databricks_proj.lookup: Close
[0m10:59:20.909559 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3a49-1f8b-aa03-b90fffd009ae) - Closing
[0m10:59:20.996513 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EF93AB40>]}
[0m10:59:20.998529 [info ] [Thread-7 (]: 8 of 17 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 3.03s]
[0m10:59:20.998529 [debug] [Thread-7 (]: Finished running node seed.dbt_databricks_proj.lookup
[0m10:59:21.001126 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m10:59:21.001126 [info ] [Thread-7 (]: 9 of 17 START test non_negitive_bronze_sales_gross_amount ...................... [RUN]
[0m10:59:21.004493 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13) - Creating connection
[0m10:59:21.006503 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13'
[0m10:59:21.006503 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m10:59:21.017678 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m10:59:21.019732 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m10:59:21.046967 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m10:59:21.046967 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m10:59:21.046967 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

select 
    *
from 
    `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where 
    gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m10:59:21.051429 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:21.331546 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3c05-1485-9fec-14502b2bd214) - Created
[0m10:59:21.615404 [debug] [Thread-7 (]: SQL status: OK in 0.560 seconds
[0m10:59:21.619437 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3c05-1485-9fec-14502b2bd214, command-id=01f08744-3c10-1ad9-a4eb-cb044cf176b9) - Closing
[0m10:59:21.621708 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: Close
[0m10:59:21.621708 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3c05-1485-9fec-14502b2bd214) - Closing
[0m10:59:21.693464 [info ] [Thread-7 (]: 9 of 17 PASS non_negitive_bronze_sales_gross_amount ............................ [[32mPASS[0m in 0.69s]
[0m10:59:21.693464 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m10:59:21.695480 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.non_negitive_test
[0m10:59:21.695480 [info ] [Thread-7 (]: 10 of 17 START test non_negitive_test .......................................... [RUN]
[0m10:59:21.697492 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_test) - Creating connection
[0m10:59:21.698507 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_test'
[0m10:59:21.698507 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.non_negitive_test
[0m10:59:21.707776 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_test"
[0m10:59:21.709858 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.non_negitive_test
[0m10:59:21.713983 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_test"
[0m10:59:21.714479 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.non_negitive_test"
[0m10:59:21.715610 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_test: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.non_negitive_test"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  select *
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales` 
where gross_amount < 0 and net_amount < 0
  
  
      
    ) dbt_internal_test
[0m10:59:21.716812 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:21.979283 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3c69-18db-8d13-e7b4f5cdbc2d) - Created
[0m10:59:22.233622 [debug] [Thread-7 (]: SQL status: OK in 0.520 seconds
[0m10:59:22.237642 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3c69-18db-8d13-e7b4f5cdbc2d, command-id=01f08744-3c73-15c0-8f7c-68a1b271b5e9) - Closing
[0m10:59:22.239652 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_test: Close
[0m10:59:22.239652 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3c69-18db-8d13-e7b4f5cdbc2d) - Closing
[0m10:59:22.315361 [info ] [Thread-7 (]: 10 of 17 PASS non_negitive_test ................................................ [[32mPASS[0m in 0.62s]
[0m10:59:22.317376 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.non_negitive_test
[0m10:59:22.317376 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m10:59:22.317376 [info ] [Thread-7 (]: 11 of 17 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m10:59:22.321404 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m10:59:22.321404 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m10:59:22.321404 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m10:59:22.337038 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m10:59:22.339082 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m10:59:22.343525 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m10:59:22.345538 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m10:59:22.345538 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m10:59:22.345538 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:22.598154 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3cc8-1b3e-aa58-459e5b54af25) - Created
[0m10:59:22.846085 [debug] [Thread-7 (]: SQL status: OK in 0.500 seconds
[0m10:59:22.851324 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3cc8-1b3e-aa58-459e5b54af25, command-id=01f08744-3cd2-10d7-a95c-1295ab416dae) - Closing
[0m10:59:22.851324 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m10:59:22.851324 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3cc8-1b3e-aa58-459e5b54af25) - Closing
[0m10:59:22.945383 [info ] [Thread-7 (]: 11 of 17 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 0.63s]
[0m10:59:22.946393 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m10:59:22.948437 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m10:59:22.948437 [info ] [Thread-7 (]: 12 of 17 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m10:59:22.948437 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m10:59:22.950449 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m10:59:22.950449 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m10:59:22.966883 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m10:59:22.969024 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m10:59:22.972725 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m10:59:22.975035 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m10:59:22.976059 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m10:59:22.976659 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:23.251398 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3d2c-18d3-8d2c-cf3d7f50f958) - Created
[0m10:59:23.451539 [debug] [Thread-7 (]: SQL status: OK in 0.470 seconds
[0m10:59:23.451539 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3d2c-18d3-8d2c-cf3d7f50f958, command-id=01f08744-3d36-176a-aab9-26ad31d10e79) - Closing
[0m10:59:23.451539 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m10:59:23.451539 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3d2c-18d3-8d2c-cf3d7f50f958) - Closing
[0m10:59:23.551253 [info ] [Thread-7 (]: 12 of 17 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 0.60s]
[0m10:59:23.551253 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m10:59:23.551253 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m10:59:23.551253 [info ] [Thread-7 (]: 13 of 17 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m10:59:23.551253 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m10:59:23.551253 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m10:59:23.551253 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m10:59:23.574317 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m10:59:23.581579 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m10:59:23.581579 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m10:59:23.585719 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m10:59:23.588269 [debug] [Thread-7 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m10:59:23.589791 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:23.846292 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3d87-13c6-81df-c2278963249b) - Created
[0m10:59:24.591515 [debug] [Thread-7 (]: SQL status: OK in 1.000 seconds
[0m10:59:24.595022 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3d87-13c6-81df-c2278963249b, command-id=01f08744-3d90-156b-a515-113e00f239f8) - Closing
[0m10:59:24.597032 [debug] [Thread-7 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m10:59:24.597032 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3d87-13c6-81df-c2278963249b) - Closing
[0m10:59:24.691887 [info ] [Thread-7 (]: 13 of 17 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 1.14s]
[0m10:59:24.694672 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m10:59:24.696689 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m10:59:24.696689 [info ] [Thread-7 (]: 14 of 17 START test not_null_bronze_store_store_sk ............................. [RUN]
[0m10:59:24.698704 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m10:59:24.698704 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m10:59:24.698704 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m10:59:24.709605 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m10:59:24.711500 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m10:59:24.716069 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m10:59:24.716069 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m10:59:24.719214 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m10:59:24.719214 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:24.982630 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3e33-1823-9a22-6b4553f55a74) - Created
[0m10:59:25.505507 [debug] [Thread-7 (]: SQL status: OK in 0.790 seconds
[0m10:59:25.511393 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3e33-1823-9a22-6b4553f55a74, command-id=01f08744-3e3d-1ce1-9cd1-561bc09c8634) - Closing
[0m10:59:25.511393 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m10:59:25.511393 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3e33-1823-9a22-6b4553f55a74) - Closing
[0m10:59:25.600002 [info ] [Thread-7 (]: 14 of 17 PASS not_null_bronze_store_store_sk ................................... [[32mPASS[0m in 0.90s]
[0m10:59:25.601515 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m10:59:25.602802 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m10:59:25.602802 [info ] [Thread-7 (]: 15 of 17 START test unique_bronze_store_store_sk ............................... [RUN]
[0m10:59:25.604316 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m10:59:25.604939 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m10:59:25.604939 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m10:59:25.613521 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m10:59:25.615533 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m10:59:25.619562 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m10:59:25.619562 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m10:59:25.621587 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m10:59:25.621587 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:25.890570 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3ebe-137c-85ec-9c36fee79b65) - Created
[0m10:59:26.631255 [debug] [Thread-7 (]: SQL status: OK in 1.010 seconds
[0m10:59:26.631255 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3ebe-137c-85ec-9c36fee79b65, command-id=01f08744-3ec8-122d-92b7-b01da98960e1) - Closing
[0m10:59:26.631255 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m10:59:26.631255 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3ebe-137c-85ec-9c36fee79b65) - Closing
[0m10:59:26.727803 [info ] [Thread-7 (]: 15 of 17 PASS unique_bronze_store_store_sk ..................................... [[32mPASS[0m in 1.12s]
[0m10:59:26.727803 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m10:59:26.729815 [debug] [Thread-7 (]: Began running node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m10:59:26.729815 [info ] [Thread-7 (]: 16 of 17 START snapshot gold.gold_items_snapshot ............................... [RUN]
[0m10:59:26.731328 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.dbt_databricks_proj.gold_items_snapshot) - Creating connection
[0m10:59:26.733084 [debug] [Thread-7 (]: Acquiring new databricks connection 'snapshot.dbt_databricks_proj.gold_items_snapshot'
[0m10:59:26.733084 [debug] [Thread-7 (]: Began compiling node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m10:59:26.741571 [debug] [Thread-7 (]: Began executing node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m10:59:26.791432 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:27.038572 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9) - Created
[0m10:59:27.046459 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:27.047964 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot` AS JSON

  
[0m10:59:27.552838 [debug] [Thread-7 (]: SQL status: OK in 0.500 seconds
[0m10:59:27.560886 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9, command-id=01f08744-3f78-193f-b258-f8c7e378144c) - Closing
[0m10:59:27.616777 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:27.621307 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

        
  
    create or replace temporary view `gold_items_snapshot__dbt_tmp` as
      
    
    with snapshot_query as (

        select * from `dbt_databricks_proj_dev`.`gold`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedDate as dbt_updated_at,
            updatedDate as dbt_valid_from,
            
  
  coalesce(nullif(updatedDate, updatedDate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedDate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedDate as dbt_updated_at,
            updatedDate as dbt_valid_from,
            updatedDate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updatedDate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updatedDate)
        )
    )

    select * from insertions
    union all
    select * from updates

  
    
[0m10:59:28.063327 [debug] [Thread-7 (]: SQL status: OK in 0.440 seconds
[0m10:59:28.065342 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9, command-id=01f08744-3fd0-107c-8069-e76d77c2af76) - Closing
[0m10:59:28.071387 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:28.073157 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `gold_items_snapshot__dbt_tmp` AS JSON

  
[0m10:59:28.267575 [debug] [Thread-7 (]: SQL status: OK in 0.190 seconds
[0m10:59:28.269587 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9, command-id=01f08744-4015-1907-bd99-ac978b068b58) - Closing
[0m10:59:28.273676 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:28.275950 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot` AS JSON

  
[0m10:59:28.486816 [debug] [Thread-7 (]: SQL status: OK in 0.210 seconds
[0m10:59:28.489338 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9, command-id=01f08744-4033-1d5e-9c88-a441290244b0) - Closing
[0m10:59:28.491360 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:28.491360 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `gold_items_snapshot__dbt_tmp` AS JSON

  
[0m10:59:28.676237 [debug] [Thread-7 (]: SQL status: OK in 0.180 seconds
[0m10:59:28.680225 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9, command-id=01f08744-4058-1783-9518-8308f8677596) - Closing
[0m10:59:28.684565 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:28.684565 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot` AS JSON

  
[0m10:59:28.985176 [debug] [Thread-7 (]: SQL status: OK in 0.300 seconds
[0m10:59:28.987189 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9, command-id=01f08744-4072-196e-ae27-6a2dc7454f40) - Closing
[0m10:59:28.996951 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:28.996951 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `gold_items_snapshot__dbt_tmp` AS JSON

  
[0m10:59:29.137514 [debug] [Thread-7 (]: SQL status: OK in 0.140 seconds
[0m10:59:29.141532 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9, command-id=01f08744-40a2-1199-bd31-d47e48a3c7c1) - Closing
[0m10:59:29.161301 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:29.161301 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */
select * from (
        
    
    with snapshot_query as (

        select * from `dbt_databricks_proj_dev`.`gold`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedDate as dbt_updated_at,
            updatedDate as dbt_valid_from,
            
  
  coalesce(nullif(updatedDate, updatedDate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedDate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedDate as dbt_updated_at,
            updatedDate as dbt_valid_from,
            updatedDate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updatedDate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updatedDate)
        )
    )

    select * from insertions
    union all
    select * from updates

    ) as __dbt_sbq
    where false
    limit 0

[0m10:59:29.601362 [debug] [Thread-7 (]: SQL status: OK in 0.440 seconds
[0m10:59:29.613503 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:29.613503 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m10:59:29.615517 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9, command-id=01f08744-40bc-137f-8936-7268fe67b6a6) - Closing
[0m10:59:29.736463 [debug] [Thread-7 (]: SQL status: OK in 0.120 seconds
[0m10:59:29.738477 [debug] [Thread-7 (]: Writing runtime sql for node "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:29.740491 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:29.741503 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

      merge into `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot` as DBT_INTERNAL_DEST
    
      using `gold_items_snapshot__dbt_tmp` as DBT_INTERNAL_SOURCE
    
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id
    when matched
     
       and ( DBT_INTERNAL_DEST.dbt_valid_to = to_date('9999-12-31') or
             DBT_INTERNAL_DEST.dbt_valid_to is null )
     
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert *
    ;

  
[0m10:59:29.742637 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9, command-id=01f08744-4100-14ca-a6dc-fd970da6c9ee) - Closing
[0m10:59:37.211555 [debug] [Thread-7 (]: SQL status: OK in 7.470 seconds
[0m10:59:37.211555 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9, command-id=01f08744-4114-107a-8a66-1f82d44ee836) - Closing
[0m10:59:37.331237 [debug] [Thread-7 (]: Applying DROP to: `gold_items_snapshot__dbt_tmp`
[0m10:59:37.331237 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m10:59:37.331237 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */
DROP VIEW IF EXISTS `gold_items_snapshot__dbt_tmp`
[0m10:59:37.688777 [debug] [Thread-7 (]: SQL status: OK in 0.350 seconds
[0m10:59:37.691294 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9, command-id=01f08744-459c-1057-bf30-0b039d2845c3) - Closing
[0m10:59:37.691294 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: Close
[0m10:59:37.691294 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-3f6d-1e8f-8eed-3927780aaad9) - Closing
[0m10:59:37.775399 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EF973920>]}
[0m10:59:37.777416 [info ] [Thread-7 (]: 16 of 17 OK snapshotted gold.gold_items_snapshot ............................... [[32mOK[0m in 11.04s]
[0m10:59:37.777416 [debug] [Thread-7 (]: Finished running node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m10:59:37.777416 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.silver_salesinfo
[0m10:59:37.779431 [info ] [Thread-7 (]: 17 of 17 START sql table model silver.silver_salesinfo ......................... [RUN]
[0m10:59:37.780443 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.silver_salesinfo) - Creating connection
[0m10:59:37.781453 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.silver_salesinfo'
[0m10:59:37.781997 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.silver_salesinfo
[0m10:59:37.789154 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.silver_salesinfo"
[0m10:59:37.791167 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.silver_salesinfo
[0m10:59:37.793214 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m10:59:37.796246 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.silver_salesinfo"
[0m10:59:37.797750 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.silver_salesinfo"
[0m10:59:37.797750 [debug] [Thread-7 (]: On model.dbt_databricks_proj.silver_salesinfo: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.silver_salesinfo"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`silver`.`silver_salesinfo`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with customers as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_customer`
),
products as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
),
sales as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
),
joined_data as (

select 
    s.sales_id,
    
    s.quantity * s.unit_price
 as gross_amount,
    
    s.payment_method,
    c.gender,
    p.category
from sales s
join customers c on s.customer_sk = c.customer_sk  
join products p on s.product_sk = p.product_sk

)

select 
    category,
    gender,
    sum(gross_amount) as total_gross_amount
from joined_data
group by 
    category,gender
order by
    total_gross_amount desc
  
[0m10:59:37.797750 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m10:59:38.065368 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-4600-13ca-9afc-ef02cc2681a2) - Created
[0m10:59:40.435872 [debug] [Thread-7 (]: SQL status: OK in 2.640 seconds
[0m10:59:40.438333 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08744-4600-13ca-9afc-ef02cc2681a2, command-id=01f08744-4609-1ecc-b13a-b2d48a4a7690) - Closing
[0m10:59:40.438333 [debug] [Thread-7 (]: Applying tags to relation None
[0m10:59:40.438333 [debug] [Thread-7 (]: On model.dbt_databricks_proj.silver_salesinfo: Close
[0m10:59:40.441155 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08744-4600-13ca-9afc-ef02cc2681a2) - Closing
[0m10:59:40.521557 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d9e32cf-db77-4fd7-b412-1f8df1349e6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EF9A7F50>]}
[0m10:59:40.521557 [info ] [Thread-7 (]: 17 of 17 OK created sql table model silver.silver_salesinfo .................... [[32mOK[0m in 2.74s]
[0m10:59:40.521557 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.silver_salesinfo
[0m10:59:40.521557 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:59:40.521557 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:59:40.521557 [info ] [MainThread]: 
[0m10:59:40.531297 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 5 table models, 7 data tests, 3 view models in 0 hours 0 minutes and 39.72 seconds (39.72s).
[0m10:59:40.534334 [debug] [MainThread]: Command end result
[0m10:59:40.571255 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m10:59:40.580308 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m10:59:40.586370 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m10:59:40.586370 [info ] [MainThread]: 
[0m10:59:40.586370 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:59:40.591341 [info ] [MainThread]: 
[0m10:59:40.591341 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=17
[0m10:59:40.591341 [debug] [MainThread]: Command `dbt build` succeeded at 10:59:40.591341 after 43.52 seconds
[0m10:59:40.591341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6BDE46DE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6BBC0C3E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EE37B830>]}
[0m10:59:40.591341 [debug] [MainThread]: Flushing usage events
[0m10:59:41.083703 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:48:02.645239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001097ADBD460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001097DF3FC20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001097E958350>]}


============================== 11:48:02.645239 | 4177c081-76b8-44b0-8dc9-3dc458182c69 ==============================
[0m11:48:02.645239 [info ] [MainThread]: Running with dbt=1.10.10
[0m11:48:02.645239 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt build --target prod', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'static_parser': 'True', 'write_json': 'True'}
[0m11:48:08.253774 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m11:48:08.253774 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m11:48:08.253774 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m11:48:15.061482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092D6CCB00>]}
[0m11:48:15.153545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001090157F770>]}
[0m11:48:15.155552 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m11:48:15.920351 [debug] [MainThread]: checksum: af4148875ea7aa1549d372d0d0c9ad91031d05358531ca115c8e08a093099b13, vars: {}, profile: , target: prod, version: 1.10.10
[0m11:48:16.092041 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m11:48:16.092041 [debug] [MainThread]: previous checksum: af4148875ea7aa1549d372d0d0c9ad91031d05358531ca115c8e08a093099b13, current checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b
[0m11:48:16.092041 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m11:48:16.092041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092E18C290>]}
[0m11:48:18.904153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092F9210D0>]}
[0m11:48:19.024323 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m11:48:19.068864 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m11:48:19.106154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092F693200>]}
[0m11:48:19.106772 [info ] [MainThread]: Found 8 models, 5 analyses, 7 data tests, 1 seed, 1 snapshot, 7 sources, 688 macros
[0m11:48:19.107825 [info ] [MainThread]: 
[0m11:48:19.107825 [info ] [MainThread]: Concurrency: 1 threads (target='prod')
[0m11:48:19.107825 [info ] [MainThread]: 
[0m11:48:19.107825 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:48:19.107825 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:48:19.122793 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod) - Creating connection
[0m11:48:19.123588 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod'
[0m11:48:19.124554 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod"
[0m11:48:19.124554 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: GetSchemas(database=dbt_databricks_proj_prod, schema=None)
[0m11:48:19.125203 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:48:19.757557 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-1525-1ea5-ad2c-1f14f301a1c2) - Created
[0m11:49:21.119825 [debug] [ThreadPool]: SQL status: OK in 61.990 seconds
[0m11:49:21.121858 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874b-1525-1ea5-ad2c-1f14f301a1c2, command-id=01f0874b-3922-1a73-b79d-8605a8177adb) - Closing
[0m11:49:21.121858 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: Close
[0m11:49:21.123872 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-1525-1ea5-ad2c-1f14f301a1c2) - Closing
[0m11:49:21.228088 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod) - Creating connection
[0m11:49:21.228088 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod'
[0m11:49:21.228088 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod"
[0m11:49:21.229602 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: GetSchemas(database=dbt_databricks_proj_prod, schema=None)
[0m11:49:21.229602 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:49:21.561778 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3a12-1ab4-b264-1d79b4a8a8dc) - Created
[0m11:49:21.836094 [debug] [ThreadPool]: SQL status: OK in 0.610 seconds
[0m11:49:21.838246 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874b-3a12-1ab4-b264-1d79b4a8a8dc, command-id=01f0874b-3a1f-1162-adda-119aa8af3fbe) - Closing
[0m11:49:21.838246 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: Close
[0m11:49:21.839759 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3a12-1ab4-b264-1d79b4a8a8dc) - Closing
[0m11:49:21.935696 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod) - Creating connection
[0m11:49:21.937755 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod'
[0m11:49:21.937755 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod"
[0m11:49:21.937755 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: GetSchemas(database=dbt_databricks_proj_prod, schema=None)
[0m11:49:21.937755 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:49:22.243359 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3a7a-181e-b6a4-0e0a54edc0b1) - Created
[0m11:49:22.549536 [debug] [ThreadPool]: SQL status: OK in 0.610 seconds
[0m11:49:22.553083 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874b-3a7a-181e-b6a4-0e0a54edc0b1, command-id=01f0874b-3a88-1f9e-966a-dd7e95c40577) - Closing
[0m11:49:22.553083 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: Close
[0m11:49:22.553083 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3a7a-181e-b6a4-0e0a54edc0b1) - Closing
[0m11:49:22.629763 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_databricks_proj_prod_silver) - Creating connection
[0m11:49:22.629763 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_databricks_proj_prod_silver'
[0m11:49:22.629763 [debug] [ThreadPool]: Creating schema "database: "dbt_databricks_proj_prod"
schema: "silver"
"
[0m11:49:22.642067 [debug] [ThreadPool]: Using databricks connection "create_dbt_databricks_proj_prod_silver"
[0m11:49:22.642067 [debug] [ThreadPool]: On create_dbt_databricks_proj_prod_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "connection_name": "create_dbt_databricks_proj_prod_silver"} */
create schema if not exists `dbt_databricks_proj_prod`.`silver`
  
[0m11:49:22.642067 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:49:22.919602 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3ae5-1651-be23-dca62688c41b) - Created
[0m11:49:24.194696 [debug] [ThreadPool]: SQL status: OK in 1.550 seconds
[0m11:49:24.196079 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874b-3ae5-1651-be23-dca62688c41b, command-id=01f0874b-3aef-1251-a1bc-326534be6cca) - Closing
[0m11:49:24.196746 [debug] [ThreadPool]: On create_dbt_databricks_proj_prod_silver: Close
[0m11:49:24.197477 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3ae5-1651-be23-dca62688c41b) - Closing
[0m11:49:24.275757 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_databricks_proj_prod_gold) - Creating connection
[0m11:49:24.275757 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_databricks_proj_prod_gold'
[0m11:49:24.275757 [debug] [ThreadPool]: Creating schema "database: "dbt_databricks_proj_prod"
schema: "gold"
"
[0m11:49:24.286233 [debug] [ThreadPool]: Using databricks connection "create_dbt_databricks_proj_prod_gold"
[0m11:49:24.288356 [debug] [ThreadPool]: On create_dbt_databricks_proj_prod_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "connection_name": "create_dbt_databricks_proj_prod_gold"} */
create schema if not exists `dbt_databricks_proj_prod`.`gold`
  
[0m11:49:24.288356 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:49:24.579879 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3be0-12ec-8ffd-bce723cf4a24) - Created
[0m11:49:25.003534 [debug] [ThreadPool]: SQL status: OK in 0.720 seconds
[0m11:49:25.009556 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874b-3be0-12ec-8ffd-bce723cf4a24, command-id=01f0874b-3beb-1b45-b240-2a707e775734) - Closing
[0m11:49:25.009556 [debug] [ThreadPool]: On create_dbt_databricks_proj_prod_gold: Close
[0m11:49:25.011582 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3be0-12ec-8ffd-bce723cf4a24) - Closing
[0m11:49:25.095547 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt_databricks_proj_prod_bronze) - Creating connection
[0m11:49:25.095547 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt_databricks_proj_prod_bronze'
[0m11:49:25.095547 [debug] [ThreadPool]: Creating schema "database: "dbt_databricks_proj_prod"
schema: "bronze"
"
[0m11:49:25.099833 [debug] [ThreadPool]: Using databricks connection "create_dbt_databricks_proj_prod_bronze"
[0m11:49:25.102344 [debug] [ThreadPool]: On create_dbt_databricks_proj_prod_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "connection_name": "create_dbt_databricks_proj_prod_bronze"} */
create schema if not exists `dbt_databricks_proj_prod`.`bronze`
  
[0m11:49:25.102344 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:49:25.349459 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3c56-1b12-b083-06626a3ec024) - Created
[0m11:49:25.827232 [debug] [ThreadPool]: SQL status: OK in 0.720 seconds
[0m11:49:25.829746 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874b-3c56-1b12-b083-06626a3ec024, command-id=01f0874b-3c61-1642-aa36-1597abc6316d) - Closing
[0m11:49:25.831785 [debug] [ThreadPool]: On create_dbt_databricks_proj_prod_bronze: Close
[0m11:49:25.831785 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3c56-1b12-b083-06626a3ec024) - Closing
[0m11:49:25.923276 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod_silver) - Creating connection
[0m11:49:25.923276 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod_silver'
[0m11:49:25.929812 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod_silver"
[0m11:49:25.929812 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "connection_name": "list_dbt_databricks_proj_prod_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_prod' 
  AND table_schema = 'silver'

  
[0m11:49:25.937899 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:49:26.206164 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3cd9-1761-ab44-5e2f15a3f7d5) - Created
[0m11:49:27.571667 [debug] [ThreadPool]: SQL status: OK in 1.630 seconds
[0m11:49:27.581682 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874b-3cd9-1761-ab44-5e2f15a3f7d5, command-id=01f0874b-3ce4-169b-9fad-29ff1ba1a38c) - Closing
[0m11:49:27.583693 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_silver: Close
[0m11:49:27.583693 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3cd9-1761-ab44-5e2f15a3f7d5) - Closing
[0m11:49:27.657620 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod_gold) - Creating connection
[0m11:49:27.657620 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod_gold'
[0m11:49:27.661632 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod_gold"
[0m11:49:27.663636 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "connection_name": "list_dbt_databricks_proj_prod_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_prod' 
  AND table_schema = 'gold'

  
[0m11:49:27.663636 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:49:27.952790 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3de1-1f3f-a251-3b823f2c4eb7) - Created
[0m11:49:28.443117 [debug] [ThreadPool]: SQL status: OK in 0.780 seconds
[0m11:49:28.447142 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874b-3de1-1f3f-a251-3b823f2c4eb7, command-id=01f0874b-3dee-1e69-823d-289c3fea3c3c) - Closing
[0m11:49:28.449157 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_gold: Close
[0m11:49:28.449157 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3de1-1f3f-a251-3b823f2c4eb7) - Closing
[0m11:49:28.531800 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod_bronze) - Creating connection
[0m11:49:28.531800 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod_bronze'
[0m11:49:28.539650 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod_bronze"
[0m11:49:28.539650 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "connection_name": "list_dbt_databricks_proj_prod_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_prod' 
  AND table_schema = 'bronze'

  
[0m11:49:28.539650 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:49:28.828692 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3e69-1d27-bb02-3ec7250ee1ce) - Created
[0m11:49:29.312392 [debug] [ThreadPool]: SQL status: OK in 0.770 seconds
[0m11:49:29.316158 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874b-3e69-1d27-bb02-3ec7250ee1ce, command-id=01f0874b-3e74-129f-a329-bef2bf040df2) - Closing
[0m11:49:29.316158 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_bronze: Close
[0m11:49:29.316158 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874b-3e69-1d27-bb02-3ec7250ee1ce) - Closing
[0m11:49:29.400779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092F985190>]}
[0m11:49:29.407678 [debug] [Thread-10 ]: Began running node model.dbt_databricks_proj.bronze_customer
[0m11:49:29.407678 [info ] [Thread-10 ]: 1 of 17 START sql table model bronze.bronze_customer ........................... [RUN]
[0m11:49:29.409725 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_customer) - Creating connection
[0m11:49:29.409725 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_customer'
[0m11:49:29.409725 [debug] [Thread-10 ]: Began compiling node model.dbt_databricks_proj.bronze_customer
[0m11:49:29.415863 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_customer"
[0m11:49:29.422417 [debug] [Thread-10 ]: Began executing node model.dbt_databricks_proj.bronze_customer
[0m11:49:29.441376 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m11:49:29.441376 [warn ] [Thread-10 ]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m11:49:29.441376 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092FEE8710>]}
[0m11:49:29.490001 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_customer"
[0m11:49:29.490001 [debug] [Thread-10 ]: Using databricks connection "model.dbt_databricks_proj.bronze_customer"
[0m11:49:29.496327 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_customer"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_prod`.`source`.`dim_customer`
  
[0m11:49:29.496327 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:49:29.758460 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-3ef6-1803-b9e1-0184fe92292a) - Created
[0m11:49:39.417411 [debug] [Thread-10 ]: SQL status: OK in 9.920 seconds
[0m11:49:39.417411 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-3ef6-1803-b9e1-0184fe92292a, command-id=01f0874b-3f02-1621-97c6-d8aa1eba092b) - Closing
[0m11:49:39.563134 [debug] [Thread-10 ]: Applying tags to relation None
[0m11:49:39.583721 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_customer: Close
[0m11:49:39.583721 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-3ef6-1803-b9e1-0184fe92292a) - Closing
[0m11:49:39.681728 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001097DD2D130>]}
[0m11:49:39.682496 [info ] [Thread-10 ]: 1 of 17 OK created sql table model bronze.bronze_customer ...................... [[32mOK[0m in 10.27s]
[0m11:49:39.683801 [debug] [Thread-10 ]: Finished running node model.dbt_databricks_proj.bronze_customer
[0m11:49:39.683801 [debug] [Thread-10 ]: Began running node model.dbt_databricks_proj.bronze_date
[0m11:49:39.684665 [info ] [Thread-10 ]: 2 of 17 START sql view model bronze.bronze_date ................................ [RUN]
[0m11:49:39.685751 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_date) - Creating connection
[0m11:49:39.685751 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_date'
[0m11:49:39.687013 [debug] [Thread-10 ]: Began compiling node model.dbt_databricks_proj.bronze_date
[0m11:49:39.689681 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_date"
[0m11:49:39.689681 [debug] [Thread-10 ]: Began executing node model.dbt_databricks_proj.bronze_date
[0m11:49:39.703829 [debug] [Thread-10 ]: MATERIALIZING VIEW
[0m11:49:39.718206 [debug] [Thread-10 ]: Creating view `dbt_databricks_proj_prod`.`bronze`.`bronze_date`
[0m11:49:39.718206 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_date"
[0m11:49:39.718206 [debug] [Thread-10 ]: Using databricks connection "model.dbt_databricks_proj.bronze_date"
[0m11:49:39.718206 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_date"} */

  
  
  create or replace view `dbt_databricks_proj_prod`.`bronze`.`bronze_date`
  
  as (
    select * from `dbt_databricks_proj_prod`.`source`.`dim_date`
  )

[0m11:49:39.718206 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:49:39.996020 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4511-1bbb-8d94-d417b53413fc) - Created
[0m11:49:40.778983 [debug] [Thread-10 ]: SQL status: OK in 1.060 seconds
[0m11:49:40.778983 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-4511-1bbb-8d94-d417b53413fc, command-id=01f0874b-451b-19ed-bead-9f30803238bf) - Closing
[0m11:49:40.781421 [debug] [Thread-10 ]: Applying tags to relation None
[0m11:49:40.781421 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_date: Close
[0m11:49:40.783433 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4511-1bbb-8d94-d417b53413fc) - Closing
[0m11:49:40.862257 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092FEEA870>]}
[0m11:49:40.862257 [info ] [Thread-10 ]: 2 of 17 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 1.18s]
[0m11:49:40.865039 [debug] [Thread-10 ]: Finished running node model.dbt_databricks_proj.bronze_date
[0m11:49:40.865039 [debug] [Thread-10 ]: Began running node model.dbt_databricks_proj.bronze_product
[0m11:49:40.865039 [info ] [Thread-10 ]: 3 of 17 START sql view model bronze.bronze_product ............................. [RUN]
[0m11:49:40.867052 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_product) - Creating connection
[0m11:49:40.867052 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_product'
[0m11:49:40.867052 [debug] [Thread-10 ]: Began compiling node model.dbt_databricks_proj.bronze_product
[0m11:49:40.872006 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_product"
[0m11:49:40.872006 [debug] [Thread-10 ]: Began executing node model.dbt_databricks_proj.bronze_product
[0m11:49:40.876027 [debug] [Thread-10 ]: MATERIALIZING VIEW
[0m11:49:40.876027 [debug] [Thread-10 ]: Creating view `dbt_databricks_proj_prod`.`bronze`.`bronze_product`
[0m11:49:40.878034 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_product"
[0m11:49:40.879040 [debug] [Thread-10 ]: Using databricks connection "model.dbt_databricks_proj.bronze_product"
[0m11:49:40.879040 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_product"} */

  
  
  create or replace view `dbt_databricks_proj_prod`.`bronze`.`bronze_product`
  
  as (
    select * from `dbt_databricks_proj_prod`.`source`.`dim_product`
  )

[0m11:49:40.879040 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:49:41.123032 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-45be-16fb-b22f-7148b4a9a43f) - Created
[0m11:49:41.596814 [debug] [Thread-10 ]: SQL status: OK in 0.720 seconds
[0m11:49:41.598825 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-45be-16fb-b22f-7148b4a9a43f, command-id=01f0874b-45c9-1406-8824-e078bacdc520) - Closing
[0m11:49:41.598825 [debug] [Thread-10 ]: Applying tags to relation None
[0m11:49:41.601194 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_product: Close
[0m11:49:41.601194 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-45be-16fb-b22f-7148b4a9a43f) - Closing
[0m11:49:41.687154 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092FF467E0>]}
[0m11:49:41.688660 [info ] [Thread-10 ]: 3 of 17 OK created sql view model bronze.bronze_product ........................ [[32mOK[0m in 0.82s]
[0m11:49:41.689869 [debug] [Thread-10 ]: Finished running node model.dbt_databricks_proj.bronze_product
[0m11:49:41.689869 [debug] [Thread-10 ]: Began running node model.dbt_databricks_proj.bronze_returns
[0m11:49:41.689869 [info ] [Thread-10 ]: 4 of 17 START sql table model bronze.bronze_returns ............................ [RUN]
[0m11:49:41.691884 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_returns) - Creating connection
[0m11:49:41.691884 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_returns'
[0m11:49:41.691884 [debug] [Thread-10 ]: Began compiling node model.dbt_databricks_proj.bronze_returns
[0m11:49:41.698141 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_returns"
[0m11:49:41.698141 [debug] [Thread-10 ]: Began executing node model.dbt_databricks_proj.bronze_returns
[0m11:49:41.702168 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m11:49:41.708729 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_returns"
[0m11:49:41.708729 [debug] [Thread-10 ]: Using databricks connection "model.dbt_databricks_proj.bronze_returns"
[0m11:49:41.708729 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_returns"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_prod`.`source`.`fact_returns`
  
[0m11:49:41.710743 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:49:41.976967 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4640-1e1b-958c-0b4d7c11d481) - Created
[0m11:49:44.976754 [debug] [Thread-10 ]: SQL status: OK in 3.270 seconds
[0m11:49:44.979778 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-4640-1e1b-958c-0b4d7c11d481, command-id=01f0874b-464a-1035-8e69-2d9c40b59bb1) - Closing
[0m11:49:44.979778 [debug] [Thread-10 ]: Applying tags to relation None
[0m11:49:44.979778 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_returns: Close
[0m11:49:44.983269 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4640-1e1b-958c-0b4d7c11d481) - Closing
[0m11:49:45.063769 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092FF4F740>]}
[0m11:49:45.063769 [info ] [Thread-10 ]: 4 of 17 OK created sql table model bronze.bronze_returns ....................... [[32mOK[0m in 3.37s]
[0m11:49:45.066809 [debug] [Thread-10 ]: Finished running node model.dbt_databricks_proj.bronze_returns
[0m11:49:45.066809 [debug] [Thread-10 ]: Began running node model.dbt_databricks_proj.bronze_sales
[0m11:49:45.066809 [info ] [Thread-10 ]: 5 of 17 START sql view model bronze.bronze_sales ............................... [RUN]
[0m11:49:45.066809 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_sales) - Creating connection
[0m11:49:45.066809 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_sales'
[0m11:49:45.066809 [debug] [Thread-10 ]: Began compiling node model.dbt_databricks_proj.bronze_sales
[0m11:49:45.076548 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_sales"
[0m11:49:45.076548 [debug] [Thread-10 ]: Began executing node model.dbt_databricks_proj.bronze_sales
[0m11:49:45.078835 [debug] [Thread-10 ]: MATERIALIZING VIEW
[0m11:49:45.078835 [debug] [Thread-10 ]: Creating view `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
[0m11:49:45.083691 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_sales"
[0m11:49:45.084485 [debug] [Thread-10 ]: Using databricks connection "model.dbt_databricks_proj.bronze_sales"
[0m11:49:45.085357 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_sales"} */

  
  
  create or replace view `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
  
  as (
    select * from `dbt_databricks_proj_prod`.`source`.`fact_sales`
  )

[0m11:49:45.085357 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:49:45.337398 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4841-16cf-a513-2b69400c345d) - Created
[0m11:49:45.785112 [debug] [Thread-10 ]: SQL status: OK in 0.700 seconds
[0m11:49:45.785112 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-4841-16cf-a513-2b69400c345d, command-id=01f0874b-484b-1697-9bad-c8c0ad27bd38) - Closing
[0m11:49:45.785112 [debug] [Thread-10 ]: Applying tags to relation None
[0m11:49:45.785112 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_sales: Close
[0m11:49:45.785112 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4841-16cf-a513-2b69400c345d) - Closing
[0m11:49:45.859952 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092FB1CE00>]}
[0m11:49:45.867988 [info ] [Thread-10 ]: 5 of 17 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 0.79s]
[0m11:49:45.867988 [debug] [Thread-10 ]: Finished running node model.dbt_databricks_proj.bronze_sales
[0m11:49:45.867988 [debug] [Thread-10 ]: Began running node model.dbt_databricks_proj.bronze_store
[0m11:49:45.867988 [info ] [Thread-10 ]: 6 of 17 START sql table model bronze.bronze_store .............................. [RUN]
[0m11:49:45.867988 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_store) - Creating connection
[0m11:49:45.867988 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_store'
[0m11:49:45.867988 [debug] [Thread-10 ]: Began compiling node model.dbt_databricks_proj.bronze_store
[0m11:49:45.876528 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_store"
[0m11:49:45.876528 [debug] [Thread-10 ]: Began executing node model.dbt_databricks_proj.bronze_store
[0m11:49:45.876528 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m11:49:45.884310 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_store"
[0m11:49:45.884310 [debug] [Thread-10 ]: Using databricks connection "model.dbt_databricks_proj.bronze_store"
[0m11:49:45.884310 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_store"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_prod`.`source`.`dim_store`
  
[0m11:49:45.884310 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:49:46.138506 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-48bd-12ea-b583-e123a15ade57) - Created
[0m11:49:49.279130 [debug] [Thread-10 ]: SQL status: OK in 3.390 seconds
[0m11:49:49.281143 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-48bd-12ea-b583-e123a15ade57, command-id=01f0874b-48c6-14bb-90a6-f05796b4daa6) - Closing
[0m11:49:49.282155 [debug] [Thread-10 ]: Applying tags to relation None
[0m11:49:49.284168 [debug] [Thread-10 ]: On model.dbt_databricks_proj.bronze_store: Close
[0m11:49:49.286181 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-48bd-12ea-b583-e123a15ade57) - Closing
[0m11:49:49.371898 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092FE7A2D0>]}
[0m11:49:49.373911 [info ] [Thread-10 ]: 6 of 17 OK created sql table model bronze.bronze_store ......................... [[32mOK[0m in 3.50s]
[0m11:49:49.373911 [debug] [Thread-10 ]: Finished running node model.dbt_databricks_proj.bronze_store
[0m11:49:49.375926 [debug] [Thread-10 ]: Began running node model.dbt_databricks_proj.source_gold_items
[0m11:49:49.375926 [info ] [Thread-10 ]: 7 of 17 START sql table model gold.source_gold_items ........................... [RUN]
[0m11:49:49.377936 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.source_gold_items) - Creating connection
[0m11:49:49.377936 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_databricks_proj.source_gold_items'
[0m11:49:49.379943 [debug] [Thread-10 ]: Began compiling node model.dbt_databricks_proj.source_gold_items
[0m11:49:49.384097 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_databricks_proj.source_gold_items"
[0m11:49:49.386100 [debug] [Thread-10 ]: Began executing node model.dbt_databricks_proj.source_gold_items
[0m11:49:49.390819 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m11:49:49.390819 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_databricks_proj.source_gold_items"
[0m11:49:49.390819 [debug] [Thread-10 ]: Using databricks connection "model.dbt_databricks_proj.source_gold_items"
[0m11:49:49.390819 [debug] [Thread-10 ]: On model.dbt_databricks_proj.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.source_gold_items"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`gold`.`source_gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with cte1 as (
select *,
row_number() over (partition by id order by updatedDate desc) as dedup_id
from 
`dbt_databricks_proj_prod`.`source`.`items`

)

select id,name,category,updatedDate from cte1
where dedup_id=1
  
[0m11:49:49.390819 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:49:49.637940 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4ad1-1c87-bf28-3821f8923805) - Created
[0m11:49:50.097821 [debug] [Thread-10 ]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.source_gold_items"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`gold`.`source_gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with cte1 as (
select *,
row_number() over (partition by id order by updatedDate desc) as dedup_id
from 
`dbt_databricks_proj_prod`.`source`.`items`

)

select id,name,category,updatedDate from cte1
where dedup_id=1
  
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f0874b-4adb-19b5-8eaa-175cfc5e4d98
[0m11:49:50.099831 [debug] [Thread-10 ]: On model.dbt_databricks_proj.source_gold_items: Close
[0m11:49:50.099831 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4ad1-1c87-bf28-3821f8923805) - Closing
[0m11:49:50.445507 [debug] [Thread-10 ]: Database Error in model source_gold_items (models\gold\source_gold_items.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
  compiled code at target\run\dbt_databricks_proj\models\gold\source_gold_items.sql
[0m11:49:50.445507 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092FF32540>]}
[0m11:49:50.447518 [error] [Thread-10 ]: 7 of 17 ERROR creating sql table model gold.source_gold_items .................. [[31mERROR[0m in 1.07s]
[0m11:49:50.449270 [debug] [Thread-10 ]: Finished running node model.dbt_databricks_proj.source_gold_items
[0m11:49:50.449270 [debug] [Thread-10 ]: Began running node seed.dbt_databricks_proj.lookup
[0m11:49:50.449270 [debug] [Thread-13 ]: Marking all children of 'model.dbt_databricks_proj.source_gold_items' to be skipped because of status 'error'.  Reason: Database Error in model source_gold_items (models\gold\source_gold_items.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
  compiled code at target\run\dbt_databricks_proj\models\gold\source_gold_items.sql.
[0m11:49:50.449270 [info ] [Thread-10 ]: 8 of 17 START seed file bronze.lookup .......................................... [RUN]
[0m11:49:50.453648 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_databricks_proj.lookup) - Creating connection
[0m11:49:50.453648 [debug] [Thread-10 ]: Acquiring new databricks connection 'seed.dbt_databricks_proj.lookup'
[0m11:49:50.453648 [debug] [Thread-10 ]: Began compiling node seed.dbt_databricks_proj.lookup
[0m11:49:50.453648 [debug] [Thread-10 ]: Began executing node seed.dbt_databricks_proj.lookup
[0m11:49:50.497913 [debug] [Thread-10 ]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m11:49:50.497913 [debug] [Thread-10 ]: On seed.dbt_databricks_proj.lookup: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "seed.dbt_databricks_proj.lookup"} */

    create  table `dbt_databricks_proj_prod`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_email` string )
    
  using delta
    
    
    
    
    
  
[0m11:49:50.497913 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:49:50.759838 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4b7d-1708-b46a-20eeeff702db) - Created
[0m11:49:53.066053 [debug] [Thread-10 ]: SQL status: OK in 2.570 seconds
[0m11:49:53.068066 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-4b7d-1708-b46a-20eeeff702db, command-id=01f0874b-4b87-174d-8606-982a100349a8) - Closing
[0m11:49:53.085862 [debug] [Thread-10 ]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m11:49:53.085862 [debug] [Thread-10 ]: On seed.dbt_databricks_proj.lookup: 
          insert overwrite `dbt_databricks_proj_prod`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m11:49:55.013504 [debug] [Thread-10 ]: SQL status: OK in 1.930 seconds
[0m11:49:55.013504 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-4b7d-1708-b46a-20eeeff702db, command-id=01f0874b-4ce9-1e27-995f-4593f32ad24d) - Closing
[0m11:49:55.019027 [debug] [Thread-10 ]: Writing runtime SQL for node "seed.dbt_databricks_proj.lookup"
[0m11:49:55.027701 [debug] [Thread-10 ]: On seed.dbt_databricks_proj.lookup: Close
[0m11:49:55.027701 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4b7d-1708-b46a-20eeeff702db) - Closing
[0m11:49:55.113388 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092FF284A0>]}
[0m11:49:55.113388 [info ] [Thread-10 ]: 8 of 17 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 4.66s]
[0m11:49:55.117167 [debug] [Thread-10 ]: Finished running node seed.dbt_databricks_proj.lookup
[0m11:49:55.118896 [debug] [Thread-10 ]: Began running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m11:49:55.118896 [info ] [Thread-10 ]: 9 of 17 START test non_negitive_bronze_sales_gross_amount ...................... [RUN]
[0m11:49:55.120531 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13) - Creating connection
[0m11:49:55.120531 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13'
[0m11:49:55.121166 [debug] [Thread-10 ]: Began compiling node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m11:49:55.126466 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m11:49:55.128474 [debug] [Thread-10 ]: Began executing node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m11:49:55.149794 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m11:49:55.149794 [debug] [Thread-10 ]: Using databricks connection "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m11:49:55.149794 [debug] [Thread-10 ]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

select 
    *
from 
    `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
where 
    gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m11:49:55.149794 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:49:55.401958 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4e42-1010-9f6a-feaf3e653038) - Created
[0m11:49:57.386463 [debug] [Thread-10 ]: SQL status: OK in 2.240 seconds
[0m11:49:57.390150 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-4e42-1010-9f6a-feaf3e653038, command-id=01f0874b-4e4b-157b-b1d0-1c48be99901b) - Closing
[0m11:49:57.395788 [debug] [Thread-10 ]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: Close
[0m11:49:57.396459 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4e42-1010-9f6a-feaf3e653038) - Closing
[0m11:49:57.482158 [info ] [Thread-10 ]: 9 of 17 PASS non_negitive_bronze_sales_gross_amount ............................ [[32mPASS[0m in 2.36s]
[0m11:49:57.487756 [debug] [Thread-10 ]: Finished running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m11:49:57.487756 [debug] [Thread-10 ]: Began running node test.dbt_databricks_proj.non_negitive_test
[0m11:49:57.489768 [info ] [Thread-10 ]: 10 of 17 START test non_negitive_test .......................................... [RUN]
[0m11:49:57.489768 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_test) - Creating connection
[0m11:49:57.489768 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_test'
[0m11:49:57.489768 [debug] [Thread-10 ]: Began compiling node test.dbt_databricks_proj.non_negitive_test
[0m11:49:57.495798 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_test"
[0m11:49:57.497806 [debug] [Thread-10 ]: Began executing node test.dbt_databricks_proj.non_negitive_test
[0m11:49:57.501190 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_test"
[0m11:49:57.503206 [debug] [Thread-10 ]: Using databricks connection "test.dbt_databricks_proj.non_negitive_test"
[0m11:49:57.503914 [debug] [Thread-10 ]: On test.dbt_databricks_proj.non_negitive_test: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.non_negitive_test"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  select *
from `dbt_databricks_proj_prod`.`bronze`.`bronze_sales` 
where gross_amount < 0 and net_amount < 0
  
  
      
    ) dbt_internal_test
[0m11:49:57.503914 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:49:57.767243 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4fa9-15f6-8724-537220e78905) - Created
[0m11:49:58.914275 [debug] [Thread-10 ]: SQL status: OK in 1.410 seconds
[0m11:49:58.918441 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-4fa9-15f6-8724-537220e78905, command-id=01f0874b-4fb4-1227-884e-df4325b09c5f) - Closing
[0m11:49:58.920450 [debug] [Thread-10 ]: On test.dbt_databricks_proj.non_negitive_test: Close
[0m11:49:58.920450 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-4fa9-15f6-8724-537220e78905) - Closing
[0m11:49:58.990681 [info ] [Thread-10 ]: 10 of 17 PASS non_negitive_test ................................................ [[32mPASS[0m in 1.50s]
[0m11:49:58.992694 [debug] [Thread-10 ]: Finished running node test.dbt_databricks_proj.non_negitive_test
[0m11:49:58.992694 [debug] [Thread-10 ]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:49:58.994707 [info ] [Thread-10 ]: 11 of 17 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m11:49:58.994707 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m11:49:58.996719 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m11:49:58.996719 [debug] [Thread-10 ]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:49:59.007148 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:49:59.009156 [debug] [Thread-10 ]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:49:59.015408 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:49:59.015408 [debug] [Thread-10 ]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m11:49:59.017418 [debug] [Thread-10 ]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m11:49:59.017418 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:49:59.289194 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-5093-147b-b7aa-72df6a4d78d8) - Created
[0m11:49:59.976275 [debug] [Thread-10 ]: SQL status: OK in 0.960 seconds
[0m11:49:59.980297 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-5093-147b-b7aa-72df6a4d78d8, command-id=01f0874b-509c-1858-a718-62f38eede1e7) - Closing
[0m11:49:59.980297 [debug] [Thread-10 ]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m11:49:59.980297 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-5093-147b-b7aa-72df6a4d78d8) - Closing
[0m11:50:00.085471 [info ] [Thread-10 ]: 11 of 17 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 1.09s]
[0m11:50:00.087482 [debug] [Thread-10 ]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m11:50:00.087482 [debug] [Thread-10 ]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m11:50:00.087482 [info ] [Thread-10 ]: 12 of 17 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m11:50:00.089703 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m11:50:00.089703 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m11:50:00.089703 [debug] [Thread-10 ]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m11:50:00.243958 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:50:00.245970 [debug] [Thread-10 ]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m11:50:00.250186 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:50:00.251196 [debug] [Thread-10 ]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m11:50:00.251196 [debug] [Thread-10 ]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:50:00.251196 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:50:00.530946 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-514e-17cc-9926-f0051eb46d15) - Created
[0m11:50:01.676596 [debug] [Thread-10 ]: SQL status: OK in 1.430 seconds
[0m11:50:01.681415 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-514e-17cc-9926-f0051eb46d15, command-id=01f0874b-5159-1ed8-9919-f77faffbabab) - Closing
[0m11:50:01.683425 [debug] [Thread-10 ]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m11:50:01.683425 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-514e-17cc-9926-f0051eb46d15) - Closing
[0m11:50:01.771927 [info ] [Thread-10 ]: 12 of 17 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.68s]
[0m11:50:01.771927 [debug] [Thread-10 ]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m11:50:01.773940 [debug] [Thread-10 ]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:50:01.775160 [info ] [Thread-10 ]: 13 of 17 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m11:50:01.776641 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m11:50:01.776641 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m11:50:01.776641 [debug] [Thread-10 ]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:50:01.782432 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:50:01.784447 [debug] [Thread-10 ]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:50:01.787662 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:50:01.788628 [debug] [Thread-10 ]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m11:50:01.788628 [debug] [Thread-10 ]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_prod`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m11:50:01.788628 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:50:02.052955 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-5237-1bc5-9dc5-3e7d10f98b47) - Created
[0m11:50:03.202991 [debug] [Thread-10 ]: SQL status: OK in 1.410 seconds
[0m11:50:03.208613 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-5237-1bc5-9dc5-3e7d10f98b47, command-id=01f0874b-5241-1742-973b-40e84d4420a1) - Closing
[0m11:50:03.208613 [debug] [Thread-10 ]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m11:50:03.208613 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-5237-1bc5-9dc5-3e7d10f98b47) - Closing
[0m11:50:03.294017 [info ] [Thread-10 ]: 13 of 17 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 1.52s]
[0m11:50:03.295026 [debug] [Thread-10 ]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m11:50:03.295026 [debug] [Thread-10 ]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m11:50:03.297041 [info ] [Thread-10 ]: 14 of 17 START test not_null_bronze_store_store_sk ............................. [RUN]
[0m11:50:03.297041 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m11:50:03.297041 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m11:50:03.299053 [debug] [Thread-10 ]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m11:50:03.303470 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:50:03.305480 [debug] [Thread-10 ]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m11:50:03.309508 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:50:03.309508 [debug] [Thread-10 ]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m11:50:03.309508 [debug] [Thread-10 ]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_prod`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m11:50:03.311265 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:50:03.579156 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-5320-18a8-827b-c2b6dc8d64ef) - Created
[0m11:50:04.129768 [debug] [Thread-10 ]: SQL status: OK in 0.820 seconds
[0m11:50:04.134418 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-5320-18a8-827b-c2b6dc8d64ef, command-id=01f0874b-532b-19cc-810e-cfc6c9261680) - Closing
[0m11:50:04.134418 [debug] [Thread-10 ]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m11:50:04.136429 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-5320-18a8-827b-c2b6dc8d64ef) - Closing
[0m11:50:04.226757 [info ] [Thread-10 ]: 14 of 17 PASS not_null_bronze_store_store_sk ................................... [[32mPASS[0m in 0.93s]
[0m11:50:04.226757 [debug] [Thread-10 ]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m11:50:04.226757 [debug] [Thread-10 ]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m11:50:04.230088 [info ] [Thread-10 ]: 15 of 17 START test unique_bronze_store_store_sk ............................... [RUN]
[0m11:50:04.230088 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m11:50:04.230088 [debug] [Thread-10 ]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m11:50:04.230088 [debug] [Thread-10 ]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m11:50:04.238341 [debug] [Thread-10 ]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m11:50:04.239157 [debug] [Thread-10 ]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m11:50:04.241167 [debug] [Thread-10 ]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m11:50:04.243179 [debug] [Thread-10 ]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m11:50:04.243179 [debug] [Thread-10 ]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_prod`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m11:50:04.243179 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:50:04.503372 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-53ae-1191-b356-19f4902d7a6b) - Created
[0m11:50:05.089416 [debug] [Thread-10 ]: SQL status: OK in 0.850 seconds
[0m11:50:05.097542 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-53ae-1191-b356-19f4902d7a6b, command-id=01f0874b-53b7-1dc3-879d-1cf97150a693) - Closing
[0m11:50:05.097542 [debug] [Thread-10 ]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m11:50:05.097542 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-53ae-1191-b356-19f4902d7a6b) - Closing
[0m11:50:05.190713 [info ] [Thread-10 ]: 15 of 17 PASS unique_bronze_store_store_sk ..................................... [[32mPASS[0m in 0.96s]
[0m11:50:05.190713 [debug] [Thread-10 ]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m11:50:05.190713 [debug] [Thread-10 ]: Began running node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m11:50:05.190713 [info ] [Thread-10 ]: 16 of 17 SKIP relation gold.gold_items_snapshot ................................ [[33mSKIP[0m]
[0m11:50:05.194366 [debug] [Thread-10 ]: Finished running node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m11:50:05.194366 [debug] [Thread-10 ]: Began running node model.dbt_databricks_proj.silver_salesinfo
[0m11:50:05.194366 [debug] [Thread-13 ]: Marking all children of 'snapshot.dbt_databricks_proj.gold_items_snapshot' to be skipped because of status 'skipped'. 
[0m11:50:05.196382 [info ] [Thread-10 ]: 17 of 17 START sql table model silver.silver_salesinfo ......................... [RUN]
[0m11:50:05.196382 [debug] [Thread-10 ]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.silver_salesinfo) - Creating connection
[0m11:50:05.199045 [debug] [Thread-10 ]: Acquiring new databricks connection 'model.dbt_databricks_proj.silver_salesinfo'
[0m11:50:05.199045 [debug] [Thread-10 ]: Began compiling node model.dbt_databricks_proj.silver_salesinfo
[0m11:50:05.204763 [debug] [Thread-10 ]: Writing injected SQL for node "model.dbt_databricks_proj.silver_salesinfo"
[0m11:50:05.205275 [debug] [Thread-10 ]: Began executing node model.dbt_databricks_proj.silver_salesinfo
[0m11:50:05.207901 [debug] [Thread-10 ]: MATERIALIZING TABLE
[0m11:50:05.210491 [debug] [Thread-10 ]: Writing runtime sql for node "model.dbt_databricks_proj.silver_salesinfo"
[0m11:50:05.211577 [debug] [Thread-10 ]: Using databricks connection "model.dbt_databricks_proj.silver_salesinfo"
[0m11:50:05.211577 [debug] [Thread-10 ]: On model.dbt_databricks_proj.silver_salesinfo: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.silver_salesinfo"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`silver`.`silver_salesinfo`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with customers as (
    select * from `dbt_databricks_proj_prod`.`bronze`.`bronze_customer`
),
products as (
    select * from `dbt_databricks_proj_prod`.`bronze`.`bronze_product`
),
sales as (
    select * from `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
),
joined_data as (

select 
    s.sales_id,
    
    s.quantity * s.unit_price
 as gross_amount,
    
    s.payment_method,
    c.gender,
    p.category
from sales s
join customers c on s.customer_sk = c.customer_sk  
join products p on s.product_sk = p.product_sk

)

select 
    category,
    gender,
    sum(gross_amount) as total_gross_amount
from joined_data
group by 
    category,gender
order by
    total_gross_amount desc
  
[0m11:50:05.211577 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m11:50:05.464797 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-5440-13c3-8247-201b37e0cc03) - Created
[0m11:50:09.237886 [debug] [Thread-10 ]: SQL status: OK in 4.030 seconds
[0m11:50:09.239902 [debug] [Thread-10 ]: Databricks adapter: Cursor(session-id=01f0874b-5440-13c3-8247-201b37e0cc03, command-id=01f0874b-5449-1f8b-9531-8ae8502214fb) - Closing
[0m11:50:09.239902 [debug] [Thread-10 ]: Applying tags to relation None
[0m11:50:09.243386 [debug] [Thread-10 ]: On model.dbt_databricks_proj.silver_salesinfo: Close
[0m11:50:09.243386 [debug] [Thread-10 ]: Databricks adapter: Connection(session-id=01f0874b-5440-13c3-8247-201b37e0cc03) - Closing
[0m11:50:09.325054 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4177c081-76b8-44b0-8dc9-3dc458182c69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001092F5D1070>]}
[0m11:50:09.325054 [info ] [Thread-10 ]: 17 of 17 OK created sql table model silver.silver_salesinfo .................... [[32mOK[0m in 4.13s]
[0m11:50:09.333102 [debug] [Thread-10 ]: Finished running node model.dbt_databricks_proj.silver_salesinfo
[0m11:50:09.335879 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m11:50:09.335879 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m11:50:09.335879 [info ] [MainThread]: 
[0m11:50:09.335879 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 5 table models, 7 data tests, 3 view models in 0 hours 1 minutes and 50.23 seconds (110.23s).
[0m11:50:09.343523 [debug] [MainThread]: Command end result
[0m11:50:09.398904 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m11:50:09.407177 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m11:50:09.415220 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m11:50:09.415220 [info ] [MainThread]: 
[0m11:50:09.415220 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:50:09.423909 [info ] [MainThread]: 
[0m11:50:09.423909 [error] [MainThread]: [31mFailure in model source_gold_items (models\gold\source_gold_items.sql)[0m
[0m11:50:09.426195 [error] [MainThread]:   Database Error in model source_gold_items (models\gold\source_gold_items.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
  compiled code at target\run\dbt_databricks_proj\models\gold\source_gold_items.sql
[0m11:50:09.426195 [info ] [MainThread]: 
[0m11:50:09.428207 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_proj\models\gold\source_gold_items.sql
[0m11:50:09.428207 [info ] [MainThread]: 
[0m11:50:09.430219 [info ] [MainThread]: Done. PASS=15 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=17
[0m11:50:09.431973 [debug] [MainThread]: Command `dbt build` failed at 11:50:09.430219 after 127.00 seconds
[0m11:50:09.431973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001097E958EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001097E958350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001097E485640>]}
[0m11:50:09.431973 [debug] [MainThread]: Flushing usage events
[0m11:50:09.934321 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:11:45.363391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027380329D60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027381777500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027383179A90>]}


============================== 12:11:45.367698 | e800e770-e773-4101-98dc-2bb46488bb3a ==============================
[0m12:11:45.367698 [info ] [MainThread]: Running with dbt=1.10.10
[0m12:11:45.367698 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt build --target prod', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'log_cache_events': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj'}
[0m12:11:46.611071 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:11:46.611071 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:11:46.611071 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:11:47.838890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273816BD700>]}
[0m12:11:47.909914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B2E46FC0>]}
[0m12:11:47.909914 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m12:11:48.344487 [debug] [MainThread]: checksum: af4148875ea7aa1549d372d0d0c9ad91031d05358531ca115c8e08a093099b13, vars: {}, profile: , target: prod, version: 1.10.10
[0m12:11:48.502097 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m12:11:48.502097 [debug] [MainThread]: previous checksum: af4148875ea7aa1549d372d0d0c9ad91031d05358531ca115c8e08a093099b13, current checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b
[0m12:11:48.502097 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m12:11:48.502097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B35877D0>]}
[0m12:11:51.347256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B4B6DDC0>]}
[0m12:11:51.499467 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m12:11:51.499467 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m12:11:51.546963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B4CFA330>]}
[0m12:11:51.546963 [info ] [MainThread]: Found 8 models, 5 analyses, 7 data tests, 1 seed, 1 snapshot, 7 sources, 688 macros
[0m12:11:51.552192 [info ] [MainThread]: 
[0m12:11:51.552192 [info ] [MainThread]: Concurrency: 1 threads (target='prod')
[0m12:11:51.552192 [info ] [MainThread]: 
[0m12:11:51.552192 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m12:11:51.552192 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:11:51.565430 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod) - Creating connection
[0m12:11:51.565430 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod'
[0m12:11:51.567526 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod"
[0m12:11:51.567526 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: GetSchemas(database=dbt_databricks_proj_prod, schema=None)
[0m12:11:51.568139 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:11:52.188178 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-5efb-1311-870f-46722997f6f6) - Created
[0m12:12:53.627675 [debug] [ThreadPool]: SQL status: OK in 62.060 seconds
[0m12:12:53.627675 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874e-5efb-1311-870f-46722997f6f6, command-id=01f0874e-82fa-1b80-803b-353b3db1f3d0) - Closing
[0m12:12:53.627675 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: Close
[0m12:12:53.627675 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-5efb-1311-870f-46722997f6f6) - Closing
[0m12:12:53.740618 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod) - Creating connection
[0m12:12:53.741581 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod'
[0m12:12:53.741581 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod"
[0m12:12:53.741581 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: GetSchemas(database=dbt_databricks_proj_prod, schema=None)
[0m12:12:53.741581 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:54.072981 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-83fb-1cb4-9e72-65ed100bdf7d) - Created
[0m12:12:54.351054 [debug] [ThreadPool]: SQL status: OK in 0.610 seconds
[0m12:12:54.353068 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874e-83fb-1cb4-9e72-65ed100bdf7d, command-id=01f0874e-840a-1caa-95af-b2ba5e9ebc63) - Closing
[0m12:12:54.353068 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: Close
[0m12:12:54.353068 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-83fb-1cb4-9e72-65ed100bdf7d) - Closing
[0m12:12:54.438389 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod) - Creating connection
[0m12:12:54.440404 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod'
[0m12:12:54.440404 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod"
[0m12:12:54.440404 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: GetSchemas(database=dbt_databricks_proj_prod, schema=None)
[0m12:12:54.440404 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:54.692741 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-845f-1fad-b488-f028a94d172b) - Created
[0m12:12:54.900334 [debug] [ThreadPool]: SQL status: OK in 0.460 seconds
[0m12:12:54.901480 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874e-845f-1fad-b488-f028a94d172b, command-id=01f0874e-846c-1e22-bb7c-fff39b57728a) - Closing
[0m12:12:54.902965 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod: Close
[0m12:12:54.902965 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-845f-1fad-b488-f028a94d172b) - Closing
[0m12:12:54.989163 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod_bronze) - Creating connection
[0m12:12:54.989163 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod_bronze'
[0m12:12:55.012257 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod_bronze"
[0m12:12:55.012257 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "connection_name": "list_dbt_databricks_proj_prod_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_prod' 
  AND table_schema = 'bronze'

  
[0m12:12:55.012257 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:55.284114 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-84ba-1041-abf1-41389b8d6adb) - Created
[0m12:12:58.245584 [debug] [ThreadPool]: SQL status: OK in 3.230 seconds
[0m12:12:58.259712 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874e-84ba-1041-abf1-41389b8d6adb, command-id=01f0874e-84c3-16c2-811d-40a67ba30eb7) - Closing
[0m12:12:58.259712 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_bronze: Close
[0m12:12:58.259712 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-84ba-1041-abf1-41389b8d6adb) - Closing
[0m12:12:58.348624 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod_gold) - Creating connection
[0m12:12:58.350638 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod_gold'
[0m12:12:58.357125 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod_gold"
[0m12:12:58.357125 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "connection_name": "list_dbt_databricks_proj_prod_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_prod' 
  AND table_schema = 'gold'

  
[0m12:12:58.359134 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:58.610857 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-86b5-19cc-bd1e-72e1921dd016) - Created
[0m12:12:59.062573 [debug] [ThreadPool]: SQL status: OK in 0.700 seconds
[0m12:12:59.066599 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874e-86b5-19cc-bd1e-72e1921dd016, command-id=01f0874e-86bf-1929-b330-ba0ebf81277b) - Closing
[0m12:12:59.068614 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_gold: Close
[0m12:12:59.068614 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-86b5-19cc-bd1e-72e1921dd016) - Closing
[0m12:12:59.154628 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_prod_silver) - Creating connection
[0m12:12:59.154628 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_prod_silver'
[0m12:12:59.154628 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_prod_silver"
[0m12:12:59.162678 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "connection_name": "list_dbt_databricks_proj_prod_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_prod' 
  AND table_schema = 'silver'

  
[0m12:12:59.163213 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:12:59.436617 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-872f-1ccb-8256-fcd36a65ea7c) - Created
[0m12:13:00.135891 [debug] [ThreadPool]: SQL status: OK in 0.970 seconds
[0m12:13:00.141679 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0874e-872f-1ccb-8256-fcd36a65ea7c, command-id=01f0874e-873d-1582-bfa7-1452fe9b9a71) - Closing
[0m12:13:00.141679 [debug] [ThreadPool]: On list_dbt_databricks_proj_prod_silver: Close
[0m12:13:00.145924 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0874e-872f-1ccb-8256-fcd36a65ea7c) - Closing
[0m12:13:00.221268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B4CD9F10>]}
[0m12:13:00.236685 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_customer
[0m12:13:00.236685 [info ] [Thread-7 (]: 1 of 17 START sql table model bronze.bronze_customer ........................... [RUN]
[0m12:13:00.244893 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_customer) - Creating connection
[0m12:13:00.246860 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_customer'
[0m12:13:00.246860 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_customer
[0m12:13:00.272752 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_customer"
[0m12:13:00.277022 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_customer
[0m12:13:00.318965 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m12:13:00.324611 [warn ] [Thread-7 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m12:13:00.327102 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B52AC6B0>]}
[0m12:13:00.429207 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_customer"
[0m12:13:00.431217 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_customer"
[0m12:13:00.435182 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_customer"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_prod`.`source`.`dim_customer`
  
[0m12:13:00.435182 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:00.776170 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-87ff-1e1d-bc54-d61fc64a51fe) - Created
[0m12:13:09.973585 [debug] [Thread-7 (]: SQL status: OK in 9.540 seconds
[0m12:13:09.974310 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-87ff-1e1d-bc54-d61fc64a51fe, command-id=01f0874e-880a-1220-851f-6ef51a42351d) - Closing
[0m12:13:10.147781 [debug] [Thread-7 (]: Applying tags to relation None
[0m12:13:10.197033 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_customer: Close
[0m12:13:10.198385 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-87ff-1e1d-bc54-d61fc64a51fe) - Closing
[0m12:13:10.313240 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027380E1BCB0>]}
[0m12:13:10.316103 [info ] [Thread-7 (]: 1 of 17 OK created sql table model bronze.bronze_customer ...................... [[32mOK[0m in 10.07s]
[0m12:13:10.316103 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_customer
[0m12:13:10.323632 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_date
[0m12:13:10.324795 [info ] [Thread-7 (]: 2 of 17 START sql view model bronze.bronze_date ................................ [RUN]
[0m12:13:10.324795 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_date) - Creating connection
[0m12:13:10.324795 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_date'
[0m12:13:10.324795 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_date
[0m12:13:10.334577 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_date"
[0m12:13:10.339657 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_date
[0m12:13:10.379859 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m12:13:10.402142 [debug] [Thread-7 (]: Creating view `dbt_databricks_proj_prod`.`bronze`.`bronze_date`
[0m12:13:10.404663 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_date"
[0m12:13:10.406419 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_date"
[0m12:13:10.406419 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_date"} */

  
  
  create or replace view `dbt_databricks_proj_prod`.`bronze`.`bronze_date`
  
  as (
    select * from `dbt_databricks_proj_prod`.`source`.`dim_date`
  )

[0m12:13:10.410722 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:10.930970 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-8e04-1a30-9e66-1da813e473f8) - Created
[0m12:13:11.865155 [debug] [Thread-7 (]: SQL status: OK in 1.450 seconds
[0m12:13:11.869566 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-8e04-1a30-9e66-1da813e473f8, command-id=01f0874e-8e17-19eb-8bb7-5a6cc7732cb6) - Closing
[0m12:13:11.870078 [debug] [Thread-7 (]: Applying tags to relation None
[0m12:13:11.874429 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_date: Close
[0m12:13:11.876813 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-8e04-1a30-9e66-1da813e473f8) - Closing
[0m12:13:11.959466 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B532BAA0>]}
[0m12:13:11.965220 [info ] [Thread-7 (]: 2 of 17 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 1.63s]
[0m12:13:11.967233 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_date
[0m12:13:11.969249 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_product
[0m12:13:11.971260 [info ] [Thread-7 (]: 3 of 17 START sql view model bronze.bronze_product ............................. [RUN]
[0m12:13:11.973418 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_product) - Creating connection
[0m12:13:11.973418 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_product'
[0m12:13:11.973418 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_product
[0m12:13:11.985746 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_product"
[0m12:13:11.990882 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_product
[0m12:13:11.999454 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m12:13:12.006711 [debug] [Thread-7 (]: Creating view `dbt_databricks_proj_prod`.`bronze`.`bronze_product`
[0m12:13:12.008872 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_product"
[0m12:13:12.015978 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_product"
[0m12:13:12.015978 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_product"} */

  
  
  create or replace view `dbt_databricks_proj_prod`.`bronze`.`bronze_product`
  
  as (
    select * from `dbt_databricks_proj_prod`.`source`.`dim_product`
  )

[0m12:13:12.017990 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:12.411776 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-8eea-1936-aa78-67cad1a674c6) - Created
[0m12:13:12.990777 [debug] [Thread-7 (]: SQL status: OK in 0.970 seconds
[0m12:13:12.994799 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-8eea-1936-aa78-67cad1a674c6, command-id=01f0874e-8ef9-1dc4-beb1-9fdc5b75fd09) - Closing
[0m12:13:12.996807 [debug] [Thread-7 (]: Applying tags to relation None
[0m12:13:12.999444 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_product: Close
[0m12:13:12.999444 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-8eea-1936-aa78-67cad1a674c6) - Closing
[0m12:13:13.081974 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B5316840>]}
[0m12:13:13.083655 [info ] [Thread-7 (]: 3 of 17 OK created sql view model bronze.bronze_product ........................ [[32mOK[0m in 1.11s]
[0m12:13:13.083655 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_product
[0m12:13:13.083655 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_returns
[0m12:13:13.083655 [info ] [Thread-7 (]: 4 of 17 START sql table model bronze.bronze_returns ............................ [RUN]
[0m12:13:13.090620 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_returns) - Creating connection
[0m12:13:13.090620 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_returns'
[0m12:13:13.090620 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_returns
[0m12:13:13.100832 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_returns"
[0m12:13:13.106821 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_returns
[0m12:13:13.111211 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m12:13:13.116405 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_returns"
[0m12:13:13.122473 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_returns"
[0m12:13:13.123977 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_returns"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_prod`.`source`.`fact_returns`
  
[0m12:13:13.123977 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:13.459060 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-8f8f-11f5-a5e0-1b609590d50c) - Created
[0m12:13:15.719903 [debug] [Thread-7 (]: SQL status: OK in 2.590 seconds
[0m12:13:15.723493 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-8f8f-11f5-a5e0-1b609590d50c, command-id=01f0874e-8f99-1dcb-8464-3dc6fa500371) - Closing
[0m12:13:15.725698 [debug] [Thread-7 (]: Applying tags to relation None
[0m12:13:15.730112 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_returns: Close
[0m12:13:15.730112 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-8f8f-11f5-a5e0-1b609590d50c) - Closing
[0m12:13:15.877183 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B529D520>]}
[0m12:13:15.881093 [info ] [Thread-7 (]: 4 of 17 OK created sql table model bronze.bronze_returns ....................... [[32mOK[0m in 2.79s]
[0m12:13:15.883759 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_returns
[0m12:13:15.883759 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_sales
[0m12:13:15.885771 [info ] [Thread-7 (]: 5 of 17 START sql view model bronze.bronze_sales ............................... [RUN]
[0m12:13:15.887793 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_sales) - Creating connection
[0m12:13:15.890119 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_sales'
[0m12:13:15.890119 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_sales
[0m12:13:15.903758 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_sales"
[0m12:13:15.907780 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_sales
[0m12:13:15.913854 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m12:13:15.917866 [debug] [Thread-7 (]: Creating view `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
[0m12:13:15.917866 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_sales"
[0m12:13:15.921887 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_sales"
[0m12:13:15.923356 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_sales"} */

  
  
  create or replace view `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
  
  as (
    select * from `dbt_databricks_proj_prod`.`source`.`fact_sales`
  )

[0m12:13:15.924620 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:16.630437 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-9167-157f-a5bc-c7e882155981) - Created
[0m12:13:17.093038 [debug] [Thread-7 (]: SQL status: OK in 1.170 seconds
[0m12:13:17.093038 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-9167-157f-a5bc-c7e882155981, command-id=01f0874e-917d-11aa-9fea-c255c3ccc03e) - Closing
[0m12:13:17.097811 [debug] [Thread-7 (]: Applying tags to relation None
[0m12:13:17.101039 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_sales: Close
[0m12:13:17.102058 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-9167-157f-a5bc-c7e882155981) - Closing
[0m12:13:17.282239 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B52CB3E0>]}
[0m12:13:17.284248 [info ] [Thread-7 (]: 5 of 17 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 1.39s]
[0m12:13:17.285764 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_sales
[0m12:13:17.285764 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_store
[0m12:13:17.290025 [info ] [Thread-7 (]: 6 of 17 START sql table model bronze.bronze_store .............................. [RUN]
[0m12:13:17.292724 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_store) - Creating connection
[0m12:13:17.294239 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_store'
[0m12:13:17.294239 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_store
[0m12:13:17.310911 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_store"
[0m12:13:17.320963 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_store
[0m12:13:17.327300 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m12:13:17.327954 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_store"
[0m12:13:17.327954 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_store"
[0m12:13:17.335532 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.bronze_store"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_prod`.`source`.`dim_store`
  
[0m12:13:17.335532 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:17.987409 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-9241-11dd-bee2-943b7b5aec7c) - Created
[0m12:13:20.221443 [debug] [Thread-7 (]: SQL status: OK in 2.890 seconds
[0m12:13:20.226156 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-9241-11dd-bee2-943b7b5aec7c, command-id=01f0874e-924c-1793-912a-379ad7c95986) - Closing
[0m12:13:20.226156 [debug] [Thread-7 (]: Applying tags to relation None
[0m12:13:20.231189 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_store: Close
[0m12:13:20.231189 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-9241-11dd-bee2-943b7b5aec7c) - Closing
[0m12:13:20.323128 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B535D250>]}
[0m12:13:20.324178 [info ] [Thread-7 (]: 6 of 17 OK created sql table model bronze.bronze_store ......................... [[32mOK[0m in 3.03s]
[0m12:13:20.324178 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_store
[0m12:13:20.326187 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.source_gold_items
[0m12:13:20.326187 [info ] [Thread-7 (]: 7 of 17 START sql table model gold.source_gold_items ........................... [RUN]
[0m12:13:20.329179 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.source_gold_items) - Creating connection
[0m12:13:20.329179 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.source_gold_items'
[0m12:13:20.331220 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.source_gold_items
[0m12:13:20.341907 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.source_gold_items"
[0m12:13:20.345589 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.source_gold_items
[0m12:13:20.351934 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m12:13:20.360607 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.source_gold_items"
[0m12:13:20.362615 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.source_gold_items"
[0m12:13:20.364130 [debug] [Thread-7 (]: On model.dbt_databricks_proj.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.source_gold_items"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`gold`.`source_gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with cte1 as (
select *,
row_number() over (partition by id order by updatedDate desc) as dedup_id
from 
`dbt_databricks_proj_prod`.`source`.`items`

)

select id,name,category,updatedDate from cte1
where dedup_id=1
  
[0m12:13:20.364130 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:20.717209 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-93e1-1ea4-9dc7-0e23d7434b0a) - Created
[0m12:13:21.111784 [debug] [Thread-7 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.source_gold_items"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`gold`.`source_gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with cte1 as (
select *,
row_number() over (partition by id order by updatedDate desc) as dedup_id
from 
`dbt_databricks_proj_prod`.`source`.`items`

)

select id,name,category,updatedDate from cte1
where dedup_id=1
  
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f0874e-93ed-14f8-b8f6-13ecf2df16f7
[0m12:13:21.113796 [debug] [Thread-7 (]: On model.dbt_databricks_proj.source_gold_items: Close
[0m12:13:21.115807 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-93e1-1ea4-9dc7-0e23d7434b0a) - Closing
[0m12:13:21.228011 [debug] [Thread-7 (]: Database Error in model source_gold_items (models\gold\source_gold_items.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
  compiled code at target\run\dbt_databricks_proj\models\gold\source_gold_items.sql
[0m12:13:21.231537 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B52915B0>]}
[0m12:13:21.231537 [error] [Thread-7 (]: 7 of 17 ERROR creating sql table model gold.source_gold_items .................. [[31mERROR[0m in 0.90s]
[0m12:13:21.231537 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.source_gold_items
[0m12:13:21.236124 [debug] [Thread-7 (]: Began running node seed.dbt_databricks_proj.lookup
[0m12:13:21.236124 [debug] [Thread-10 ]: Marking all children of 'model.dbt_databricks_proj.source_gold_items' to be skipped because of status 'error'.  Reason: Database Error in model source_gold_items (models\gold\source_gold_items.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
  compiled code at target\run\dbt_databricks_proj\models\gold\source_gold_items.sql.
[0m12:13:21.238647 [info ] [Thread-7 (]: 8 of 17 START seed file bronze.lookup .......................................... [RUN]
[0m12:13:21.241128 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_databricks_proj.lookup) - Creating connection
[0m12:13:21.243150 [debug] [Thread-7 (]: Acquiring new databricks connection 'seed.dbt_databricks_proj.lookup'
[0m12:13:21.243150 [debug] [Thread-7 (]: Began compiling node seed.dbt_databricks_proj.lookup
[0m12:13:21.245163 [debug] [Thread-7 (]: Began executing node seed.dbt_databricks_proj.lookup
[0m12:13:21.337116 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m12:13:21.340061 [debug] [Thread-7 (]: On seed.dbt_databricks_proj.lookup: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "seed.dbt_databricks_proj.lookup"} */

    create or replace table `dbt_databricks_proj_prod`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_email` string )
    
  using delta
    
    
    
    
    
  
[0m12:13:21.340061 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:21.676201 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-9474-1174-b0f0-a33fa1687d4a) - Created
[0m12:13:22.819515 [debug] [Thread-7 (]: SQL status: OK in 1.480 seconds
[0m12:13:22.819515 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-9474-1174-b0f0-a33fa1687d4a, command-id=01f0874e-947f-10a3-8bd5-a51142300fbf) - Closing
[0m12:13:22.858377 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m12:13:22.858377 [debug] [Thread-7 (]: On seed.dbt_databricks_proj.lookup: 
          insert overwrite `dbt_databricks_proj_prod`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m12:13:24.359428 [debug] [Thread-7 (]: SQL status: OK in 1.500 seconds
[0m12:13:24.359428 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-9474-1174-b0f0-a33fa1687d4a, command-id=01f0874e-9533-1e0b-a950-ff5f9d06d07f) - Closing
[0m12:13:24.375484 [debug] [Thread-7 (]: Writing runtime SQL for node "seed.dbt_databricks_proj.lookup"
[0m12:13:24.378744 [debug] [Thread-7 (]: On seed.dbt_databricks_proj.lookup: Close
[0m12:13:24.378744 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-9474-1174-b0f0-a33fa1687d4a) - Closing
[0m12:13:24.484754 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B5307740>]}
[0m12:13:24.489741 [info ] [Thread-7 (]: 8 of 17 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 3.24s]
[0m12:13:24.493215 [debug] [Thread-7 (]: Finished running node seed.dbt_databricks_proj.lookup
[0m12:13:24.493215 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m12:13:24.495660 [info ] [Thread-7 (]: 9 of 17 START test non_negitive_bronze_sales_gross_amount ...................... [RUN]
[0m12:13:24.497411 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13) - Creating connection
[0m12:13:24.498604 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13'
[0m12:13:24.498604 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m12:13:24.509716 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m12:13:24.516631 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m12:13:24.574916 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m12:13:24.583279 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m12:13:24.583279 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

select 
    *
from 
    `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
where 
    gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m12:13:24.583279 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:46.241868 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a319-1a1a-9f38-e85475511d96) - Created
[0m12:13:47.436205 [debug] [Thread-7 (]: SQL status: OK in 22.850 seconds
[0m12:13:47.442752 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-a319-1a1a-9f38-e85475511d96, command-id=01f0874e-a323-1881-9464-a4f3d1aae489) - Closing
[0m12:13:47.450001 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: Close
[0m12:13:47.450719 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a319-1a1a-9f38-e85475511d96) - Closing
[0m12:13:47.527930 [info ] [Thread-7 (]: 9 of 17 PASS non_negitive_bronze_sales_gross_amount ............................ [[32mPASS[0m in 23.03s]
[0m12:13:47.532618 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m12:13:47.533906 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.non_negitive_test
[0m12:13:47.535920 [info ] [Thread-7 (]: 10 of 17 START test non_negitive_test .......................................... [RUN]
[0m12:13:47.539466 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_test) - Creating connection
[0m12:13:47.541480 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_test'
[0m12:13:47.543483 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.non_negitive_test
[0m12:13:47.557459 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_test"
[0m12:13:47.562697 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.non_negitive_test
[0m12:13:47.570283 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_test"
[0m12:13:47.573065 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.non_negitive_test"
[0m12:13:47.574077 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_test: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.non_negitive_test"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  select *
from `dbt_databricks_proj_prod`.`bronze`.`bronze_sales` 
where gross_amount < 0 and net_amount < 0
  
  
      
    ) dbt_internal_test
[0m12:13:47.574077 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:47.930521 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a41a-1adc-a390-fa06529c85dc) - Created
[0m12:13:48.611440 [debug] [Thread-7 (]: SQL status: OK in 1.040 seconds
[0m12:13:48.619078 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-a41a-1adc-a390-fa06529c85dc, command-id=01f0874e-a425-1797-9dbd-f5c321c6203b) - Closing
[0m12:13:48.619078 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_test: Close
[0m12:13:48.619078 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a41a-1adc-a390-fa06529c85dc) - Closing
[0m12:13:48.715490 [info ] [Thread-7 (]: 10 of 17 PASS non_negitive_test ................................................ [[32mPASS[0m in 1.17s]
[0m12:13:48.717780 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.non_negitive_test
[0m12:13:48.721613 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m12:13:48.721613 [info ] [Thread-7 (]: 11 of 17 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m12:13:48.726148 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m12:13:48.728183 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m12:13:48.728183 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m12:13:48.755059 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m12:13:48.759281 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m12:13:48.771055 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m12:13:48.773072 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m12:13:48.775088 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m12:13:48.776101 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:49.117302 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a4d0-115a-849c-88da63250597) - Created
[0m12:13:49.613953 [debug] [Thread-7 (]: SQL status: OK in 0.840 seconds
[0m12:13:49.620667 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-a4d0-115a-849c-88da63250597, command-id=01f0874e-a4da-1d1b-84dd-44d106eb296f) - Closing
[0m12:13:49.624065 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m12:13:49.624065 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a4d0-115a-849c-88da63250597) - Closing
[0m12:13:49.707846 [info ] [Thread-7 (]: 11 of 17 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 0.98s]
[0m12:13:49.712536 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m12:13:49.712536 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m12:13:49.715002 [info ] [Thread-7 (]: 12 of 17 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m12:13:49.716931 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m12:13:49.718693 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m12:13:49.718693 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m12:13:49.746343 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m12:13:49.752319 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m12:13:49.760155 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m12:13:49.764185 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m12:13:49.765197 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m12:13:49.765197 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:50.118623 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a566-1565-b961-332ffc459e7a) - Created
[0m12:13:50.687664 [debug] [Thread-7 (]: SQL status: OK in 0.920 seconds
[0m12:13:50.689698 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-a566-1565-b961-332ffc459e7a, command-id=01f0874e-a572-1def-91bf-06baeef818a1) - Closing
[0m12:13:50.696083 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m12:13:50.696083 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a566-1565-b961-332ffc459e7a) - Closing
[0m12:13:50.789688 [info ] [Thread-7 (]: 12 of 17 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.07s]
[0m12:13:50.791702 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m12:13:50.791702 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m12:13:50.794038 [info ] [Thread-7 (]: 13 of 17 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m12:13:50.794038 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m12:13:50.797210 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m12:13:50.799250 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m12:13:50.822431 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m12:13:50.822431 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m12:13:51.172774 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m12:13:51.176801 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m12:13:51.176801 [debug] [Thread-7 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_prod`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m12:13:51.179071 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:51.494582 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a63b-1431-a89e-ab9068616e51) - Created
[0m12:13:52.720284 [debug] [Thread-7 (]: SQL status: OK in 1.540 seconds
[0m12:13:52.728019 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-a63b-1431-a89e-ab9068616e51, command-id=01f0874e-a645-18c6-8cd5-75625a7c3826) - Closing
[0m12:13:52.728019 [debug] [Thread-7 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m12:13:52.728019 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a63b-1431-a89e-ab9068616e51) - Closing
[0m12:13:52.831268 [info ] [Thread-7 (]: 13 of 17 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 2.04s]
[0m12:13:52.835391 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m12:13:52.836279 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m12:13:52.837367 [info ] [Thread-7 (]: 14 of 17 START test not_null_bronze_store_store_sk ............................. [RUN]
[0m12:13:52.840181 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m12:13:52.842485 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m12:13:52.843773 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m12:13:52.857419 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m12:13:52.869383 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m12:13:52.879812 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m12:13:52.882479 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m12:13:52.883109 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_prod`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m12:13:52.887137 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:53.282311 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a74b-1c6f-a0ab-a1d6c23c9337) - Created
[0m12:13:53.782410 [debug] [Thread-7 (]: SQL status: OK in 0.900 seconds
[0m12:13:53.787617 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-a74b-1c6f-a0ab-a1d6c23c9337, command-id=01f0874e-a756-1655-8311-78468dd3eb6c) - Closing
[0m12:13:53.790347 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m12:13:53.792764 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a74b-1c6f-a0ab-a1d6c23c9337) - Closing
[0m12:13:53.870612 [info ] [Thread-7 (]: 14 of 17 PASS not_null_bronze_store_store_sk ................................... [[32mPASS[0m in 1.03s]
[0m12:13:53.870612 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m12:13:53.878732 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m12:13:53.878732 [info ] [Thread-7 (]: 15 of 17 START test unique_bronze_store_store_sk ............................... [RUN]
[0m12:13:53.886980 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m12:13:53.888263 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m12:13:53.888263 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m12:13:53.901236 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m12:13:53.905067 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m12:13:53.912799 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m12:13:53.915794 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m12:13:53.917916 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_prod`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m12:13:53.919925 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:54.285363 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a7e3-1799-96df-348c4c6b683c) - Created
[0m12:13:55.281823 [debug] [Thread-7 (]: SQL status: OK in 1.360 seconds
[0m12:13:55.287702 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-a7e3-1799-96df-348c4c6b683c, command-id=01f0874e-a7ef-1066-8946-9101d68571d1) - Closing
[0m12:13:55.290014 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m12:13:55.290887 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a7e3-1799-96df-348c4c6b683c) - Closing
[0m12:13:55.375877 [info ] [Thread-7 (]: 15 of 17 PASS unique_bronze_store_store_sk ..................................... [[32mPASS[0m in 1.49s]
[0m12:13:55.379129 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m12:13:55.379129 [debug] [Thread-7 (]: Began running node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m12:13:55.380640 [info ] [Thread-7 (]: 16 of 17 SKIP relation gold.gold_items_snapshot ................................ [[33mSKIP[0m]
[0m12:13:55.382847 [debug] [Thread-7 (]: Finished running node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m12:13:55.384342 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.silver_salesinfo
[0m12:13:55.385557 [debug] [Thread-10 ]: Marking all children of 'snapshot.dbt_databricks_proj.gold_items_snapshot' to be skipped because of status 'skipped'. 
[0m12:13:55.385557 [info ] [Thread-7 (]: 17 of 17 START sql table model silver.silver_salesinfo ......................... [RUN]
[0m12:13:55.389727 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.silver_salesinfo) - Creating connection
[0m12:13:55.389727 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.silver_salesinfo'
[0m12:13:55.389727 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.silver_salesinfo
[0m12:13:55.404598 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.silver_salesinfo"
[0m12:13:55.407130 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.silver_salesinfo
[0m12:13:55.415369 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m12:13:55.418723 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.silver_salesinfo"
[0m12:13:55.423881 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.silver_salesinfo"
[0m12:13:55.427684 [debug] [Thread-7 (]: On model.dbt_databricks_proj.silver_salesinfo: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "prod", "node_id": "model.dbt_databricks_proj.silver_salesinfo"} */

  
    
        create or replace table `dbt_databricks_proj_prod`.`silver`.`silver_salesinfo`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with customers as (
    select * from `dbt_databricks_proj_prod`.`bronze`.`bronze_customer`
),
products as (
    select * from `dbt_databricks_proj_prod`.`bronze`.`bronze_product`
),
sales as (
    select * from `dbt_databricks_proj_prod`.`bronze`.`bronze_sales`
),
joined_data as (

select 
    s.sales_id,
    
    s.quantity * s.unit_price
 as gross_amount,
    
    s.payment_method,
    c.gender,
    p.category
from sales s
join customers c on s.customer_sk = c.customer_sk  
join products p on s.product_sk = p.product_sk

)

select 
    category,
    gender,
    sum(gross_amount) as total_gross_amount
from joined_data
group by 
    category,gender
order by
    total_gross_amount desc
  
[0m12:13:55.427684 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m12:13:55.767963 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a8c6-1a87-b438-9325c443e88a) - Created
[0m12:13:59.964768 [debug] [Thread-7 (]: SQL status: OK in 4.520 seconds
[0m12:13:59.966275 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f0874e-a8c6-1a87-b438-9325c443e88a, command-id=01f0874e-a8d1-13c0-8138-561420acc6da) - Closing
[0m12:13:59.966275 [debug] [Thread-7 (]: Applying tags to relation None
[0m12:13:59.966275 [debug] [Thread-7 (]: On model.dbt_databricks_proj.silver_salesinfo: Close
[0m12:13:59.966275 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f0874e-a8c6-1a87-b438-9325c443e88a) - Closing
[0m12:14:00.070565 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e800e770-e773-4101-98dc-2bb46488bb3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B4A8DA90>]}
[0m12:14:00.072581 [info ] [Thread-7 (]: 17 of 17 OK created sql table model silver.silver_salesinfo .................... [[32mOK[0m in 4.67s]
[0m12:14:00.072581 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.silver_salesinfo
[0m12:14:00.076737 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m12:14:00.076737 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:14:00.076737 [info ] [MainThread]: 
[0m12:14:00.076737 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 5 table models, 7 data tests, 3 view models in 0 hours 2 minutes and 8.52 seconds (128.52s).
[0m12:14:00.088024 [debug] [MainThread]: Command end result
[0m12:14:00.194325 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m12:14:00.202967 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m12:14:00.221754 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m12:14:00.221754 [info ] [MainThread]: 
[0m12:14:00.223768 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:14:00.225781 [info ] [MainThread]: 
[0m12:14:00.225781 [error] [MainThread]: [31mFailure in model source_gold_items (models\gold\source_gold_items.sql)[0m
[0m12:14:00.227795 [error] [MainThread]:   Database Error in model source_gold_items (models\gold\source_gold_items.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt_databricks_proj_prod`.`source`.`items` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 21 pos 0
  compiled code at target\run\dbt_databricks_proj\models\gold\source_gold_items.sql
[0m12:14:00.229808 [info ] [MainThread]: 
[0m12:14:00.231822 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_proj\models\gold\source_gold_items.sql
[0m12:14:00.231822 [info ] [MainThread]: 
[0m12:14:00.231822 [info ] [MainThread]: Done. PASS=15 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=17
[0m12:14:00.231822 [debug] [MainThread]: Command `dbt build` failed at 12:14:00.231822 after 135.05 seconds
[0m12:14:00.231822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002738395E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273831DF620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273B495C680>]}
[0m12:14:00.240167 [debug] [MainThread]: Flushing usage events
[0m12:14:01.161685 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:33:01.835565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF7DEC8410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF7B34B6E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF7E49C140>]}


============================== 13:33:01.835565 | d7df0608-e1c7-458f-84ed-9bdf092bc213 ==============================
[0m13:33:01.835565 [info ] [MainThread]: Running with dbt=1.10.10
[0m13:33:01.851353 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj\\logs', 'profiles_dir': 'C:\\Users\\vrbsr\\OneDrive\\Desktop\\All_Files\\Projects\\DBT_Databricks_project\\dbt_databricks_proj', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m13:33:03.037160 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m13:33:03.037160 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m13:33:03.037160 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m13:33:04.240671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2CABFEF0>]}
[0m13:33:04.323294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2B59FFB0>]}
[0m13:33:04.326339 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m13:33:04.723751 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m13:33:04.964334 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:33:04.964334 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:33:05.074728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2DAAD790>]}
[0m13:33:05.224239 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m13:33:05.231070 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m13:33:05.298357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2DE47EF0>]}
[0m13:33:05.298920 [info ] [MainThread]: Found 8 models, 5 analyses, 7 data tests, 1 seed, 1 snapshot, 7 sources, 688 macros
[0m13:33:05.301953 [info ] [MainThread]: 
[0m13:33:05.301953 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:33:05.305836 [info ] [MainThread]: 
[0m13:33:05.306918 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:33:05.306918 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:33:05.318244 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m13:33:05.318984 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m13:33:05.320517 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m13:33:05.322436 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m13:33:05.323001 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:33:05.684124 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-b7dd-1ce8-905f-fda4522bdd15) - Created
[0m13:33:06.119555 [debug] [ThreadPool]: SQL status: OK in 0.800 seconds
[0m13:33:06.119555 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08759-b7dd-1ce8-905f-fda4522bdd15, command-id=01f08759-b7ec-1572-b5a3-a277300bd5bc) - Closing
[0m13:33:06.119555 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m13:33:06.119555 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-b7dd-1ce8-905f-fda4522bdd15) - Closing
[0m13:33:06.204078 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m13:33:06.204078 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m13:33:06.206092 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m13:33:06.206092 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m13:33:06.206092 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:33:06.470662 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-b857-1531-aa21-3918c9a72162) - Created
[0m13:33:06.680221 [debug] [ThreadPool]: SQL status: OK in 0.470 seconds
[0m13:33:06.682234 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08759-b857-1531-aa21-3918c9a72162, command-id=01f08759-b863-1b74-8582-05a7ecaced5b) - Closing
[0m13:33:06.684247 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m13:33:06.684247 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-b857-1531-aa21-3918c9a72162) - Closing
[0m13:33:06.792826 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev) - Creating connection
[0m13:33:06.792826 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev'
[0m13:33:06.792826 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev"
[0m13:33:06.792826 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: GetSchemas(database=dbt_databricks_proj_dev, schema=None)
[0m13:33:06.795512 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:33:07.090822 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-b8b7-15be-9adb-71b97174006f) - Created
[0m13:33:07.294034 [debug] [ThreadPool]: SQL status: OK in 0.500 seconds
[0m13:33:07.296047 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08759-b8b7-15be-9adb-71b97174006f, command-id=01f08759-b8c3-1bf1-9685-3eb66c698b51) - Closing
[0m13:33:07.298060 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev: Close
[0m13:33:07.298060 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-b8b7-15be-9adb-71b97174006f) - Closing
[0m13:33:07.388136 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_silver) - Creating connection
[0m13:33:07.388136 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_silver'
[0m13:33:07.411849 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_silver"
[0m13:33:07.411849 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_silver"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'silver'

  
[0m13:33:07.411849 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:33:07.675962 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-b90f-195b-b2c5-222f151e4b5a) - Created
[0m13:33:08.628330 [debug] [ThreadPool]: SQL status: OK in 1.220 seconds
[0m13:33:08.639100 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08759-b90f-195b-b2c5-222f151e4b5a, command-id=01f08759-b91c-1505-81bb-71bfeed4112a) - Closing
[0m13:33:08.639100 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_silver: Close
[0m13:33:08.639100 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-b90f-195b-b2c5-222f151e4b5a) - Closing
[0m13:33:08.721940 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_bronze) - Creating connection
[0m13:33:08.721940 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_bronze'
[0m13:33:08.724958 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_bronze"
[0m13:33:08.726465 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'bronze'

  
[0m13:33:08.726465 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:33:08.998413 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-b9da-1940-a3da-4b15bb112162) - Created
[0m13:33:09.446976 [debug] [ThreadPool]: SQL status: OK in 0.720 seconds
[0m13:33:09.448726 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08759-b9da-1940-a3da-4b15bb112162, command-id=01f08759-b9e6-1d33-bc15-ebc39cbe8b65) - Closing
[0m13:33:09.450737 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_bronze: Close
[0m13:33:09.450737 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-b9da-1940-a3da-4b15bb112162) - Closing
[0m13:33:09.560908 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt_databricks_proj_dev_gold) - Creating connection
[0m13:33:09.560908 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt_databricks_proj_dev_gold'
[0m13:33:09.566474 [debug] [ThreadPool]: Using databricks connection "list_dbt_databricks_proj_dev_gold"
[0m13:33:09.566474 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "connection_name": "list_dbt_databricks_proj_dev_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt_databricks_proj_dev' 
  AND table_schema = 'gold'

  
[0m13:33:09.566474 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:33:09.828622 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-ba5a-1665-bb46-86e11638e2e3) - Created
[0m13:33:10.230780 [debug] [ThreadPool]: SQL status: OK in 0.660 seconds
[0m13:33:10.234807 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08759-ba5a-1665-bb46-86e11638e2e3, command-id=01f08759-ba65-12d8-bf0b-e24185bd79c9) - Closing
[0m13:33:10.234807 [debug] [ThreadPool]: On list_dbt_databricks_proj_dev_gold: Close
[0m13:33:10.234807 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08759-ba5a-1665-bb46-86e11638e2e3) - Closing
[0m13:33:10.306837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2D8FBAA0>]}
[0m13:33:10.315086 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_customer
[0m13:33:10.315086 [info ] [Thread-7 (]: 1 of 17 START sql table model bronze.bronze_customer ........................... [RUN]
[0m13:33:10.317096 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_customer) - Creating connection
[0m13:33:10.317096 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_customer'
[0m13:33:10.319114 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_customer
[0m13:33:10.328527 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_customer"
[0m13:33:10.330536 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_customer
[0m13:33:10.351301 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m13:33:10.352482 [warn ] [Thread-7 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m13:33:10.360089 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2F2BC5C0>]}
[0m13:33:10.418364 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_customer"
[0m13:33:10.418364 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_customer"
[0m13:33:10.418364 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_customer"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_customer`
  
[0m13:33:10.418364 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:10.679382 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-badc-118f-9ba6-d82a49b4fdc3) - Created
[0m13:33:14.052587 [debug] [Thread-7 (]: SQL status: OK in 3.630 seconds
[0m13:33:14.054599 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-badc-118f-9ba6-d82a49b4fdc3, command-id=01f08759-bae6-168c-a9e5-5efd9cd928b5) - Closing
[0m13:33:14.069670 [debug] [Thread-7 (]: Applying tags to relation None
[0m13:33:14.216979 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_customer: Close
[0m13:33:14.218996 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-badc-118f-9ba6-d82a49b4fdc3) - Closing
[0m13:33:14.308927 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF7D8DD040>]}
[0m13:33:14.308927 [info ] [Thread-7 (]: 1 of 17 OK created sql table model bronze.bronze_customer ...................... [[32mOK[0m in 3.99s]
[0m13:33:14.311306 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_customer
[0m13:33:14.311306 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_date
[0m13:33:14.311306 [info ] [Thread-7 (]: 2 of 17 START sql view model bronze.bronze_date ................................ [RUN]
[0m13:33:14.311306 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_date) - Creating connection
[0m13:33:14.311306 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_date'
[0m13:33:14.311306 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_date
[0m13:33:14.317907 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_date"
[0m13:33:14.319920 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_date
[0m13:33:14.334630 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m13:33:14.355269 [debug] [Thread-7 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_date`
[0m13:33:14.356777 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_date"
[0m13:33:14.358783 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_date"
[0m13:33:14.358783 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_date"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_date`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`dim_date`
  )

[0m13:33:14.358783 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:14.626934 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-bd35-1b88-961a-f9ca0e90cb6e) - Created
[0m13:33:15.896875 [debug] [Thread-7 (]: SQL status: OK in 1.540 seconds
[0m13:33:15.898885 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-bd35-1b88-961a-f9ca0e90cb6e, command-id=01f08759-bd40-1a50-a858-863eab94ac7c) - Closing
[0m13:33:15.898885 [debug] [Thread-7 (]: Applying tags to relation None
[0m13:33:15.900897 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_date: Close
[0m13:33:15.900897 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-bd35-1b88-961a-f9ca0e90cb6e) - Closing
[0m13:33:16.000491 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2F2BD820>]}
[0m13:33:16.001492 [info ] [Thread-7 (]: 2 of 17 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 1.69s]
[0m13:33:16.003499 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_date
[0m13:33:16.003499 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_product
[0m13:33:16.003499 [info ] [Thread-7 (]: 3 of 17 START sql view model bronze.bronze_product ............................. [RUN]
[0m13:33:16.005510 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_product) - Creating connection
[0m13:33:16.005510 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_product'
[0m13:33:16.005510 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_product
[0m13:33:16.011540 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_product"
[0m13:33:16.013549 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_product
[0m13:33:16.015560 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m13:33:16.018581 [debug] [Thread-7 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
[0m13:33:16.019042 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_product"
[0m13:33:16.020530 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_product"
[0m13:33:16.022195 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_product"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`dim_product`
  )

[0m13:33:16.022195 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:16.283967 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-be33-108c-b442-89410c9421f0) - Created
[0m13:33:17.126093 [debug] [Thread-7 (]: SQL status: OK in 1.100 seconds
[0m13:33:17.128102 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-be33-108c-b442-89410c9421f0, command-id=01f08759-be3d-19cc-85d3-d11e5358bda1) - Closing
[0m13:33:17.128102 [debug] [Thread-7 (]: Applying tags to relation None
[0m13:33:17.130111 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_product: Close
[0m13:33:17.130111 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-be33-108c-b442-89410c9421f0) - Closing
[0m13:33:17.210914 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2DF00680>]}
[0m13:33:17.212931 [info ] [Thread-7 (]: 3 of 17 OK created sql view model bronze.bronze_product ........................ [[32mOK[0m in 1.21s]
[0m13:33:17.214943 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_product
[0m13:33:17.214943 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_returns
[0m13:33:17.214943 [info ] [Thread-7 (]: 4 of 17 START sql table model bronze.bronze_returns ............................ [RUN]
[0m13:33:17.216995 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_returns) - Creating connection
[0m13:33:17.216995 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_returns'
[0m13:33:17.218008 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_returns
[0m13:33:17.223110 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_returns"
[0m13:33:17.223110 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_returns
[0m13:33:17.225124 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m13:33:17.227140 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_returns"
[0m13:33:17.229155 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_returns"
[0m13:33:17.229155 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_returns"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_returns`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`fact_returns`
  
[0m13:33:17.229155 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:17.490054 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-beeb-16c3-b78d-1d5aa651bcd8) - Created
[0m13:33:20.503483 [debug] [Thread-7 (]: SQL status: OK in 3.270 seconds
[0m13:33:20.505494 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-beeb-16c3-b78d-1d5aa651bcd8, command-id=01f08759-bef6-1158-9476-519266638863) - Closing
[0m13:33:20.507503 [debug] [Thread-7 (]: Applying tags to relation None
[0m13:33:20.509513 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_returns: Close
[0m13:33:20.509513 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-beeb-16c3-b78d-1d5aa651bcd8) - Closing
[0m13:33:20.587197 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2D8654C0>]}
[0m13:33:20.587197 [info ] [Thread-7 (]: 4 of 17 OK created sql table model bronze.bronze_returns ....................... [[32mOK[0m in 3.37s]
[0m13:33:20.587197 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_returns
[0m13:33:20.587197 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_sales
[0m13:33:20.590830 [info ] [Thread-7 (]: 5 of 17 START sql view model bronze.bronze_sales ............................... [RUN]
[0m13:33:20.590830 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_sales) - Creating connection
[0m13:33:20.590830 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_sales'
[0m13:33:20.590830 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_sales
[0m13:33:20.601561 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_sales"
[0m13:33:20.604289 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_sales
[0m13:33:20.606245 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m13:33:20.606245 [debug] [Thread-7 (]: Creating view `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
[0m13:33:20.609262 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_sales"
[0m13:33:20.609262 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_sales"
[0m13:33:20.611293 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_sales"} */

  
  
  create or replace view `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
  
  as (
    select * from `dbt_databricks_proj_dev`.`source`.`fact_sales`
  )

[0m13:33:20.611293 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:20.882649 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c0f0-116f-9856-d83e3255e1ca) - Created
[0m13:33:21.629394 [debug] [Thread-7 (]: SQL status: OK in 1.020 seconds
[0m13:33:21.629394 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-c0f0-116f-9856-d83e3255e1ca, command-id=01f08759-c0fb-177e-866f-a877e5946e59) - Closing
[0m13:33:21.629394 [debug] [Thread-7 (]: Applying tags to relation None
[0m13:33:21.629394 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_sales: Close
[0m13:33:21.629394 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c0f0-116f-9856-d83e3255e1ca) - Closing
[0m13:33:21.728573 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2F2DB350>]}
[0m13:33:21.728573 [info ] [Thread-7 (]: 5 of 17 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 1.14s]
[0m13:33:21.728573 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_sales
[0m13:33:21.731871 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.bronze_store
[0m13:33:21.731871 [info ] [Thread-7 (]: 6 of 17 START sql table model bronze.bronze_store .............................. [RUN]
[0m13:33:21.733880 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.bronze_store) - Creating connection
[0m13:33:21.734388 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.bronze_store'
[0m13:33:21.734388 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.bronze_store
[0m13:33:21.740295 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.bronze_store"
[0m13:33:21.740295 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.bronze_store
[0m13:33:21.742949 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m13:33:21.744962 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.bronze_store"
[0m13:33:21.746974 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.bronze_store"
[0m13:33:21.747984 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.bronze_store"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select * from `dbt_databricks_proj_dev`.`source`.`dim_store`
  
[0m13:33:21.747984 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:22.019650 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c19e-14ce-895a-99e01aabd4f3) - Created
[0m13:33:24.602887 [debug] [Thread-7 (]: SQL status: OK in 2.850 seconds
[0m13:33:24.604891 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-c19e-14ce-895a-99e01aabd4f3, command-id=01f08759-c1a9-1c0e-a062-55f26100bc2a) - Closing
[0m13:33:24.606895 [debug] [Thread-7 (]: Applying tags to relation None
[0m13:33:24.608899 [debug] [Thread-7 (]: On model.dbt_databricks_proj.bronze_store: Close
[0m13:33:24.610403 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c19e-14ce-895a-99e01aabd4f3) - Closing
[0m13:33:24.676486 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2D77CA70>]}
[0m13:33:24.688458 [info ] [Thread-7 (]: 6 of 17 OK created sql table model bronze.bronze_store ......................... [[32mOK[0m in 2.94s]
[0m13:33:24.690468 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.bronze_store
[0m13:33:24.690468 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.source_gold_items
[0m13:33:24.692221 [info ] [Thread-7 (]: 7 of 17 START sql table model gold.source_gold_items ........................... [RUN]
[0m13:33:24.692221 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.source_gold_items) - Creating connection
[0m13:33:24.692221 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.source_gold_items'
[0m13:33:24.694857 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.source_gold_items
[0m13:33:24.700893 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.source_gold_items"
[0m13:33:24.702904 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.source_gold_items
[0m13:33:24.704916 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m13:33:24.707936 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.source_gold_items"
[0m13:33:24.709943 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.source_gold_items"
[0m13:33:24.709943 [debug] [Thread-7 (]: On model.dbt_databricks_proj.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.source_gold_items"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`gold`.`source_gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with cte1 as (
select *,
row_number() over (partition by id order by updatedDate desc) as dedup_id
from 
`dbt_databricks_proj_dev`.`source`.`items`

)

select id,name,category,updatedDate from cte1
where dedup_id=1
  
[0m13:33:24.709943 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:24.994663 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c365-1058-9e3f-8a6c42d405f0) - Created
[0m13:33:28.188621 [debug] [Thread-7 (]: SQL status: OK in 3.480 seconds
[0m13:33:28.190637 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-c365-1058-9e3f-8a6c42d405f0, command-id=01f08759-c36e-1cac-8939-946fabfe859d) - Closing
[0m13:33:28.190637 [debug] [Thread-7 (]: Applying tags to relation None
[0m13:33:28.192651 [debug] [Thread-7 (]: On model.dbt_databricks_proj.source_gold_items: Close
[0m13:33:28.192651 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c365-1058-9e3f-8a6c42d405f0) - Closing
[0m13:33:28.274689 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2DCDD4F0>]}
[0m13:33:28.274689 [info ] [Thread-7 (]: 7 of 17 OK created sql table model gold.source_gold_items ...................... [[32mOK[0m in 3.58s]
[0m13:33:28.276087 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.source_gold_items
[0m13:33:28.276087 [debug] [Thread-7 (]: Began running node seed.dbt_databricks_proj.lookup
[0m13:33:28.278101 [info ] [Thread-7 (]: 8 of 17 START seed file bronze.lookup .......................................... [RUN]
[0m13:33:28.278101 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_databricks_proj.lookup) - Creating connection
[0m13:33:28.278101 [debug] [Thread-7 (]: Acquiring new databricks connection 'seed.dbt_databricks_proj.lookup'
[0m13:33:28.280113 [debug] [Thread-7 (]: Began compiling node seed.dbt_databricks_proj.lookup
[0m13:33:28.280113 [debug] [Thread-7 (]: Began executing node seed.dbt_databricks_proj.lookup
[0m13:33:28.318788 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m13:33:28.318788 [debug] [Thread-7 (]: On seed.dbt_databricks_proj.lookup: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "seed.dbt_databricks_proj.lookup"} */

    create or replace table `dbt_databricks_proj_dev`.`bronze`.`lookup` (`customer_id` bigint ,`customer_name` string ,`customer_email` string )
    
  using delta
    
    
    
    
    
  
[0m13:33:28.318788 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:28.643191 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c592-1397-a0eb-09664287b9c1) - Created
[0m13:33:30.334088 [debug] [Thread-7 (]: SQL status: OK in 2.020 seconds
[0m13:33:30.336095 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-c592-1397-a0eb-09664287b9c1, command-id=01f08759-c59b-1a0c-8926-887a87699f32) - Closing
[0m13:33:30.354160 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_databricks_proj.lookup"
[0m13:33:30.354160 [debug] [Thread-7 (]: On seed.dbt_databricks_proj.lookup: 
          insert overwrite `dbt_databricks_proj_dev`.`bronze`.`lookup` values
          (%s,%s,%s),(%s,%s,%s),(%s,%s,%s)
      ...
[0m13:33:33.090666 [debug] [Thread-7 (]: SQL status: OK in 2.730 seconds
[0m13:33:33.090666 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-c592-1397-a0eb-09664287b9c1, command-id=01f08759-c6a0-1a30-ae87-9e94eeac64b3) - Closing
[0m13:33:33.106328 [debug] [Thread-7 (]: Writing runtime SQL for node "seed.dbt_databricks_proj.lookup"
[0m13:33:33.113408 [debug] [Thread-7 (]: On seed.dbt_databricks_proj.lookup: Close
[0m13:33:33.113408 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c592-1397-a0eb-09664287b9c1) - Closing
[0m13:33:33.200471 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2DCDC830>]}
[0m13:33:33.207640 [info ] [Thread-7 (]: 8 of 17 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 4.92s]
[0m13:33:33.207640 [debug] [Thread-7 (]: Finished running node seed.dbt_databricks_proj.lookup
[0m13:33:33.207640 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m13:33:33.207640 [info ] [Thread-7 (]: 9 of 17 START test non_negitive_bronze_sales_gross_amount ...................... [RUN]
[0m13:33:33.207640 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13) - Creating connection
[0m13:33:33.207640 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13'
[0m13:33:33.207640 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m13:33:33.223236 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m13:33:33.226227 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m13:33:33.251603 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m13:33:33.251603 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"
[0m13:33:33.251603 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  

select 
    *
from 
    `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where 
    gross_amount < 0


  
  
      
    ) dbt_internal_test
[0m13:33:33.261687 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:33.515492 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c878-1620-9b3b-453c94c910f1) - Created
[0m13:33:34.328332 [debug] [Thread-7 (]: SQL status: OK in 1.070 seconds
[0m13:33:34.332364 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-c878-1620-9b3b-453c94c910f1, command-id=01f08759-c882-1b6b-b666-d76a6f915730) - Closing
[0m13:33:34.336394 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13: Close
[0m13:33:34.336394 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c878-1620-9b3b-453c94c910f1) - Closing
[0m13:33:34.432717 [info ] [Thread-7 (]: 9 of 17 PASS non_negitive_bronze_sales_gross_amount ............................ [[32mPASS[0m in 1.23s]
[0m13:33:34.434728 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.non_negitive_bronze_sales_gross_amount.8b1a3fab13
[0m13:33:34.434728 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.non_negitive_test
[0m13:33:34.434728 [info ] [Thread-7 (]: 10 of 17 START test non_negitive_test .......................................... [RUN]
[0m13:33:34.437929 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.non_negitive_test) - Creating connection
[0m13:33:34.437929 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.non_negitive_test'
[0m13:33:34.437929 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.non_negitive_test
[0m13:33:34.445541 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.non_negitive_test"
[0m13:33:34.446744 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.non_negitive_test
[0m13:33:34.449866 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.non_negitive_test"
[0m13:33:34.451280 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.non_negitive_test"
[0m13:33:34.451280 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_test: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.non_negitive_test"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  select *
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales` 
where gross_amount < 0 and net_amount < 0
  
  
      
    ) dbt_internal_test
[0m13:33:34.451280 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:34.700450 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c92e-16da-87d0-fae341bdc38a) - Created
[0m13:33:35.350086 [debug] [Thread-7 (]: SQL status: OK in 0.900 seconds
[0m13:33:35.354106 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-c92e-16da-87d0-fae341bdc38a, command-id=01f08759-c937-17b4-8fc0-f42e8844127f) - Closing
[0m13:33:35.354106 [debug] [Thread-7 (]: On test.dbt_databricks_proj.non_negitive_test: Close
[0m13:33:35.356117 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c92e-16da-87d0-fae341bdc38a) - Closing
[0m13:33:35.442173 [info ] [Thread-7 (]: 10 of 17 PASS non_negitive_test ................................................ [[32mPASS[0m in 1.01s]
[0m13:33:35.442173 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.non_negitive_test
[0m13:33:35.444184 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:33:35.444184 [info ] [Thread-7 (]: 11 of 17 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m13:33:35.444184 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m13:33:35.446194 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m13:33:35.446194 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:33:35.456242 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:33:35.456242 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:33:35.460003 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:33:35.462011 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:33:35.462011 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m13:33:35.462011 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:35.723222 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c9c9-133f-b7fe-bcb22612dc65) - Created
[0m13:33:36.275532 [debug] [Thread-7 (]: SQL status: OK in 0.810 seconds
[0m13:33:36.277542 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-c9c9-133f-b7fe-bcb22612dc65, command-id=01f08759-c9d4-168f-b3cf-00971324c816) - Closing
[0m13:33:36.279553 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m13:33:36.279553 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-c9c9-133f-b7fe-bcb22612dc65) - Closing
[0m13:33:36.381317 [info ] [Thread-7 (]: 11 of 17 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 0.94s]
[0m13:33:36.381317 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:33:36.381317 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m13:33:36.383325 [info ] [Thread-7 (]: 12 of 17 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m13:33:36.383325 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m13:33:36.383325 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d'
[0m13:33:36.383325 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m13:33:36.398041 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:33:36.400034 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m13:33:36.405227 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:33:36.405546 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:33:36.407330 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m13:33:36.407330 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:36.692552 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-ca5c-16a9-83fb-d9444b3d1a25) - Created
[0m13:33:37.300051 [debug] [Thread-7 (]: SQL status: OK in 0.890 seconds
[0m13:33:37.305681 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ca5c-16a9-83fb-d9444b3d1a25, command-id=01f08759-ca68-11af-86cc-e2abf33b0ef0) - Closing
[0m13:33:37.306423 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m13:33:37.306423 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-ca5c-16a9-83fb-d9444b3d1a25) - Closing
[0m13:33:37.384312 [info ] [Thread-7 (]: 12 of 17 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.00s]
[0m13:33:37.384862 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.unique_bronze_sales_sales_id.3c35aa753d
[0m13:33:37.386877 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m13:33:37.386877 [info ] [Thread-7 (]: 13 of 17 START test accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [RUN]
[0m13:33:37.388887 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159) - Creating connection
[0m13:33:37.388887 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159'
[0m13:33:37.390902 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m13:33:37.411191 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m13:33:37.411191 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m13:33:37.416494 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m13:33:37.418816 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"
[0m13:33:37.419836 [debug] [Thread-7 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Manhattan','MegaMart Brooklyn','MegaMart Austin','MegaMart San Jose','MegaMart Toronto'
)



  
  
      
    ) dbt_internal_test
[0m13:33:37.419836 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:37.680436 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-caf3-161e-ab22-94ff10027130) - Created
[0m13:33:38.631022 [debug] [Thread-7 (]: SQL status: OK in 1.210 seconds
[0m13:33:38.635040 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-caf3-161e-ab22-94ff10027130, command-id=01f08759-cafe-1ba5-8cb0-3a229ad38763) - Closing
[0m13:33:38.637049 [debug] [Thread-7 (]: On test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159: Close
[0m13:33:38.637049 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-caf3-161e-ab22-94ff10027130) - Closing
[0m13:33:38.716070 [info ] [Thread-7 (]: 13 of 17 PASS accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto  [[32mPASS[0m in 1.33s]
[0m13:33:38.716070 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.accepted_values_bronze_store_store_name__MegaMart_Manhattan__MegaMart_Brooklyn__MegaMart_Austin__MegaMart_San_Jose__MegaMart_Toronto.557ba83159
[0m13:33:38.716070 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m13:33:38.716070 [info ] [Thread-7 (]: 14 of 17 START test not_null_bronze_store_store_sk ............................. [RUN]
[0m13:33:38.726225 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a) - Creating connection
[0m13:33:38.726225 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a'
[0m13:33:38.726225 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m13:33:38.735509 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m13:33:38.737145 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m13:33:38.739527 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m13:33:38.741230 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"
[0m13:33:38.742083 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select store_sk
from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is null



  
  
      
    ) dbt_internal_test
[0m13:33:38.742590 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:39.025005 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-cbc0-1d08-8cb5-707c8066230c) - Created
[0m13:33:39.621018 [debug] [Thread-7 (]: SQL status: OK in 0.880 seconds
[0m13:33:39.621018 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-cbc0-1d08-8cb5-707c8066230c, command-id=01f08759-cbcc-10cf-a8b2-d0e66c388d67) - Closing
[0m13:33:39.621018 [debug] [Thread-7 (]: On test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a: Close
[0m13:33:39.628077 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-cbc0-1d08-8cb5-707c8066230c) - Closing
[0m13:33:39.722849 [info ] [Thread-7 (]: 14 of 17 PASS not_null_bronze_store_store_sk ................................... [[32mPASS[0m in 1.00s]
[0m13:33:39.724862 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.not_null_bronze_store_store_sk.ffdb44062a
[0m13:33:39.726875 [debug] [Thread-7 (]: Began running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m13:33:39.726875 [info ] [Thread-7 (]: 15 of 17 START test unique_bronze_store_store_sk ............................... [RUN]
[0m13:33:39.728889 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63) - Creating connection
[0m13:33:39.728889 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63'
[0m13:33:39.730903 [debug] [Thread-7 (]: Began compiling node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m13:33:39.730903 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m13:33:39.739476 [debug] [Thread-7 (]: Began executing node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m13:33:39.742608 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m13:33:39.742608 [debug] [Thread-7 (]: Using databricks connection "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"
[0m13:33:39.742608 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    store_sk as unique_field,
    count(*) as n_records

from `dbt_databricks_proj_dev`.`bronze`.`bronze_store`
where store_sk is not null
group by store_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m13:33:39.742608 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:39.987652 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-cc56-1c23-8261-146bc6936177) - Created
[0m13:33:40.655153 [debug] [Thread-7 (]: SQL status: OK in 0.910 seconds
[0m13:33:40.659341 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-cc56-1c23-8261-146bc6936177, command-id=01f08759-cc60-1c22-8fb4-80747e2ad557) - Closing
[0m13:33:40.659341 [debug] [Thread-7 (]: On test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63: Close
[0m13:33:40.661351 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-cc56-1c23-8261-146bc6936177) - Closing
[0m13:33:40.739944 [info ] [Thread-7 (]: 15 of 17 PASS unique_bronze_store_store_sk ..................................... [[32mPASS[0m in 1.01s]
[0m13:33:40.741960 [debug] [Thread-7 (]: Finished running node test.dbt_databricks_proj.unique_bronze_store_store_sk.cd37333b63
[0m13:33:40.741960 [debug] [Thread-7 (]: Began running node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m13:33:40.743971 [info ] [Thread-7 (]: 16 of 17 START snapshot gold.gold_items_snapshot ............................... [RUN]
[0m13:33:40.743971 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.dbt_databricks_proj.gold_items_snapshot) - Creating connection
[0m13:33:40.745986 [debug] [Thread-7 (]: Acquiring new databricks connection 'snapshot.dbt_databricks_proj.gold_items_snapshot'
[0m13:33:40.745986 [debug] [Thread-7 (]: Began compiling node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m13:33:40.755819 [debug] [Thread-7 (]: Began executing node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m13:33:40.809177 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:41.095117 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-ccfc-1958-906f-af7434ff791e) - Created
[0m13:33:41.103039 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:41.103039 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot` AS JSON

  
[0m13:33:42.009925 [debug] [Thread-7 (]: SQL status: OK in 0.910 seconds
[0m13:33:42.013697 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ccfc-1958-906f-af7434ff791e, command-id=01f08759-cd09-1292-97d2-4ee0d94fdb8f) - Closing
[0m13:33:42.061564 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:42.061564 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

        
  
    create or replace temporary view `gold_items_snapshot__dbt_tmp` as
      
    
    with snapshot_query as (

        select * from `dbt_databricks_proj_dev`.`gold`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedDate as dbt_updated_at,
            updatedDate as dbt_valid_from,
            
  
  coalesce(nullif(updatedDate, updatedDate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedDate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedDate as dbt_updated_at,
            updatedDate as dbt_valid_from,
            updatedDate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updatedDate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updatedDate)
        )
    )

    select * from insertions
    union all
    select * from updates

  
    
[0m13:33:42.521739 [debug] [Thread-7 (]: SQL status: OK in 0.460 seconds
[0m13:33:42.523752 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ccfc-1958-906f-af7434ff791e, command-id=01f08759-cd9c-139f-8411-70ba799e5556) - Closing
[0m13:33:42.527779 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:42.529792 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `gold_items_snapshot__dbt_tmp` AS JSON

  
[0m13:33:42.828957 [debug] [Thread-7 (]: SQL status: OK in 0.300 seconds
[0m13:33:42.832728 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ccfc-1958-906f-af7434ff791e, command-id=01f08759-cde3-1161-948a-b7f327f1b5be) - Closing
[0m13:33:42.836133 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:42.836133 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot` AS JSON

  
[0m13:33:43.130104 [debug] [Thread-7 (]: SQL status: OK in 0.290 seconds
[0m13:33:43.130104 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ccfc-1958-906f-af7434ff791e, command-id=01f08759-ce11-1682-bdb9-30f13343cdd3) - Closing
[0m13:33:43.141177 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:43.141177 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `gold_items_snapshot__dbt_tmp` AS JSON

  
[0m13:33:43.443066 [debug] [Thread-7 (]: SQL status: OK in 0.300 seconds
[0m13:33:43.447093 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ccfc-1958-906f-af7434ff791e, command-id=01f08759-ce3f-13c2-b6b6-0c539036afbe) - Closing
[0m13:33:43.453133 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:43.453133 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot` AS JSON

  
[0m13:33:43.750923 [debug] [Thread-7 (]: SQL status: OK in 0.300 seconds
[0m13:33:43.750923 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ccfc-1958-906f-af7434ff791e, command-id=01f08759-ce6f-1331-a929-0c3a63efe088) - Closing
[0m13:33:43.761605 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:43.761605 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

    
  DESCRIBE TABLE EXTENDED `gold_items_snapshot__dbt_tmp` AS JSON

  
[0m13:33:44.056746 [debug] [Thread-7 (]: SQL status: OK in 0.300 seconds
[0m13:33:44.061724 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ccfc-1958-906f-af7434ff791e, command-id=01f08759-ce9e-1989-bc91-a3bf72390579) - Closing
[0m13:33:44.083584 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:44.084284 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */
select * from (
        
    
    with snapshot_query as (

        select * from `dbt_databricks_proj_dev`.`gold`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedDate as dbt_updated_at,
            updatedDate as dbt_valid_from,
            
  
  coalesce(nullif(updatedDate, updatedDate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedDate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedDate as dbt_updated_at,
            updatedDate as dbt_valid_from,
            updatedDate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updatedDate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updatedDate)
        )
    )

    select * from insertions
    union all
    select * from updates

    ) as __dbt_sbq
    where false
    limit 0

[0m13:33:44.671210 [debug] [Thread-7 (]: SQL status: OK in 0.590 seconds
[0m13:33:44.680505 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:44.680505 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m13:33:44.680505 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ccfc-1958-906f-af7434ff791e, command-id=01f08759-cecf-18fe-8e04-b22e27b4baee) - Closing
[0m13:33:44.873225 [debug] [Thread-7 (]: SQL status: OK in 0.190 seconds
[0m13:33:44.876025 [debug] [Thread-7 (]: Writing runtime sql for node "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:44.878038 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:44.878038 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */

      merge into `dbt_databricks_proj_dev`.`gold`.`gold_items_snapshot` as DBT_INTERNAL_DEST
    
      using `gold_items_snapshot__dbt_tmp` as DBT_INTERNAL_SOURCE
    
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id
    when matched
     
       and ( DBT_INTERNAL_DEST.dbt_valid_to = to_date('9999-12-31') or
             DBT_INTERNAL_DEST.dbt_valid_to is null )
     
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert *
    ;

  
[0m13:33:44.878038 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ccfc-1958-906f-af7434ff791e, command-id=01f08759-cf2a-1c67-b5fb-763d54875133) - Closing
[0m13:33:50.772185 [debug] [Thread-7 (]: SQL status: OK in 5.890 seconds
[0m13:33:50.773689 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ccfc-1958-906f-af7434ff791e, command-id=01f08759-cf48-17f1-894f-e4b1ee2d0052) - Closing
[0m13:33:50.907369 [debug] [Thread-7 (]: Applying DROP to: `gold_items_snapshot__dbt_tmp`
[0m13:33:50.916582 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_databricks_proj.gold_items_snapshot"
[0m13:33:50.916582 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "snapshot.dbt_databricks_proj.gold_items_snapshot"} */
DROP VIEW IF EXISTS `gold_items_snapshot__dbt_tmp`
[0m13:33:51.126412 [debug] [Thread-7 (]: SQL status: OK in 0.210 seconds
[0m13:33:51.129718 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-ccfc-1958-906f-af7434ff791e, command-id=01f08759-d2e2-174c-b5bb-58e6b2237dbb) - Closing
[0m13:33:51.129718 [debug] [Thread-7 (]: On snapshot.dbt_databricks_proj.gold_items_snapshot: Close
[0m13:33:51.132560 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-ccfc-1958-906f-af7434ff791e) - Closing
[0m13:33:51.219920 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF7E417530>]}
[0m13:33:51.219920 [info ] [Thread-7 (]: 16 of 17 OK snapshotted gold.gold_items_snapshot ............................... [[32mOK[0m in 10.48s]
[0m13:33:51.221929 [debug] [Thread-7 (]: Finished running node snapshot.dbt_databricks_proj.gold_items_snapshot
[0m13:33:51.221929 [debug] [Thread-7 (]: Began running node model.dbt_databricks_proj.silver_salesinfo
[0m13:33:51.221929 [info ] [Thread-7 (]: 17 of 17 START sql table model silver.silver_salesinfo ......................... [RUN]
[0m13:33:51.223940 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_proj.silver_salesinfo) - Creating connection
[0m13:33:51.225179 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_databricks_proj.silver_salesinfo'
[0m13:33:51.225179 [debug] [Thread-7 (]: Began compiling node model.dbt_databricks_proj.silver_salesinfo
[0m13:33:51.230285 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_databricks_proj.silver_salesinfo"
[0m13:33:51.233197 [debug] [Thread-7 (]: Began executing node model.dbt_databricks_proj.silver_salesinfo
[0m13:33:51.235114 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m13:33:51.238362 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_databricks_proj.silver_salesinfo"
[0m13:33:51.238362 [debug] [Thread-7 (]: Using databricks connection "model.dbt_databricks_proj.silver_salesinfo"
[0m13:33:51.239982 [debug] [Thread-7 (]: On model.dbt_databricks_proj.silver_salesinfo: /* {"app": "dbt", "dbt_version": "1.10.10", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_databricks_proj", "target_name": "dev", "node_id": "model.dbt_databricks_proj.silver_salesinfo"} */

  
    
        create or replace table `dbt_databricks_proj_dev`.`silver`.`silver_salesinfo`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with customers as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_customer`
),
products as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_product`
),
sales as (
    select * from `dbt_databricks_proj_dev`.`bronze`.`bronze_sales`
),
joined_data as (

select 
    s.sales_id,
    
    s.quantity * s.unit_price
 as gross_amount,
    
    s.payment_method,
    c.gender,
    p.category
from sales s
join customers c on s.customer_sk = c.customer_sk  
join products p on s.product_sk = p.product_sk

)

select 
    category,
    gender,
    sum(gross_amount) as total_gross_amount
from joined_data
group by 
    category,gender
order by
    total_gross_amount desc
  
[0m13:33:51.239982 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:33:51.502191 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-d330-1984-a899-dfdaa08ff77e) - Created
[0m13:33:55.425016 [debug] [Thread-7 (]: SQL status: OK in 4.190 seconds
[0m13:33:55.427030 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08759-d330-1984-a899-dfdaa08ff77e, command-id=01f08759-d33b-1d1b-a96b-abbffe801bc7) - Closing
[0m13:33:55.429044 [debug] [Thread-7 (]: Applying tags to relation None
[0m13:33:55.431057 [debug] [Thread-7 (]: On model.dbt_databricks_proj.silver_salesinfo: Close
[0m13:33:55.432068 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08759-d330-1984-a899-dfdaa08ff77e) - Closing
[0m13:33:55.512487 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd7df0608-e1c7-458f-84ed-9bdf092bc213', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF2DF00440>]}
[0m13:33:55.514512 [info ] [Thread-7 (]: 17 of 17 OK created sql table model silver.silver_salesinfo .................... [[32mOK[0m in 4.29s]
[0m13:33:55.514512 [debug] [Thread-7 (]: Finished running node model.dbt_databricks_proj.silver_salesinfo
[0m13:33:55.514512 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:33:55.518225 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:33:55.518225 [info ] [MainThread]: 
[0m13:33:55.518225 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 5 table models, 7 data tests, 3 view models in 0 hours 0 minutes and 50.21 seconds (50.21s).
[0m13:33:55.524063 [debug] [MainThread]: Command end result
[0m13:33:55.567406 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\manifest.json
[0m13:33:55.574100 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\semantic_manifest.json
[0m13:33:55.580142 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\vrbsr\OneDrive\Desktop\All_Files\Projects\DBT_Databricks_project\dbt_databricks_proj\target\run_results.json
[0m13:33:55.582607 [info ] [MainThread]: 
[0m13:33:55.583368 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:33:55.583368 [info ] [MainThread]: 
[0m13:33:55.584951 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=17
[0m13:33:55.584951 [debug] [MainThread]: Command `dbt build` succeeded at 13:33:55.584951 after 53.93 seconds
[0m13:33:55.584951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF7E3B8B00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF7D4A1520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF7D4A09E0>]}
[0m13:33:55.584951 [debug] [MainThread]: Flushing usage events
[0m13:33:56.082396 [debug] [MainThread]: An error was encountered while trying to flush usage events
